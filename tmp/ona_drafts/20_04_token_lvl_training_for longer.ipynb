{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f838074-e829-40d5-9b15-949a9bfe9708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import uuid, sys, os\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "\n",
    "from transformers import EsmModel, AutoTokenizer # huggingface\n",
    "import esm\n",
    "\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.cuda.set_device(0)  # 0 == \"first visible\" -> actually GPU 2 on the node\n",
    "torch.manual_seed(0)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import AdamW\n",
    "from accelerate import Accelerator\n",
    "import training_utils.partitioning_utils as pat_utils\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "# LoRA\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d0770f-c901-45f7-b5e7-801a2f8f261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1+cu128\n",
      "Using device: cuda\n",
      "Current location: /zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch:\", torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print(\"Current location:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da12c27-b0c9-4166-bf60-a7e182e83805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /zhome/c9/0/203261/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms232958\u001b[0m (\u001b[33ms232958-danmarks-tekniske-universitet-dtu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://api.wandb.ai/status\").status_code\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"f8a6d759fe657b095d56bddbdb4d586dfaebd468\", relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a771b897-1647-4594-b648-41d2639d5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting a seed to have the same initiation of weights\n",
    "\n",
    "def set_seed(seed: int = 0):\n",
    "    # Python & NumPy\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "\n",
    "    # CuDNN settings (for convolution etc.)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # (Optional) for some Python hashing randomness\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "SEED = 0\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfc6c69-e492-4bf1-a23e-e8ee41a27d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "memory_verbose = False\n",
    "use_wandb = True # Used to track loss in real-time without printing\n",
    "\n",
    "seq_embed_dimension = 1280 #| 960 | 1152\n",
    "# struct_embed_dimension = 256\n",
    "number_of_recycles = 2\n",
    "padding_value = -5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b152a01f-a72c-4d75-9e1c-6b6f937515eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory:  34.072559616\n",
      "Reserved memory:  0.0\n",
      "Allocated memory:  0.0\n",
      "Free memory:  0.0\n"
     ]
    }
   ],
   "source": [
    "# ## Training variables\n",
    "runID = uuid.uuid4()\n",
    "\n",
    "def print_mem_consumption():\n",
    "    # 1. Total memory available on the GPU (device 0)\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    # 2. How much memory PyTorch has *reserved* from CUDA\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    # 3. How much of that reserved memory is actually *used* by tensors\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    # 4. Reserved but not currently allocated (so “free inside PyTorch’s pool”)\n",
    "    f = r - a\n",
    "\n",
    "    print(\"Total memory: \", t/1e9)      # total VRAM in GB\n",
    "    print(\"Reserved memory: \", r/1e9)   # PyTorch’s reserved pool in GB\n",
    "    print(\"Allocated memory: \", a//1e9) # actually in use (integer division)\n",
    "    print(\"Free memory: \", f/1e9)       # slack in the reserved pool in GB\n",
    "print_mem_consumption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b001f70e-d769-4c9e-ad66-6e6c919a0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_key_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings < (padding_value + offset)).all(dim=-1)\n",
    "\n",
    "def create_mean_of_non_masked(embeddings, padding_mask):\n",
    "    # Use masked select and mean to compute the mean of non-masked elements\n",
    "    # embeddings should be of shape (batch_size, seq_len, features)\n",
    "    seq_embeddings = []\n",
    "    for i in range(embeddings.shape[0]): # looping over all batch elements\n",
    "        non_masked_embeddings = embeddings[i][~padding_mask[i]] # shape [num_real_tokens, features]\n",
    "        if len(non_masked_embeddings) == 0:\n",
    "            print(\"You are masking all positions when creating sequence representation\")\n",
    "            sys.exit(1)\n",
    "        mean_embedding = non_masked_embeddings.mean(dim=0) # sequence is represented by the single vecotr [1152] [features]\n",
    "        seq_embeddings.append(mean_embedding)\n",
    "    return torch.stack(seq_embeddings)\n",
    "\n",
    "def non_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings > (padding_value + offset)).all(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349b030-2126-46c1-bb65-8d25e7fb6c0e",
   "metadata": {},
   "source": [
    "### Loading Data for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1277c85e-2ea7-44f6-8523-8b1362106edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interface_id</th>\n",
       "      <th>PDB</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>seq_target</th>\n",
       "      <th>seq_target_len</th>\n",
       "      <th>seq_pdb_target</th>\n",
       "      <th>pdb_target_len</th>\n",
       "      <th>target_chain</th>\n",
       "      <th>seq_binder</th>\n",
       "      <th>seq_binder_len</th>\n",
       "      <th>seq_pdb_binder</th>\n",
       "      <th>pdb_binder_len</th>\n",
       "      <th>binder_chain</th>\n",
       "      <th>pdb_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6IDB_0</td>\n",
       "      <td>6IDB</td>\n",
       "      <td>6IDB_0_A</td>\n",
       "      <td>6IDB_0_B</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "      <td>6IDB_A</td>\n",
       "      <td>GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...</td>\n",
       "      <td>172</td>\n",
       "      <td>GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...</td>\n",
       "      <td>172</td>\n",
       "      <td>6IDB_B</td>\n",
       "      <td>6idb.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2WZP_3</td>\n",
       "      <td>2WZP</td>\n",
       "      <td>2WZP_3_D</td>\n",
       "      <td>2WZP_3_G</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "      <td>2WZP_D</td>\n",
       "      <td>TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...</td>\n",
       "      <td>266</td>\n",
       "      <td>TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...</td>\n",
       "      <td>266</td>\n",
       "      <td>2WZP_G</td>\n",
       "      <td>2wzp.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ZKP_0</td>\n",
       "      <td>1ZKP</td>\n",
       "      <td>1ZKP_0_A</td>\n",
       "      <td>1ZKP_0_C</td>\n",
       "      <td>LYFQSNAKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLA...</td>\n",
       "      <td>246</td>\n",
       "      <td>LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...</td>\n",
       "      <td>251</td>\n",
       "      <td>1ZKP_A</td>\n",
       "      <td>AKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQKYI...</td>\n",
       "      <td>240</td>\n",
       "      <td>AMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQK...</td>\n",
       "      <td>245</td>\n",
       "      <td>1ZKP_C</td>\n",
       "      <td>1zkp.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6GRH_3</td>\n",
       "      <td>6GRH</td>\n",
       "      <td>6GRH_3_C</td>\n",
       "      <td>6GRH_3_D</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "      <td>6GRH_C</td>\n",
       "      <td>MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...</td>\n",
       "      <td>396</td>\n",
       "      <td>MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...</td>\n",
       "      <td>396</td>\n",
       "      <td>6GRH_D</td>\n",
       "      <td>6grh.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8R57_1</td>\n",
       "      <td>8R57</td>\n",
       "      <td>8R57_1_M</td>\n",
       "      <td>8R57_1_f</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "      <td>8R57_M</td>\n",
       "      <td>PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...</td>\n",
       "      <td>64</td>\n",
       "      <td>PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...</td>\n",
       "      <td>64</td>\n",
       "      <td>8R57_f</td>\n",
       "      <td>8r57.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>4YO8_0</td>\n",
       "      <td>4YO8</td>\n",
       "      <td>4YO8_0_A</td>\n",
       "      <td>4YO8_0_B</td>\n",
       "      <td>HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...</td>\n",
       "      <td>238</td>\n",
       "      <td>HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...</td>\n",
       "      <td>238</td>\n",
       "      <td>4YO8_A</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "      <td>4YO8_B</td>\n",
       "      <td>4yo8.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>3CKI_0</td>\n",
       "      <td>3CKI</td>\n",
       "      <td>3CKI_0_A</td>\n",
       "      <td>3CKI_0_B</td>\n",
       "      <td>DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...</td>\n",
       "      <td>256</td>\n",
       "      <td>DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...</td>\n",
       "      <td>256</td>\n",
       "      <td>3CKI_A</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "      <td>3CKI_B</td>\n",
       "      <td>3cki.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>7MHY_1</td>\n",
       "      <td>7MHY</td>\n",
       "      <td>7MHY_1_M</td>\n",
       "      <td>7MHY_1_N</td>\n",
       "      <td>QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...</td>\n",
       "      <td>118</td>\n",
       "      <td>QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...</td>\n",
       "      <td>118</td>\n",
       "      <td>7MHY_M</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "      <td>7MHY_N</td>\n",
       "      <td>7mhy.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>7MHY_2</td>\n",
       "      <td>7MHY</td>\n",
       "      <td>7MHY_2_O</td>\n",
       "      <td>7MHY_2_P</td>\n",
       "      <td>IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...</td>\n",
       "      <td>100</td>\n",
       "      <td>IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...</td>\n",
       "      <td>100</td>\n",
       "      <td>7MHY_O</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "      <td>7MHY_P</td>\n",
       "      <td>7mhy.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>6O42_0</td>\n",
       "      <td>6O42</td>\n",
       "      <td>6O42_0_L</td>\n",
       "      <td>6O42_0_H</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>214</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>214</td>\n",
       "      <td>6O42_L</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "      <td>6O42_H</td>\n",
       "      <td>6o42.pdb.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1977 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     interface_id   PDB       ID1       ID2  \\\n",
       "0          6IDB_0  6IDB  6IDB_0_A  6IDB_0_B   \n",
       "1          2WZP_3  2WZP  2WZP_3_D  2WZP_3_G   \n",
       "2          1ZKP_0  1ZKP  1ZKP_0_A  1ZKP_0_C   \n",
       "3          6GRH_3  6GRH  6GRH_3_C  6GRH_3_D   \n",
       "4          8R57_1  8R57  8R57_1_M  8R57_1_f   \n",
       "...           ...   ...       ...       ...   \n",
       "1972       4YO8_0  4YO8  4YO8_0_A  4YO8_0_B   \n",
       "1973       3CKI_0  3CKI  3CKI_0_A  3CKI_0_B   \n",
       "1974       7MHY_1  7MHY  7MHY_1_M  7MHY_1_N   \n",
       "1975       7MHY_2  7MHY  7MHY_2_O  7MHY_2_P   \n",
       "1976       6O42_0  6O42  6O42_0_L  6O42_0_H   \n",
       "\n",
       "                                             seq_target  seq_target_len  \\\n",
       "0     DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...             317   \n",
       "1     VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...             122   \n",
       "2     LYFQSNAKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLA...             246   \n",
       "3     SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...             266   \n",
       "4     DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...             118   \n",
       "...                                                 ...             ...   \n",
       "1972  HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...             238   \n",
       "1973  DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...             256   \n",
       "1974  QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...             118   \n",
       "1975  IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...             100   \n",
       "1976  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...             214   \n",
       "\n",
       "                                         seq_pdb_target  pdb_target_len  \\\n",
       "0     DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...             317   \n",
       "1     VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...             122   \n",
       "2     LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...             251   \n",
       "3     SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...             266   \n",
       "4     DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...             118   \n",
       "...                                                 ...             ...   \n",
       "1972  HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...             238   \n",
       "1973  DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...             256   \n",
       "1974  QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...             118   \n",
       "1975  IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...             100   \n",
       "1976  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...             214   \n",
       "\n",
       "     target_chain                                         seq_binder  \\\n",
       "0          6IDB_A  GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...   \n",
       "1          2WZP_D  TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...   \n",
       "2          1ZKP_A  AKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQKYI...   \n",
       "3          6GRH_C  MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...   \n",
       "4          8R57_M  PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...   \n",
       "...           ...                                                ...   \n",
       "1972       4YO8_A  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...   \n",
       "1973       3CKI_A  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...   \n",
       "1974       7MHY_M  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...   \n",
       "1975       7MHY_O  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...   \n",
       "1976       6O42_L  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...   \n",
       "\n",
       "      seq_binder_len                                     seq_pdb_binder  \\\n",
       "0                172  GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...   \n",
       "1                266  TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...   \n",
       "2                240  AMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQK...   \n",
       "3                396  MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...   \n",
       "4                 64  PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...   \n",
       "...              ...                                                ...   \n",
       "1972             242  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...   \n",
       "1973             121  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...   \n",
       "1974             109  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...   \n",
       "1975              94  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...   \n",
       "1976             220  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...   \n",
       "\n",
       "      pdb_binder_len binder_chain     pdb_path  \n",
       "0                172       6IDB_B  6idb.pdb.gz  \n",
       "1                266       2WZP_G  2wzp.pdb.gz  \n",
       "2                245       1ZKP_C  1zkp.pdb.gz  \n",
       "3                396       6GRH_D  6grh.pdb.gz  \n",
       "4                 64       8R57_f  8r57.pdb.gz  \n",
       "...              ...          ...          ...  \n",
       "1972             242       4YO8_B  4yo8.pdb.gz  \n",
       "1973             121       3CKI_B  3cki.pdb.gz  \n",
       "1974             109       7MHY_N  7mhy.pdb.gz  \n",
       "1975              94       7MHY_P  7mhy.pdb.gz  \n",
       "1976             220       6O42_H  6o42.pdb.gz  \n",
       "\n",
       "[1977 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_train = pd.read_csv(\"/work3/s232958/data/PPint_DB/PPint_train_w_pbd_lens.csv\",index_col=0).reset_index(drop=True)\n",
    "Df_test = pd.read_csv(\"/work3/s232958/data/PPint_DB/PPint_test_w_pbd_lens.csv\",index_col=0).reset_index(drop=True)\n",
    "\n",
    "Df_train[\"target_chain\"] = [str(row.ID1[:5]+row.ID1[-1]) for __, row in Df_train.iterrows()]\n",
    "Df_train[\"binder_chain\"] = [str(row.ID2[:5]+row.ID2[-1]) for __, row in Df_train.iterrows()]\n",
    "\n",
    "Df_test[\"target_chain\"] = [str(row.ID1[:5]+row.ID1[-1]) for __, row in Df_test.iterrows()]\n",
    "Df_test[\"binder_chain\"] = [str(row.ID2[:5]+row.ID2[-1]) for __, row in Df_test.iterrows()]\n",
    "\n",
    "Df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2dc3459-94e9-4184-88a3-b13120177122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SKVVKFSYMWTINNFSFCREEMGEVIKSSTFSSKLKWCLRVNPKGLDSKDYLSLYLLLVSCPKEVRAKFKFSILNAKGEETKAMESQRAYRFVQGKDWGFKKFIRRGFLLDEANGLLPDDKLTLFCEVSVVQDSQTMNMVKVPECRLADELGGLWENSRFTDCCLCVAGQEFQAHKAILAARSPVFSAMFEHKNRVEINDVEPEVFKEMMCFIYTGKAPNLDKMADDLLAAADKYALERLKVMCEDALCSNLSVENAAEILILADLHSADQLKTQAVDFINYHA'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_train[Df_train.ID1.str.startswith(\"3HU6\")].seq_target.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab57963-a7cc-4b28-b250-bf5f5529f82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6IDB_A</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2WZP_D</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ZKP_A</td>\n",
       "      <td>LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6GRH_C</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8R57_M</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>4YO8_B</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>3CKI_B</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>7MHY_N</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>7MHY_P</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>6O42_H</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3949 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                           sequence  seq_len\n",
       "0     6IDB_A  DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...      317\n",
       "1     2WZP_D  VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...      122\n",
       "2     1ZKP_A  LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...      251\n",
       "3     6GRH_C  SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...      266\n",
       "4     8R57_M  DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...      118\n",
       "...      ...                                                ...      ...\n",
       "3949  4YO8_B  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...      242\n",
       "3950  3CKI_B  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...      121\n",
       "3951  7MHY_N  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...      109\n",
       "3952  7MHY_P  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...       94\n",
       "3953  6O42_H  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...      220\n",
       "\n",
       "[3949 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Df1 = Df_train[[\"target_chain\", \"seq_pdb_target\", \"pdb_target_len\"]].rename(columns = {\n",
    "    \"seq_pdb_target\" : \"sequence\",\n",
    "    \"target_chain\" : \"ID\",\n",
    "    \"pdb_target_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "train_Df2 = Df_train[[\"binder_chain\", \"seq_pdb_binder\", \"pdb_binder_len\"]].rename(columns = {\n",
    "    \"seq_pdb_binder\" : \"sequence\",\n",
    "    \"binder_chain\" : \"ID\",\n",
    "    \"pdb_binder_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "Df_train_LONG = pd.concat([train_Df1, train_Df2], axis=0, ignore_index=True).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "Df_train_LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9355a32-db3d-4962-b5b3-6c7515eb52c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1NNW_A</td>\n",
       "      <td>VYVAVLANIAGNLPALTAALSRIEEMREEGYEIEKYYILGNIVGLF...</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3UCN_A</td>\n",
       "      <td>TADLSPLLEANRKWADECAAKDSTYFSKVAGSQAPEYLYIGCADSR...</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1POV_1</td>\n",
       "      <td>QHRSRSESSIESFFARGACVTIMTVDNPASTTNKDKLFAVWKITYK...</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3R6Y_C</td>\n",
       "      <td>VRIEKDFLGEKEIPKDAYYGVQTIRATENFPITGYRIHPELIKSLG...</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5YHI_A</td>\n",
       "      <td>PMRYPVDVYTGKIQVDGELMLTELGLEGDGPDRALCHYPREHYLYW...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>3GXE_F</td>\n",
       "      <td>GLPGMKGHRGF</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>6LY5_l</td>\n",
       "      <td>ANFIKPYNDDPFVGHLATPITSSAVTRSLLKNLPAYRFGLTPLLRG...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>5MLK_B</td>\n",
       "      <td>ARISKVLVANRGEIAVRVIRAARDAGLPSVAVYAEPDAESPHVRLA...</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>8BS4_B</td>\n",
       "      <td>GHPVLEKLKAAHSYNPKEFEWNLKSGRVFIIKSYSEDDIHRSIKYS...</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>6WDS_H</td>\n",
       "      <td>VQLVESGGGLVKPGGLRLSCAASGFTFSTYIMTWVRQAPGRGLEWV...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                           sequence  seq_len\n",
       "0    1NNW_A  VYVAVLANIAGNLPALTAALSRIEEMREEGYEIEKYYILGNIVGLF...      251\n",
       "1    3UCN_A  TADLSPLLEANRKWADECAAKDSTYFSKVAGSQAPEYLYIGCADSR...      222\n",
       "2    1POV_1  QHRSRSESSIESFFARGACVTIMTVDNPASTTNKDKLFAVWKITYK...      235\n",
       "3    3R6Y_C  VRIEKDFLGEKEIPKDAYYGVQTIRATENFPITGYRIHPELIKSLG...      383\n",
       "4    5YHI_A  PMRYPVDVYTGKIQVDGELMLTELGLEGDGPDRALCHYPREHYLYW...      202\n",
       "..      ...                                                ...      ...\n",
       "983  3GXE_F                                        GLPGMKGHRGF       11\n",
       "984  6LY5_l  ANFIKPYNDDPFVGHLATPITSSAVTRSLLKNLPAYRFGLTPLLRG...      144\n",
       "985  5MLK_B  ARISKVLVANRGEIAVRVIRAARDAGLPSVAVYAEPDAESPHVRLA...      384\n",
       "986  8BS4_B  GHPVLEKLKAAHSYNPKEFEWNLKSGRVFIIKSYSEDDIHRSIKYS...      193\n",
       "987  6WDS_H  VQLVESGGGLVKPGGLRLSCAASGFTFSTYIMTWVRQAPGRGLEWV...      115\n",
       "\n",
       "[985 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Df1 = Df_test[[\"target_chain\", \"seq_pdb_target\", \"pdb_target_len\"]].rename(columns = {\n",
    "    \"seq_pdb_target\" : \"sequence\",\n",
    "    \"target_chain\" : \"ID\",\n",
    "    \"pdb_target_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "test_Df2 = Df_test[[\"binder_chain\", \"seq_pdb_binder\", \"pdb_binder_len\"]].rename(columns = {\n",
    "    \"seq_pdb_binder\" : \"sequence\",\n",
    "    \"binder_chain\" : \"ID\",\n",
    "    \"pdb_binder_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "Df_test_LONG = pd.concat([test_Df1, test_Df2], axis=0, ignore_index=True).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "Df_test_LONG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ed436-2f6a-42d8-912c-a0e9ff15b06a",
   "metadata": {},
   "source": [
    "#### Loading seqeunce, structural_embeddings & using pooled embeddings for CLIP (PPint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d15e1e2-6358-47d8-9fc5-e9e3f977566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Loading ESM2 embeddings and contacts: 100%|███████████████████████████████████████| 3949/3949 [00:11<00:00, 345.08it/s]\n",
      "#Loading ESM2 embeddings and contacts: 100%|█████████████████████████████████████████| 985/985 [00:02<00:00, 337.59it/s]\n"
     ]
    }
   ],
   "source": [
    "class CLIP_PPint_w_esmIF(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        paths,\n",
    "        embedding_dim_struct=512,\n",
    "        embedding_dim_seq=1280,\n",
    "        embedding_pad_value=-5000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim_seq = embedding_dim_seq\n",
    "        self.embedding_dim_struct = embedding_dim_struct\n",
    "        self.emb_pad = embedding_pad_value\n",
    "\n",
    "        # lengths\n",
    "        self.max_len = self.dframe[\"seq_len\"].max()+2\n",
    "\n",
    "        # paths\n",
    "        self.seq_encodings_path, self.struct_encodings_path = paths\n",
    "\n",
    "        # index & storage\n",
    "        self.dframe.set_index(\"ID\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings and contacts\"):\n",
    "\n",
    "            # laod embeddings\n",
    "            emb_struct = np.load(os.path.join(self.struct_encodings_path, f\"{accession}.npy\"))[1:-1, :] # remove EOS BOS, to use only real aa token for cos-sim\n",
    "            sequence = self.dframe.loc[accession].sequence\n",
    "\n",
    "            if len(sequence) != emb_struct.shape[0]:\n",
    "                print(sequence, emb_struct.shape[0])\n",
    "\n",
    "            if emb_struct.shape[1] != self.embedding_dim_struct:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "\n",
    "            if emb_struct.shape[0] < self.max_len:\n",
    "                emb_struct = np.concatenate([emb_struct, np.full((self.max_len - emb_struct.shape[0], emb_struct.shape[1]), self.emb_pad, dtype=emb_struct.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_struct = emb_struct[: self.max_len] # no padding was used\n",
    "\n",
    "            self.samples.append((sequence, emb_struct))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, emb_struct = self.samples[idx]\n",
    "        emb_struct = torch.from_numpy(emb_struct).float()\n",
    "        label = torch.tensor(1, dtype=torch.float32)  # single scalar labe        \n",
    "        return sequence, emb_struct, label\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        # emb_seq_list, emb_struct_list, label_list = zip(*out)\n",
    "        sequence_list, emb_struct_list, lbl_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings    \n",
    "        emb_struct_stacked  = torch.stack([torch.as_tensor(x) for x in emb_struct_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        lbl_stacked = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return list(sequence_list), emb_struct_stacked, lbl_stacked\n",
    "\n",
    "emb_seq_path = \"/work3/s232958/data/PPint_DB/embeddings_esm2\"\n",
    "emb_struct_path = \"/work3/s232958/data/PPint_DB/esmif_embeddings_noncanonical\"\n",
    "\n",
    "train_Dataset = CLIP_PPint_w_esmIF(\n",
    "    Df_train_LONG,\n",
    "    paths=[emb_seq_path, emb_struct_path],\n",
    "    embedding_dim_seq=1280,\n",
    "    embedding_dim_struct=512\n",
    ")\n",
    "\n",
    "test_Dataset = CLIP_PPint_w_esmIF(\n",
    "    Df_test_LONG,\n",
    "    paths=[emb_seq_path, emb_struct_path],\n",
    "    embedding_dim_seq=1280,\n",
    "    embedding_dim_struct=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f9021-6e1b-4dd5-a207-1f3d976d9c37",
   "metadata": {},
   "source": [
    "#### Loading seqeunce, structural_embeddings & using pooled embeddings for CLIP (meta-anlaysis dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c2f4cb1-1c4f-4a30-8d41-dca5e0704a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGFR2_124</td>\n",
       "      <td>DIVEEAHKLLSRAMSEAMENDDPDKLRRANELYFKLEEALKNNDPK...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EGFR_2_149</td>\n",
       "      <td>SEELVEKVVEEILNSDLSNDQKILETHDRLMELHDQGKISKEEYYK...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FGFR2_339</td>\n",
       "      <td>TINRVFHLHIQGDTEEARKAHEELVEEVRRWAEELAKRLNLTVRVT...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FGFR2_1234</td>\n",
       "      <td>DDLRKVERIASELAFFAAEQNDTKVAFTALELIHQLIRAIFHNDEE...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IL2Ra_48</td>\n",
       "      <td>DEEVEELEELLEKAEDPRERAKLLRELAKLIRRDPRLRELATEVVA...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>t_SARS_CoV2_RBD</td>\n",
       "      <td>TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>t_VirB8</td>\n",
       "      <td>ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>t_sntx_2</td>\n",
       "      <td>MICHNQQSSQPPTTKTCSEGQCYKKTWRDHRGTIIERGCGCPTVKP...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>t_sntx</td>\n",
       "      <td>MICYNQQSSQPPTTKTCSETSCYKKTWRDHRGTIIERGCGCPKVKP...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>t_EGFR_3</td>\n",
       "      <td>VCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYVQRNYD...</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3548 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                           sequence  \\\n",
       "0           FGFR2_124  DIVEEAHKLLSRAMSEAMENDDPDKLRRANELYFKLEEALKNNDPK...   \n",
       "1          EGFR_2_149  SEELVEKVVEEILNSDLSNDQKILETHDRLMELHDQGKISKEEYYK...   \n",
       "2           FGFR2_339  TINRVFHLHIQGDTEEARKAHEELVEEVRRWAEELAKRLNLTVRVT...   \n",
       "3          FGFR2_1234  DDLRKVERIASELAFFAAEQNDTKVAFTALELIHQLIRAIFHNDEE...   \n",
       "4            IL2Ra_48  DEEVEELEELLEKAEDPRERAKLLRELAKLIRRDPRLRELATEVVA...   \n",
       "...               ...                                                ...   \n",
       "3543  t_SARS_CoV2_RBD  TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...   \n",
       "3544          t_VirB8  ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...   \n",
       "3545         t_sntx_2  MICHNQQSSQPPTTKTCSEGQCYKKTWRDHRGTIIERGCGCPTVKP...   \n",
       "3546           t_sntx  MICYNQQSSQPPTTKTCSETSCYKKTWRDHRGTIIERGCGCPKVKP...   \n",
       "3547         t_EGFR_3  VCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYVQRNYD...   \n",
       "\n",
       "      seq_len  \n",
       "0          62  \n",
       "1          58  \n",
       "2          65  \n",
       "3          64  \n",
       "4          65  \n",
       "...       ...  \n",
       "3543      195  \n",
       "3544      138  \n",
       "3545       60  \n",
       "3546       60  \n",
       "3547      157  \n",
       "\n",
       "[3548 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.read_csv(\"/work3/s232958/data/meta_analysis/interaction_df_metaanal_w_pbd_lens.csv\").drop(columns = [\"binder_id\", \"target_id\"]).rename(columns = {\n",
    "    \"target_id_mod\" : \"target_id\",\n",
    "    \"target_binder_ID\" : \"binder_id\",\n",
    "})\n",
    "\n",
    "meta_df[\"target_id_mod\"] = [str(\"t_\"+row.target_id) for __, row in meta_df.iterrows()]\n",
    "\n",
    "# Interaction Dict\n",
    "meta_df_shuffled = meta_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "meta_df_shuffled_LONG_binder = meta_df_shuffled[[\"binder_id\", \"binder_seq\", \"seq_len_binder\"]].rename(columns = {\n",
    "    \"binder_id\" : \"ID\",\n",
    "    \"binder_seq\" : \"sequence\",\n",
    "    \"seq_len_binder\": \"seq_len\",\n",
    "})\n",
    "\n",
    "meta_df_shuffled_LONG_taget = meta_df_shuffled[[\"target_id_mod\", \"target_seq\", \"seq_len_target\"]].rename(columns = {\n",
    "    \"target_id_mod\" : \"ID\",\n",
    "    \"target_seq\" : \"sequence\",\n",
    "    \"seq_len_target\": \"seq_len\",\n",
    "}).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "\n",
    "meta_df_shuffled_LONG = pd.concat([meta_df_shuffled_LONG_binder, meta_df_shuffled_LONG_taget], axis=0, ignore_index=True)\n",
    "meta_sample_Df = meta_df_shuffled_LONG.sample(n=len(Df_test_LONG), random_state=0).reset_index(drop=True)\n",
    "meta_df_shuffled_LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf42816b-7572-41d0-9752-6c36b26bdfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Loading ESM2 embeddings and contacts: 100%|█████████████████████████████████████████| 985/985 [00:01<00:00, 611.25it/s]\n"
     ]
    }
   ],
   "source": [
    "class CLIP_Meta_w_esmIF(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        embedding_dim_struct=512,\n",
    "        embedding_dim_seq=1280,\n",
    "        embedding_pad_value=-5000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim_seq = embedding_dim_seq\n",
    "        self.embedding_dim_struct = embedding_dim_struct\n",
    "        self.emb_pad = embedding_pad_value\n",
    "\n",
    "        # lengths\n",
    "        self.max_len = self.dframe[\"seq_len\"].max()\n",
    "\n",
    "        # index & storage\n",
    "        \n",
    "        self.dframe.set_index(\"ID\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings and contacts\"):\n",
    "            \n",
    "            if accession.startswith(\"t_\"):\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_targets\"\n",
    "                \n",
    "                # emb_struct = np.load(os.path.join(esmIF_path, f\"{accession[2:]}.npy\"))\n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession[2:]}.npy\"))[1:-1, :] # remove EOS BOS, to use only real aa token for cos-sim\n",
    "                sequence = str(self.dframe.loc[accession].sequence)\n",
    "\n",
    "            else:\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "\n",
    "                # emb_struct = np.load(os.path.join(esmIF_path, f\"{accession}.npy\"))     # [Lb, D]\n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession}.npy\"))[1:-1, :] # remove EOS BOS, to use only real aa token for cos-sim\n",
    "                sequence = str(self.dframe.loc[accession].sequence)            \n",
    "\n",
    "            if len(sequence) != emb_struct.shape[0]:\n",
    "                print(str(sequence), len(sequence), emb_struct.shape[0])\n",
    "\n",
    "            if emb_struct.shape[1] != self.embedding_dim_struct:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "\n",
    "            if emb_struct.shape[0] < self.max_len:\n",
    "                emb_struct = np.concatenate([emb_struct, np.full((self.max_len - emb_struct.shape[0], emb_struct.shape[1]), self.emb_pad, dtype=emb_struct.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_struct = emb_struct[: self.max_len] # no padding was used\n",
    "\n",
    "            self.samples.append((sequence, emb_struct))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, emb_struct = self.samples[idx]\n",
    "        emb_struct = torch.from_numpy(emb_struct).float()\n",
    "        label = torch.tensor(1, dtype=torch.float32)  # single scalar labe        \n",
    "        return sequence, emb_struct, label\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        # emb_seq_list, emb_struct_list, label_list = zip(*out)\n",
    "        sequence_list, emb_struct_list, lbl_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings    \n",
    "        emb_struct_stacked  = torch.stack([torch.as_tensor(x) for x in emb_struct_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        lbl_stacked = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return list(sequence_list), emb_struct_stacked, lbl_stacked\n",
    "\n",
    "esm2_path_binders = \"/work3/s232958/data/meta_analysis/embeddings_esm2_binders\"\n",
    "esm2_path_targets = \"/work3/s232958/data/meta_analysis/embeddings_esm2_targets\"\n",
    "\n",
    "## Contact maps paths\n",
    "esmIF_path_binders = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "esmIF_path_targets = \"/work3/s232958/data/meta_analysis/esmif_embeddings_targets\"\n",
    "\n",
    "# meta_Dataset_train = CLIP_Meta_w_esmIF(\n",
    "#     meta_df_shuffled_LONG_train,\n",
    "#     embedding_dim_seq=1280,\n",
    "#     embedding_dim_struct=512\n",
    "# )\n",
    "\n",
    "meta_Dataset = CLIP_Meta_w_esmIF(\n",
    "    meta_sample_Df,\n",
    "    embedding_dim_seq=1280,\n",
    "    embedding_dim_struct=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d71f96-2474-4724-8a83-129fbe9ddf5d",
   "metadata": {},
   "source": [
    "### Contrastive Sequence-Structure Pre-training (CSSP)\n",
    "- token-lvl cos-siminilarity\n",
    "- loading seq_encoder/seq_down after 50 epochs and training longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cfd101c-a7ed-4708-afb0-ed6703649e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESM2EncoderLoRA(nn.Module):\n",
    "    def __init__(self, padding_value=-5000.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "        self.model = EsmModel.from_pretrained(\n",
    "            \"facebook/esm2_t33_650M_UR50D\",\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n",
    "        # Freeze original weights\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # LoRA on top layers\n",
    "        lora_cfg = LoraConfig(\n",
    "            task_type=\"FEATURE_EXTRACTION\",\n",
    "            inference_mode=False,\n",
    "            r=4,\n",
    "            lora_alpha=1,\n",
    "            lora_dropout=0.1,\n",
    "            bias=\"none\",\n",
    "            # target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            layers_to_transform=list(range(25, 33)),\n",
    "        )\n",
    "\n",
    "        self.model = get_peft_model(self.model, lora_cfg)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attentions(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs, output_attentions=True)\n",
    "        return out.attentions   # list[num_layers] → [B, num_heads, L, L]\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs)\n",
    "        reps = out.hidden_states[-1]                  # [B, Ltok, 1280]\n",
    "        reps = reps[:, 1:-1, :]                       # remove CLS/EOS\n",
    "\n",
    "        seq_lengths = [len(s) for s in sequences]\n",
    "        Lmax = max(seq_lengths)\n",
    "\n",
    "        B, D = reps.size(0), reps.size(-1)\n",
    "        padded = torch.full((B, Lmax, D), self.padding_value, device=reps.device)\n",
    "\n",
    "        for i, (r, real_len) in enumerate(zip(reps, seq_lengths)):\n",
    "            padded[i, :real_len] = r[:real_len]\n",
    "\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cee6ce23-8969-4fee-aae7-231abe416d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSSPBoostingESM(nn.Module):\n",
    "    def __init__(self, seq_embed_dim=1280, struct_embed_dim=512, padding_value=-5000):\n",
    "        super().__init__()\n",
    "        self.padding_value = padding_value\n",
    "        self.struct_embed_dim = 512\n",
    "        self.seq_encoder = ESM2EncoderLoRA()\n",
    "        self.seq_down = nn.Linear(seq_embed_dim, struct_embed_dim)  \n",
    "        # self.logit_scale = nn.Parameter(torch.tensor(math.log(1/0.07)))\n",
    "\n",
    "    def forward(self, sequences, struct_embed):\n",
    "    \n",
    "        # ---- encode sequence ----\n",
    "        seq_embed = self.seq_encoder(sequences)          # [B, Lseq, 1280]\n",
    "        B, Lseq, _ = seq_embed.shape\n",
    "        _, Lstr, D = struct_embed.shape                  # D = 512\n",
    "    \n",
    "        # ---- masks ----\n",
    "        seq_mask = non_padding_mask(seq_embed, self.padding_value)      # True = real\n",
    "        struct_mask = non_padding_mask(struct_embed, self.padding_value)  # True = real\n",
    "    \n",
    "        # enforce residue alignment\n",
    "        assert (\n",
    "            seq_mask.sum(dim=1).cpu().tolist()\n",
    "            == struct_mask.sum(dim=1).cpu().tolist()\n",
    "        ), \"Sequence and structure residue counts do not match\"\n",
    "    \n",
    "        # ---- project seq + pad to structure length ----\n",
    "        seq_embed_proj = torch.full(\n",
    "            (B, Lstr, D),\n",
    "            self.padding_value,\n",
    "            device=seq_embed.device,\n",
    "            dtype=seq_embed.dtype,\n",
    "        )\n",
    "    \n",
    "        for i in range(B):\n",
    "            real_seq = seq_embed[i][seq_mask[i]]     # [Li, 1280]\n",
    "            proj = self.seq_down(real_seq)            # [Li, 512]\n",
    "            seq_embed_proj[i, :proj.size(0)] = proj   # align positions\n",
    "    \n",
    "        # seq_pooled = create_mean_of_non_masked(seq_embed_proj, create_key_padding_mask(seq_embed_proj))\n",
    "        # struct_pooled = create_mean_of_non_masked(struct_embed, create_key_padding_mask(struct_embed))\n",
    "    \n",
    "        # seq_full = F.normalize(seq_pooled, dim=-1)\n",
    "        # struct_full = F.normalize(struct_pooled, dim=-1)\n",
    "    \n",
    "        # scale = torch.exp(self.logit_scale).clamp(max=100)\n",
    "        # logits_seq = scale * (seq_full @ struct_full.T)\n",
    "        # logits_struct = scale * (struct_full @ seq_full.T)\n",
    "    \n",
    "        # return logits_seq, logits_struct, seq_embed_proj, struct_embed, struct_mask\n",
    "        return seq_embed_proj, struct_embed, struct_mask\n",
    "\n",
    "    def training_step(self, batch, device):\n",
    "    \n",
    "        sequences, struct_embed, _ = batch\n",
    "        struct_embed = struct_embed.to(device)\n",
    "    \n",
    "        # logits_seq, logits_struct, seq_embed_proj, struct_embed, struct_mask = self.forward(sequences, struct_embed)\n",
    "        seq_embed_proj, struct_embed, struct_mask = self.forward(sequences, struct_embed)\n",
    "    \n",
    "        # ---- CLIP loss ----\n",
    "        # B = logits_seq.size(0)\n",
    "        # labels = torch.arange(B, device=device)\n",
    "    \n",
    "        # loss_seq = F.cross_entropy(logits_seq, labels)\n",
    "        # loss_struct = F.cross_entropy(logits_struct, labels)\n",
    "        # clip_loss = 0.5 * (loss_seq + loss_struct)\n",
    "    \n",
    "        # ---- token-level cosine loss (aligned positions) ----\n",
    "        cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Lstr]\n",
    "        cos = cos * struct_mask.float()                                   # mask padding\n",
    "    \n",
    "        per_token_loss = 1.0 - (cos.sum(dim=1) / struct_mask.sum(dim=1)).mean()\n",
    "    \n",
    "        # return clip_loss + 0.5 * per_token_loss\n",
    "        return per_token_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0ebfff-cdec-4d5f-8fba-bcb4d951ec78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seq_encoder.model.base_model.model.embeddings.word_embeddings.weight', 'seq_encoder.model.base_model.model.embeddings.position_embeddings.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.rotary_embeddings.inv_freq', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.output.dense.weight']\n",
      "['seq_encoder.model.base_model.model.embeddings.word_embeddings.weight', 'seq_encoder.model.base_model.model.embeddings.position_embeddings.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.rotary_embeddings.inv_freq', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.output.dense.weight']\n"
     ]
    }
   ],
   "source": [
    "### Loading model pre-tarined for 50 epochs\n",
    "model_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/5e338957-e280-40f1-a29f-b0c6b1551994/model_cos-sim0.5.pt\"\n",
    "model_checkpoint_dict = torch.load(model_checkpoint_path, map_location=\"cuda\")\n",
    "\n",
    "model = CSSPBoostingESM(\n",
    "    seq_embed_dim=1280,\n",
    "    struct_embed_dim=512,\n",
    "    padding_value=-5000,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(model_checkpoint_dict)\n",
    "# model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "print(list(model_checkpoint_dict.keys())[:10])\n",
    "print(list(model.state_dict().keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63c9aec4-8272-45ec-9906-08a0631d504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runID = uuid.uuid4()\n",
    "learning_rate = 2e-5\n",
    "EPOCHS = 100\n",
    "batch_size = 10\n",
    "# model = CSSPBoostingESM(seq_embed_dim=1280, struct_embed_dim=512).to(\"cuda\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "# seq_down_params = set(model.seq_down.parameters())\n",
    "# other_params = [p for p in model.parameters() if p not in seq_down_params]\n",
    "# optimizer = torch.optim.AdamW([\n",
    "#     {\"params\": other_params, \"lr\": learning_rate},\n",
    "#     {\"params\": model.seq_down.parameters(),\"lr\": 2e-5},\n",
    "# ])\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "train_dataloader = DataLoader(train_Dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_Dataset, batch_size=10, shuffle=False)\n",
    "val_dataloader = DataLoader(meta_Dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9072c55-5d54-4a1e-9e63-d11d04e0c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- token-lvl cos-siminilarity\n",
    "- train seq_down for 5 epochs and then freeze all parameters\n",
    "- train in total for 100 epochs, save model every 5 epochs and plot progress in W&B\n",
    "\"\"\"\n",
    "\n",
    "class TrainWrapper():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=model,\n",
    "        train_loader=train_dataloader,\n",
    "        test_loader=test_dataloader,\n",
    "        val_loader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        epochs=EPOCHS,\n",
    "        device=device,\n",
    "        wandb_tracker=False,\n",
    "        save_at = []\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.training_loader = train_loader\n",
    "        self.testing_loader = test_loader\n",
    "        self.validation_loader = val_loader\n",
    "        self.EPOCHS = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.wandb_tracker = wandb_tracker\n",
    "        self.save_at = set(save_at)\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "\n",
    "        self.model.train()\n",
    "        self.model.seq_encoder.train()\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        for batch in tqdm(self.training_loader, total=len(self.training_loader), desc=\"Running through epoch\"):\n",
    "\n",
    "            sequences, struct_embed, labels = batch\n",
    "            struct_embed = struct_embed.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.model.training_step((sequences, struct_embed, labels), self.device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        return running_loss / len(self.training_loader)\n",
    "    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_embeddings_cos_similariy(self, loader=None, loader_name=\"test\"):\n",
    "    \n",
    "        if loader is None:\n",
    "            loader = self.testing_loader\n",
    "    \n",
    "        self.model.eval()\n",
    "        self.model.seq_encoder.eval()\n",
    "    \n",
    "        all_embeds = []\n",
    "        cosine_similarities = []\n",
    "    \n",
    "        for batch in tqdm(loader, desc=f\"Computing cosine similarity & embeddings ({loader_name})\"):\n",
    "    \n",
    "            seqs, struct_embed, _ = batch\n",
    "            struct_embed = struct_embed.to(self.device)      # [B, Ls, 512]\n",
    "    \n",
    "            # ---- sequence embeddings ----\n",
    "            seq_embed = self.model.seq_encoder(seqs)         # [B, Lq, 1280]\n",
    "            B, Lq, _ = seq_embed.shape\n",
    "            _, Ls, Ds = struct_embed.shape\n",
    "    \n",
    "            seq_mask = non_padding_mask(seq_embed, self.model.padding_value)   # [B, Lq]\n",
    "            str_mask = non_padding_mask(struct_embed, self.model.padding_value)  # [B, Ls]\n",
    "    \n",
    "            # enforce residue-wise alignment\n",
    "            assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "    \n",
    "            # ---- project seq tokens + pad to structure length ----\n",
    "            seq_embed_proj = torch.full((B, Ls, Ds), self.model.padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "            for i in range(B):\n",
    "                real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "                proj = self.model.seq_down(real_seq)      # [Li, 512]\n",
    "                seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "    \n",
    "            # ---- token-level cosine similarity (aligned positions) ----\n",
    "            cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "            cos = cos * str_mask.float()   # mask padding\n",
    "    \n",
    "            per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "            cosine_similarities.extend(per_seq_cos.cpu().tolist())\n",
    "    \n",
    "            # ---- pooled sequence embeddings (projected space) ----\n",
    "            seq_pooled = create_mean_of_non_masked(seq_embed_proj, create_key_padding_mask(seq_embed_proj))\n",
    "            seq_full = F.normalize(seq_pooled, dim=-1)\n",
    "            all_embeds.append(seq_full.cpu())\n",
    "    \n",
    "        all_embeds = torch.cat(all_embeds, dim=0)\n",
    "    \n",
    "        avg_cos = float(np.mean(cosine_similarities))\n",
    "        std_cos = float(np.std(cosine_similarities))\n",
    "    \n",
    "        return all_embeds, cosine_similarities, avg_cos, std_cos\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval_train_loss(self):\n",
    "        self.model.eval()\n",
    "        running = 0.0\n",
    "        for sequences, struct_embed, labels in tqdm(self.training_loader, total=len(self.training_loader), desc=f\"Computing Training Loss before training\"):\n",
    "            struct_embed = struct_embed.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            loss = self.model.training_step((sequences, struct_embed, labels), self.device)\n",
    "            running += loss.item()\n",
    "        return running / len(self.training_loader)\n",
    "\n",
    "    def plot_embeddings_drift_cos_similarity_change(self, start_embeddings, end_embeddings, cosine_similarities):\n",
    "\n",
    "        drift = (end_embeddings - start_embeddings).norm(dim=1).cpu().numpy()\n",
    "        cosine_similarities = np.array(cosine_similarities)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "        ax[0].hist(drift, bins=30, color=\"steelblue\", alpha=0.8)\n",
    "        ax[0].set_title(\"Embedding Drift per Sequence\", fontsize=8)\n",
    "        ax[0].set_xlabel(\"L2 Norm Drift\", fontsize=8)\n",
    "        ax[0].set_ylabel(\"Density\", fontsize=8)\n",
    "\n",
    "        ax[1].hist(cosine_similarities, bins=40, color=\"darkorange\", alpha=0.7, density=True)\n",
    "        ax[1].set_title(\"Cosine Similarities (ESM-2 vs ESM-IF)\", fontsize=8)\n",
    "        ax[1].set_xlabel(\"Cosine Similarity\", fontsize=8)\n",
    "        ax[1].set_ylabel(\"Density\", fontsize=8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def train_model(self, save_every: int = 5):\n",
    "    \n",
    "        run_dir = f\"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_NewLoss/5e338957-e280-40f1-a29f-b0c6b1551994\"\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "    \n",
    "        print(\"\\nTrainable parameters inside seq_encoder (LoRA layers):\")\n",
    "        for name, p in self.model.seq_encoder.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                print(\"  \", name)\n",
    "    \n",
    "        # ---- Save checkpoint BEFORE training (epoch 0) ----\n",
    "        # save_path_encoder = os.path.join(run_dir, \"seq_encoder_before_training.pt\")\n",
    "        # save_path_projhead = os.path.join(run_dir, \"seq_down_before_training.pt\")\n",
    "        # torch.save(self.model.seq_encoder.state_dict(), save_path_encoder)\n",
    "        # torch.save(self.model.seq_down.state_dict(), save_path_projhead)\n",
    "        # print(f\"Saved seq_encoder checkpoint before training -> {save_path_encoder}\")\n",
    "        # print(f\"Saved proj head checkpoint before training -> {save_path_projhead}\")\n",
    "    \n",
    "        # ---- START embeddings/cos-sim for both loaders ----\n",
    "        # print(\"Computing Loss before training:\")\n",
    "        # train_loss = self.eval_train_loss()\n",
    "        # print(f\"[TRAIN] Loss {train_loss}\")\n",
    "        \n",
    "        # print(\"\\nExtracting START embeddings & cosine similarities (val + test)...\")\n",
    "        # start_val_emb, start_val_cos, start_val_avg, start_val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "        # print(f\"[VAL]  avg cos: {start_val_avg:.4f}, std: {start_val_std:.4f}\")\n",
    "        # self.plot_embeddings_drift_cos_similarity_change(start_val_emb, start_val_emb, start_val_cos)\n",
    "    \n",
    "        # start_test_emb, start_test_cos, start_test_avg, start_test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "        # print(f\"[TEST] avg cos: {start_test_avg:.4f}, std: {start_test_std:.4f}\")\n",
    "        # # self.plot_embeddings_drift_cos_similarity_change(start_test_emb, start_test_emb, start_test_cos)\n",
    "\n",
    "        if self.wandb_tracker:\n",
    "            self.wandb_tracker.log({\n",
    "                \"train/loss\": train_loss,\n",
    "                \"val/cos_avg\": start_val_avg,\n",
    "                \"val/cos_std\": start_val_std,\n",
    "                \"test/cos_avg\": start_test_avg,\n",
    "                \"test/cos_std\": start_test_std,\n",
    "            }, step=0)\n",
    "\n",
    "        for p in self.model.seq_down.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        self.optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "        for epoch in range(1, self.EPOCHS + 1):\n",
    "        \n",
    "            train_loss = self.train_one_epoch()\n",
    "            print(f\"Epoch {epoch}: loss={train_loss:.4f}\")\n",
    "    \n",
    "            # Optional: monitor cos-sim each epoch (val + test)\n",
    "            if epoch % 10 == 0:\n",
    "                val_emb, val_cos, val_avg, val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "                print(f\"[VAL]  avg cos: {val_avg:.4f}, std: {val_std:.4f}\")\n",
    "    \n",
    "                # test_emb, test_cos, test_avg, test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "                # print(f\"[TEST] avg cos: {test_avg:.4f}, std: {test_std:.4f}\")\n",
    "    \n",
    "                # ---- Save checkpoints when ----            \n",
    "                value = round(val_avg, 2)\n",
    "                if value in self.save_at:\n",
    "                    save_path_encoder = os.path.join(run_dir, f\"seq_encoder_cos-sim{value}.pt\")\n",
    "                    save_path_projhead = os.path.join(run_dir, f\"seq_down_cos-sim{value}.pt\")\n",
    "                    save_path_model = os.path.join(run_dir, f\"model_cos-sim{value}.pt\")\n",
    "                    torch.save(self.model.state_dict(), save_path_model)\n",
    "                    torch.save(self.model.seq_encoder.state_dict(), save_path_encoder)\n",
    "                    torch.save(self.model.seq_down.state_dict(), save_path_projhead)\n",
    "                    print(f\"Saved whole model checkpoint -> {save_path_model}\")\n",
    "                    print(f\"Saved seq_encoder checkpoint -> {save_path_encoder}\")\n",
    "                    print(f\"Saved proj head checkpoint -> {save_path_projhead}\")\n",
    "                    self.save_at.remove(value)\n",
    "\n",
    "            # if self.wandb_tracker:\n",
    "            #     self.wandb_tracker.log({\n",
    "            #         \"train/loss\": train_loss,\n",
    "            #         \"val/cos_avg\": val_avg,\n",
    "            #         \"val/cos_std\": val_std,\n",
    "            #         \"test/cos_avg\": test_avg,\n",
    "            #         \"test/cos_std\": test_std,\n",
    "            #     }, step=epoch)\n",
    "\n",
    "            if len(self.save_at)==0:\n",
    "                # ---- END embeddings/cos-sim for both loaders ----\n",
    "                print(\"\\nExtracting END embeddings & cosine similarities (val + test)...\")\n",
    "                end_val_emb, end_val_cos, val_avg, val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "                print(f\"[VAL]  avg cos: {val_avg:.4f}, std: {val_std:.4f}\")\n",
    "                self.plot_embeddings_drift_cos_similarity_change(start_val_emb, end_val_emb, end_val_cos)\n",
    "        \n",
    "                end_test_emb, end_test_cos, test_avg, test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "                print(f\"[TEST] avg cos: {test_avg:.4f}, std: {test_std:.4f}\")\n",
    "            \n",
    "                # Return test triplet like your original expectation:\n",
    "                return (start_val_emb, end_val_emb, end_val_cos), (start_test_emb, end_test_emb, end_test_cos)\n",
    "    \n",
    "        # ---- END embeddings/cos-sim for both loaders ----\n",
    "        # print(\"\\nExtracting END embeddings & cosine similarities (val + test)...\")\n",
    "        # end_val_emb, end_val_cos, val_avg, val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "        # print(f\"[VAL]  avg cos: {val_avg:.4f}, std: {val_std:.4f}\")\n",
    "        # self.plot_embeddings_drift_cos_similarity_change(start_val_emb, end_val_emb, end_val_cos)\n",
    "\n",
    "        # end_test_emb, end_test_cos, test_avg, test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "        # print(f\"[TEST] avg cos: {test_avg:.4f}, std: {test_std:.4f}\")\n",
    "    \n",
    "        # Return test triplet like your original expectation:\n",
    "        return (start_val_emb, end_val_emb, end_val_cos), (start_test_emb, end_test_emb, end_test_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34b248-273c-40b5-9bf8-6dff944745b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20260103_095155-i5cuydww</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF/runs/i5cuydww' target=\"_blank\">Freeze_seq_down_after_5_epochs_7ede97eb-283c-49ac-958a-572817416e9b</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF/runs/i5cuydww' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF/runs/i5cuydww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters inside seq_encoder (LoRA layers):\n",
      "   model.base_model.model.encoder.layer.25.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.output.dense.lora_B.default.weight\n",
      "Computing Loss before training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Training Loss before training: 100%|████████████████████████████████████████| 395/395 [04:46<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Loss 0.5060745651208902\n",
      "\n",
      "Extracting START embeddings & cosine similarities (val + test)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:35<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.4957, std: 0.0288\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:36<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4843, std: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:20<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.5065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:33<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.4968, std: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:37<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4850, std: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:25<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=0.5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:35<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.4978, std: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:43<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4857, std: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:47<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss=0.5051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:35<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.4983, std: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:42<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4863, std: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:52<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: loss=0.5044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:36<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.4982, std: 0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:41<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4870, std: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:44<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: loss=0.5037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:35<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.4996, std: 0.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:41<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4877, std: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:51<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: loss=0.5031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:35<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.4995, std: 0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:41<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4883, std: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:50<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: loss=0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:35<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5001, std: 0.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:42<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4890, std: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:51<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: loss=0.5018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:33<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5016, std: 0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:42<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4896, std: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:47<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: loss=0.5011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:35<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5015, std: 0.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:41<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4902, std: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:48<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: loss=0.5005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:35<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5029, std: 0.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:41<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4908, std: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:45<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: loss=0.4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:35<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5041, std: 0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:42<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4914, std: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [12:26<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: loss=0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:56<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5048, std: 0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:51<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4919, std: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [08:53<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: loss=0.4987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:34<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5037, std: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:42<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4924, std: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [05:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: loss=0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5061, std: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4930, std: 0.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:35<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: loss=0.4976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5061, std: 0.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4935, std: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: loss=0.4971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5068, std: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4941, std: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:40<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: loss=0.4965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5076, std: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4945, std: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: loss=0.4960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5086, std: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4951, std: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: loss=0.4955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5094, std: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4955, std: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:39<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: loss=0.4950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5089, std: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4961, std: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: loss=0.4944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5089, std: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4965, std: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: loss=0.4939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5102, std: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4971, std: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:39<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: loss=0.4935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5109, std: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4975, std: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:40<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: loss=0.4930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5113, std: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4980, std: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: loss=0.4925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5119, std: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4984, std: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: loss=0.4920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5126, std: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4989, std: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: loss=0.4916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5132, std: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4993, std: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: loss=0.4911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5139, std: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.4998, std: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: loss=0.4906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5141, std: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.5002, std: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:39<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: loss=0.4902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5144, std: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.5006, std: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:40<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: loss=0.4898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5149, std: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.5011, std: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: loss=0.4893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5152, std: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.5014, std: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:40<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: loss=0.4889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5150, std: 0.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.5018, std: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:45<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: loss=0.4885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:40<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5148, std: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:14<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.5021, std: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: loss=0.4881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5168, std: 0.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.5027, std: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: loss=0.4876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.5167, std: 0.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.5031, std: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch:  35%|████████████████████                                      | 137/395 [01:37<02:57,  1.46it/s]"
     ]
    }
   ],
   "source": [
    "### wandb\n",
    "if use_wandb:\n",
    "    run = wandb.init(\n",
    "        project=\"Boosting_ESM_2_w_ESM_IF\",\n",
    "        name=f\"Freeze_seq_down_after_5_epochs_{runID}\",\n",
    "        config={\"learning_rate\": learning_rate, \n",
    "                \"batch_size\": batch_size, \n",
    "                \"epochs\": EPOCHS,\n",
    "                \"architecture\": \"MiniCLIP_w_transformer_crossattn\", \n",
    "                \"dataset\": \n",
    "                \"PPint\"},\n",
    "    )\n",
    "    wandb.watch(accelerator.unwrap_model(model), log=\"all\", log_freq=100)\n",
    "else:\n",
    "    run = None\n",
    "\n",
    "# accelerator\n",
    "model, optimizer, train_dataloader, test_dataloader, val_dataloader = accelerator.prepare(model, optimizer, train_dataloader, test_dataloader, val_dataloader)\n",
    "\n",
    "training_wrapper = TrainWrapper(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    test_loader=test_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=EPOCHS,\n",
    "    device=device,\n",
    "    wandb_tracker=False,\n",
    "    save_at = [0.55, 0.60]\n",
    "    # save_at = [0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50]\n",
    ")\n",
    "\n",
    "val_params, test_params = training_wrapper.train_model(save_every=[60, 70, 80, 90, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5a908-af2d-4029-8319-9fb40f8d5f0d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc18de4-01c3-4749-b67d-b5dff72cc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(\"/work3/s232958/data/meta_analysis/interaction_df_metaanal_w_pbd_lens.csv\").drop(columns = [\"binder_id\", \"target_id\"]).rename(columns = {\n",
    "    \"target_id_mod\" : \"target_id\",\n",
    "    \"target_binder_ID\" : \"binder_id\",\n",
    "})\n",
    "\n",
    "meta_df[\"target_id_mod\"] = [str(\"t_\"+row.target_id) for __, row in meta_df.iterrows()]\n",
    "\n",
    "# Interaction Dict\n",
    "meta_df_shuffled = meta_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "meta_df_shuffled_LONG_binder = meta_df_shuffled[[\"binder_id\", \"binder_seq\", \"seq_len_binder\"]].rename(columns = {\n",
    "    \"binder_id\" : \"ID\",\n",
    "    \"binder_seq\" : \"sequence\",\n",
    "    \"seq_len_binder\": \"seq_len\",\n",
    "})\n",
    "\n",
    "meta_df_shuffled_LONG_taget = meta_df_shuffled[[\"target_id_mod\", \"target_seq\", \"seq_len_target\"]].rename(columns = {\n",
    "    \"target_id_mod\" : \"ID\",\n",
    "    \"target_seq\" : \"sequence\",\n",
    "    \"seq_len_target\": \"seq_len\",\n",
    "}).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "\n",
    "meta_df_shuffled_LONG = pd.concat([meta_df_shuffled_LONG_binder, meta_df_shuffled_LONG_taget], axis=0, ignore_index=True)\n",
    "meta_df_shuffled_LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f71035-c096-4bcb-ba16-b8eb70424ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESM2EncoderLoRA(nn.Module):\n",
    "    def __init__(self, padding_value=-5000.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "        self.model = EsmModel.from_pretrained(\n",
    "            \"facebook/esm2_t33_650M_UR50D\",\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n",
    "        # Freeze original weights\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # LoRA on top layers\n",
    "        lora_cfg = LoraConfig(\n",
    "            task_type=\"FEATURE_EXTRACTION\",\n",
    "            inference_mode=False,\n",
    "            r=4,\n",
    "            lora_alpha=1,\n",
    "            lora_dropout=0.1,\n",
    "            bias=\"none\",\n",
    "            # target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            layers_to_transform=list(range(25, 33)),\n",
    "        )\n",
    "\n",
    "        self.model = get_peft_model(self.model, lora_cfg)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attentions(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs, output_attentions=True)\n",
    "        return out.attentions   # list[num_layers] → [B, num_heads, L, L]\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs)\n",
    "        reps = out.hidden_states[-1]                  # [B, Ltok, 1280]\n",
    "        reps = reps[:, 1:-1, :]                       # remove CLS/EOS\n",
    "\n",
    "        seq_lengths = [len(s) for s in sequences]\n",
    "        Lmax = max(seq_lengths)\n",
    "\n",
    "        B, D = reps.size(0), reps.size(-1)\n",
    "        padded = torch.full((B, Lmax, D), self.padding_value, device=reps.device)\n",
    "\n",
    "        for i, (r, real_len) in enumerate(zip(reps, seq_lengths)):\n",
    "            padded[i, :real_len] = r[:real_len]\n",
    "\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500eb040-da96-416e-9dba-6bf91914e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIP_PPint_w_esmIF(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        paths,\n",
    "        embedding_dim_struct=512,\n",
    "        embedding_dim_seq=1280,\n",
    "        embedding_pad_value=-5000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim_seq = embedding_dim_seq\n",
    "        self.embedding_dim_struct = embedding_dim_struct\n",
    "        self.emb_pad = embedding_pad_value\n",
    "\n",
    "        # lengths\n",
    "        self.seq_len = self.dframe[\"seq_len\"].max()\n",
    "\n",
    "        # index & storage\n",
    "        self.dframe.set_index(\"ID\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings and contacts\"):\n",
    "\n",
    "            # laod embeddings\n",
    "            if accession.startswith(\"t_\"):\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_targets\"\n",
    "                esm2_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_targets\"\n",
    "               \n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession[2:]}.npy\"))[1:-1, :]\n",
    "                emb_seq = np.load(os.path.join(esm2_path, f\"{accession[2:]}.npy\"))[1:-1, :]\n",
    "                sequence = str(self.dframe.loc[accession].sequence)\n",
    "\n",
    "                assert (emb_struct.shape[0]== emb_seq.shape[0] == len(sequence))\n",
    "\n",
    "            else:\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "                esm2_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_binders\"\n",
    "\n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession}.npy\"))[1:-1, :]\n",
    "                emb_seq = np.load(os.path.join(esm2_path, f\"{accession}.npy\"))[1:-1, :] \n",
    "                sequence = str(self.dframe.loc[accession].sequence)\n",
    "\n",
    "                # print(emb_struct.shape, emb_seq.shape)\n",
    "                assert (emb_struct.shape[0]== emb_seq.shape[0] == len(sequence))\n",
    "\n",
    "            # quich check whether embedding dimmension is as it suppose to be\n",
    "            if emb_seq.shape[1] != self.embedding_dim_seq:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim_seq'.\")\n",
    "            if emb_struct.shape[1] != self.embedding_dim_struct:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "                \n",
    "            # add -5000 to all the padded target rows\n",
    "            if emb_seq.shape[0] < self.seq_len:\n",
    "                emb_seq = np.concatenate([emb_seq, np.full((self.seq_len - emb_seq.shape[0], emb_seq.shape[1]), self.emb_pad, dtype=emb_seq.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_seq = emb_seq[: self.seq_len] # no padding was usedd\n",
    "\n",
    "            if emb_struct.shape[0] < self.seq_len:\n",
    "                emb_struct = np.concatenate([emb_struct, np.full((self.seq_len - emb_struct.shape[0], emb_struct.shape[1]), self.emb_pad, dtype=emb_struct.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_struct = emb_struct[: self.seq_len] # no padding was used\n",
    "\n",
    "            self.samples.append((emb_seq, sequence, emb_struct))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb_seq, seq, emb_struct = self.samples[idx]\n",
    "        emb_seq, emb_struct = torch.from_numpy(emb_seq).float(), torch.from_numpy(emb_struct).float()\n",
    "        # label = torch.tensor(1, dtype=torch.float32)  # single scalar labe\n",
    "        return emb_seq, seq, emb_struct\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        # emb_seq_list, emb_struct_list, label_list = zip(*out)\n",
    "        emb_seq_list, seqs_list, emb_struct_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings\n",
    "        emb_seq_stacked  = torch.stack([torch.as_tensor(x) for x in emb_seq_list],  dim=0)  # [B, ...]        \n",
    "        emb_struct_stacked  = torch.stack([torch.as_tensor(x) for x in emb_struct_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        # labels = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return emb_seq_stacked, seqs_list, emb_struct_stacked\n",
    "\n",
    "emb_seq_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_binders\"\n",
    "emb_struct_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "\n",
    "meta_Dataset = CLIP_PPint_w_esmIF(\n",
    "    meta_df_shuffled_LONG,\n",
    "    paths=[emb_seq_path, emb_struct_path],\n",
    "    embedding_dim_seq=1280,\n",
    "    embedding_dim_struct=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21333b2d-5dd8-4455-bf85-7329f1310f3e",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44f545-4476-4782-b9e9-747a8ba862da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 1 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_1.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_1.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1280, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca76ebd-44d4-4e39-bd14-a703cd47e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading original embeddings and RANDOM projection head\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "original_embeds_random_head = []\n",
    "seq_proj = nn.Linear(1280, 512).to(\"cuda\")\n",
    "padding_value = -5000.0\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    seq_embed, seqs_list, struct_embed = batch\n",
    "    seq_embed, struct_embed = seq_embed.to(device), struct_embed.to(device)\n",
    "\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        # proj = model.seq_down(real_seq)      # [Li, 512]\n",
    "        proj = seq_proj(real_seq)\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    original_embeds_random_head.extend(per_seq_cos.cpu().tolist())\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(original_embeds_random_head, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similarities original ESM-2 embeddings/random proj_head vs ESM-IF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c415d-b9f6-4563-9a13-787ea1de5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading original embeddings and PRE-TRAINED projection head\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "original_embeds_pretrained_head_ep1 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    seq_embed, seqs_list, struct_embed = batch\n",
    "    seq_embed, struct_embed = seq_embed.to(device), struct_embed.to(device)\n",
    "\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        # proj = seq_proj(real_seq)\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    original_embeds_pretrained_head_ep1.extend(per_seq_cos.cpu().tolist())\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(original_embeds_pretrained_head_ep1, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similarities original ESM-2 embeddings/pre-trained proj_head vs ESM-IF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e3647-8445-483e-af10-7c43815e33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep1 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep1.extend(per_seq_cos.cpu().tolist())\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep1, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 1)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c027063-6b79-44d1-ac3b-bdae006bb2a4",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d98b2c-b10e-4607-a3fd-be6453bd14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 5 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_5.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_5.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1280, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc13145-22b7-4b18-8ad1-4f6be4cfcf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep5 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep5.extend(per_seq_cos.cpu().tolist())\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep5, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 5)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d435f0c-890c-4355-8013-5837d35b347b",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d6682-82a4-483f-a891-98e8c126a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 50 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_50.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "# seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_50.pt\"\n",
    "# seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "# seq_down = nn.Linear(1280, 512)\n",
    "# seq_down.load_state_dict(seq_down_state_dict)\n",
    "# seq_down.to(device)\n",
    "# # seq_down.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_5.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1280, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0b655-da3e-49b1-8096-dade7ed5f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep50 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep50.extend(per_seq_cos.cpu().tolist())\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep50, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 50)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688cca7-6bd8-46a6-82e4-62e12d5f5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.hist(original_embeds_random_head, bins=50, alpha=0.5,\n",
    "         label=\"Original ESM-2 embeds/ random proj_head\", density=True)\n",
    "\n",
    "# plt.hist(original_embeds_pretrained_head_ep1, bins=50, alpha=0.5,\n",
    "#          label=\"Original embeds (pretrained head)\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep1, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 1 \", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep5, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 5 \", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep50, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 50\", density=True)\n",
    "\n",
    "plt.xlabel(\"Cosine similarity\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cos-sim SM-2 vs ESM-IF (proj head frozen after epoch 5)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESM CUDA Env",
   "language": "python",
   "name": "esm_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
