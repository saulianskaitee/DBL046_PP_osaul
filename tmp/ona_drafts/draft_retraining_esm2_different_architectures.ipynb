{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f838074-e829-40d5-9b15-949a9bfe9708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import uuid, sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import torch\n",
    "torch.cuda.set_device(0)  # 0 == \"first visible\" -> actually GPU 2 on the node\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import AdamW\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from accelerate import Accelerator\n",
    "torch.cuda.empty_cache()\n",
    "import training_utils.partitioning_utils as pat_utils\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2318b4f4-87e8-46d5-9a0b-88e789db1aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /zhome/c9/0/203261/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms232958\u001b[0m (\u001b[33ms232958-danmarks-tekniske-universitet-dtu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get(\"https://api.wandb.ai/status\").status_code\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"f8a6d759fe657b095d56bddbdb4d586dfaebd468\", relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a771b897-1647-4594-b648-41d2639d5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting a seed to have the same initiation of weights\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    # Python & NumPy\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "\n",
    "    # CuDNN settings (for convolution etc.)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # (Optional) for some Python hashing randomness\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "SEED = 0\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ceffc5-ad46-4e77-aee2-49d4743bd362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1+cu128\n",
      "Using device: cuda\n",
      "Current location: /zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts\")\n",
    "# print(os.getcwd())\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print(\"Current location:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfc6c69-e492-4bf1-a23e-e8ee41a27d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "memory_verbose = False\n",
    "use_wandb = True # Used to track loss in real-time without printing\n",
    "model_save_steps = 3\n",
    "train_frac = 1.0\n",
    "test_frac = 1.0\n",
    "\n",
    "embedding_dimension = 1280 #| 960 | 1152\n",
    "number_of_recycles = 2\n",
    "padding_value = -5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b152a01f-a72c-4d75-9e1c-6b6f937515eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory:  34.072559616\n",
      "Reserved memory:  0.0\n",
      "Allocated memory:  0.0\n",
      "Free memory:  0.0\n"
     ]
    }
   ],
   "source": [
    "# ## Training variables\n",
    "runID = uuid.uuid4()\n",
    "\n",
    "## Output path\n",
    "# trained_model_dir = f\"/work3/s232958/data/trained/original_architecture/{runID}\"\n",
    "\n",
    "def print_mem_consumption():\n",
    "    # 1. Total memory available on the GPU (device 0)\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    # 2. How much memory PyTorch has *reserved* from CUDA\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    # 3. How much of that reserved memory is actually *used* by tensors\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    # 4. Reserved but not currently allocated (so “free inside PyTorch’s pool”)\n",
    "    f = r - a\n",
    "\n",
    "    print(\"Total memory: \", t/1e9)      # total VRAM in GB\n",
    "    print(\"Reserved memory: \", r/1e9)   # PyTorch’s reserved pool in GB\n",
    "    print(\"Allocated memory: \", a//1e9) # actually in use (integer division)\n",
    "    print(\"Free memory: \", f/1e9)       # slack in the reserved pool in GB\n",
    "print_mem_consumption()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a54147-26d3-4e49-b87a-b05209b00a7d",
   "metadata": {},
   "source": [
    "### Loading PPint dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "357bf69f-44b9-4b90-b4d7-05f5bbe0cbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interface_id</th>\n",
       "      <th>PDB</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>seq_target</th>\n",
       "      <th>seq_target_len</th>\n",
       "      <th>seq_pdb_target</th>\n",
       "      <th>pdb_target_len</th>\n",
       "      <th>target_chain</th>\n",
       "      <th>seq_binder</th>\n",
       "      <th>seq_binder_len</th>\n",
       "      <th>seq_pdb_binder</th>\n",
       "      <th>pdb_binder_len</th>\n",
       "      <th>binder_chain</th>\n",
       "      <th>pdb_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6IDB_0</td>\n",
       "      <td>6IDB</td>\n",
       "      <td>6IDB_0_A</td>\n",
       "      <td>6IDB_0_B</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "      <td>A</td>\n",
       "      <td>GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...</td>\n",
       "      <td>172</td>\n",
       "      <td>GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...</td>\n",
       "      <td>172</td>\n",
       "      <td>B</td>\n",
       "      <td>6idb.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2WZP_3</td>\n",
       "      <td>2WZP</td>\n",
       "      <td>2WZP_3_D</td>\n",
       "      <td>2WZP_3_G</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "      <td>D</td>\n",
       "      <td>TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...</td>\n",
       "      <td>266</td>\n",
       "      <td>TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...</td>\n",
       "      <td>266</td>\n",
       "      <td>G</td>\n",
       "      <td>2wzp.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ZKP_0</td>\n",
       "      <td>1ZKP</td>\n",
       "      <td>1ZKP_0_A</td>\n",
       "      <td>1ZKP_0_C</td>\n",
       "      <td>LYFQSNAKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLA...</td>\n",
       "      <td>246</td>\n",
       "      <td>LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...</td>\n",
       "      <td>251</td>\n",
       "      <td>A</td>\n",
       "      <td>AKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQKYI...</td>\n",
       "      <td>240</td>\n",
       "      <td>AMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQK...</td>\n",
       "      <td>245</td>\n",
       "      <td>C</td>\n",
       "      <td>1zkp.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6GRH_3</td>\n",
       "      <td>6GRH</td>\n",
       "      <td>6GRH_3_C</td>\n",
       "      <td>6GRH_3_D</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "      <td>C</td>\n",
       "      <td>MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...</td>\n",
       "      <td>396</td>\n",
       "      <td>MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...</td>\n",
       "      <td>396</td>\n",
       "      <td>D</td>\n",
       "      <td>6grh.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8R57_1</td>\n",
       "      <td>8R57</td>\n",
       "      <td>8R57_1_M</td>\n",
       "      <td>8R57_1_f</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "      <td>M</td>\n",
       "      <td>PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...</td>\n",
       "      <td>64</td>\n",
       "      <td>PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...</td>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>8r57.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>4YO8_0</td>\n",
       "      <td>4YO8</td>\n",
       "      <td>4YO8_0_A</td>\n",
       "      <td>4YO8_0_B</td>\n",
       "      <td>HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...</td>\n",
       "      <td>238</td>\n",
       "      <td>HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...</td>\n",
       "      <td>238</td>\n",
       "      <td>A</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "      <td>B</td>\n",
       "      <td>4yo8.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>3CKI_0</td>\n",
       "      <td>3CKI</td>\n",
       "      <td>3CKI_0_A</td>\n",
       "      <td>3CKI_0_B</td>\n",
       "      <td>DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...</td>\n",
       "      <td>256</td>\n",
       "      <td>DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...</td>\n",
       "      <td>256</td>\n",
       "      <td>A</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "      <td>B</td>\n",
       "      <td>3cki.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>7MHY_1</td>\n",
       "      <td>7MHY</td>\n",
       "      <td>7MHY_1_M</td>\n",
       "      <td>7MHY_1_N</td>\n",
       "      <td>QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...</td>\n",
       "      <td>118</td>\n",
       "      <td>QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...</td>\n",
       "      <td>118</td>\n",
       "      <td>M</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "      <td>N</td>\n",
       "      <td>7mhy.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>7MHY_2</td>\n",
       "      <td>7MHY</td>\n",
       "      <td>7MHY_2_O</td>\n",
       "      <td>7MHY_2_P</td>\n",
       "      <td>IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...</td>\n",
       "      <td>100</td>\n",
       "      <td>IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...</td>\n",
       "      <td>100</td>\n",
       "      <td>O</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "      <td>P</td>\n",
       "      <td>7mhy.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>6O42_0</td>\n",
       "      <td>6O42</td>\n",
       "      <td>6O42_0_L</td>\n",
       "      <td>6O42_0_H</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>214</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>214</td>\n",
       "      <td>L</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "      <td>H</td>\n",
       "      <td>6o42.pdb.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1977 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     interface_id   PDB       ID1       ID2  \\\n",
       "0          6IDB_0  6IDB  6IDB_0_A  6IDB_0_B   \n",
       "1          2WZP_3  2WZP  2WZP_3_D  2WZP_3_G   \n",
       "2          1ZKP_0  1ZKP  1ZKP_0_A  1ZKP_0_C   \n",
       "3          6GRH_3  6GRH  6GRH_3_C  6GRH_3_D   \n",
       "4          8R57_1  8R57  8R57_1_M  8R57_1_f   \n",
       "...           ...   ...       ...       ...   \n",
       "1972       4YO8_0  4YO8  4YO8_0_A  4YO8_0_B   \n",
       "1973       3CKI_0  3CKI  3CKI_0_A  3CKI_0_B   \n",
       "1974       7MHY_1  7MHY  7MHY_1_M  7MHY_1_N   \n",
       "1975       7MHY_2  7MHY  7MHY_2_O  7MHY_2_P   \n",
       "1976       6O42_0  6O42  6O42_0_L  6O42_0_H   \n",
       "\n",
       "                                             seq_target  seq_target_len  \\\n",
       "0     DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...             317   \n",
       "1     VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...             122   \n",
       "2     LYFQSNAKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLA...             246   \n",
       "3     SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...             266   \n",
       "4     DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...             118   \n",
       "...                                                 ...             ...   \n",
       "1972  HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...             238   \n",
       "1973  DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...             256   \n",
       "1974  QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...             118   \n",
       "1975  IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...             100   \n",
       "1976  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...             214   \n",
       "\n",
       "                                         seq_pdb_target  pdb_target_len  \\\n",
       "0     DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...             317   \n",
       "1     VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...             122   \n",
       "2     LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...             251   \n",
       "3     SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...             266   \n",
       "4     DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...             118   \n",
       "...                                                 ...             ...   \n",
       "1972  HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...             238   \n",
       "1973  DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...             256   \n",
       "1974  QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...             118   \n",
       "1975  IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...             100   \n",
       "1976  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...             214   \n",
       "\n",
       "     target_chain                                         seq_binder  \\\n",
       "0               A  GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...   \n",
       "1               D  TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...   \n",
       "2               A  AKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQKYI...   \n",
       "3               C  MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...   \n",
       "4               M  PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...   \n",
       "...           ...                                                ...   \n",
       "1972            A  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...   \n",
       "1973            A  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...   \n",
       "1974            M  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...   \n",
       "1975            O  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...   \n",
       "1976            L  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...   \n",
       "\n",
       "      seq_binder_len                                     seq_pdb_binder  \\\n",
       "0                172  GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...   \n",
       "1                266  TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...   \n",
       "2                240  AMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQK...   \n",
       "3                396  MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...   \n",
       "4                 64  PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...   \n",
       "...              ...                                                ...   \n",
       "1972             242  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...   \n",
       "1973             121  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...   \n",
       "1974             109  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...   \n",
       "1975              94  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...   \n",
       "1976             220  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...   \n",
       "\n",
       "      pdb_binder_len binder_chain     pdb_path  \n",
       "0                172            B  6idb.pdb.gz  \n",
       "1                266            G  2wzp.pdb.gz  \n",
       "2                245            C  1zkp.pdb.gz  \n",
       "3                396            D  6grh.pdb.gz  \n",
       "4                 64            f  8r57.pdb.gz  \n",
       "...              ...          ...          ...  \n",
       "1972             242            B  4yo8.pdb.gz  \n",
       "1973             121            B  3cki.pdb.gz  \n",
       "1974             109            N  7mhy.pdb.gz  \n",
       "1975              94            P  7mhy.pdb.gz  \n",
       "1976             220            H  6o42.pdb.gz  \n",
       "\n",
       "[1977 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_train = pd.read_csv(\"/work3/s232958/data/PPint_DB/PPint_train_w_pbd_lens.csv\",index_col=0).reset_index(drop=True)\n",
    "Df_test = pd.read_csv(\"/work3/s232958/data/PPint_DB/PPint_test_w_pbd_lens.csv\",index_col=0).reset_index(drop=True)\n",
    "Df_train = Df_train[~Df_train.PDB.str.startswith(\"6BJP\")]\n",
    "Df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f587290-f774-42ba-bc41-b24a0d3ac163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Loading ESM2 embeddings and contacts: 100%|████████████████████████████████████████| 1977/1977 [00:21<00:00, 93.64it/s]\n",
      "#Loading ESM2 embeddings and contacts: 100%|█████████████████████████████████████████| 494/494 [00:04<00:00, 104.67it/s]\n"
     ]
    }
   ],
   "source": [
    "class CLIP_PPint_class(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        path,\n",
    "        embedding_dim=1280,\n",
    "        embedding_pad_value=-5000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim = int(embedding_dim)\n",
    "        self.emb_pad = float(embedding_pad_value)\n",
    "\n",
    "        # lengths\n",
    "        self.max_blen = self.dframe[\"pdb_binder_len\"].max()\n",
    "        self.max_tlen = self.dframe[\"pdb_target_len\"].max()\n",
    "\n",
    "        # paths\n",
    "        self.encoding_path  = path\n",
    "\n",
    "        # index & storage\n",
    "        self.dframe.set_index(\"interface_id\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings and contacts\"):\n",
    "            tgt_id = accession.split(\"_\")[0]+\"_\"+str(self.dframe.loc[accession].target_chain)\n",
    "            bnd_id = accession.split(\"_\")[0]+\"_\"+str(self.dframe.loc[accession].binder_chain)\n",
    "\n",
    "            ### --- embeddings (pad to fixed lengths) --- ###\n",
    "            \n",
    "            # laod embeddings\n",
    "            t_emb = np.load(os.path.join(self.encoding_path, f\"{tgt_id}.npy\")) # [Lt, D]\n",
    "            b_emb = np.load(os.path.join(self.encoding_path, f\"{bnd_id}.npy\")) # [Lb, D]\n",
    "\n",
    "            # print(b_emb.shape[0], self.dframe.loc[accession].seq_binder_len)\n",
    "            # assert (b_emb.shape[0] == self.dframe.loc[accession].seq_binder_len)\n",
    "\n",
    "            # quich check whether embedding dimmension is as it suppose to be\n",
    "            if t_emb.shape[1] != self.embedding_dim or b_emb.shape[1] != self.embedding_dim:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "\n",
    "            # add -5000 to all the padded target rows\n",
    "            if t_emb.shape[0] < self.max_tlen:\n",
    "                t_emb = np.concatenate([t_emb, np.full((self.max_tlen - t_emb.shape[0], t_emb.shape[1]), self.emb_pad, dtype=t_emb.dtype)], axis=0)\n",
    "            else:\n",
    "                t_emb = t_emb[: self.max_tlen] # no padding was used\n",
    "\n",
    "            # add -5000 to all the padded binder rows\n",
    "            if b_emb.shape[0] < self.max_blen:\n",
    "                b_emb = np.concatenate([b_emb, np.full((self.max_blen - b_emb.shape[0], b_emb.shape[1]), self.emb_pad, dtype=b_emb.dtype)], axis=0)\n",
    "            else:\n",
    "                b_emb = b_emb[: self.max_blen] # no padding was used\n",
    "\n",
    "            self.samples.append((b_emb, t_emb))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        b_arr, t_arr = self.samples[idx]\n",
    "        binder_emb, target_emb = torch.from_numpy(b_arr).float(), torch.from_numpy(t_arr).float()\n",
    "        label = torch.tensor(1, dtype=torch.float32)  # single scalar labe\n",
    "        return binder_emb, target_emb, label\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        b_list, t_list, lbl_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings\n",
    "        b  = torch.stack([torch.as_tensor(x) for x in b_list],  dim=0)  # [B, ...]\n",
    "        t  = torch.stack([torch.as_tensor(x) for x in t_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        labels = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return b, t, labels\n",
    "\n",
    "emb_path = \"/work3/s232958/data/PPint_DB/embeddings_esm2\"\n",
    "\n",
    "training_Dataset = CLIP_PPint_class(\n",
    "    Df_train,\n",
    "    path=emb_path,\n",
    "    embedding_dim=1280\n",
    ")\n",
    "\n",
    "testing_Dataset = CLIP_PPint_class(\n",
    "    Df_test,\n",
    "    path=emb_path,\n",
    "    embedding_dim=1280\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "994cb2f6-9a80-457c-a1ae-3ec4e479e4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Getting indeces of non-dimers\n",
    "indices_non_dimers_val = Df_test[~Df_test[\"dimer\"]].index.tolist()\n",
    "indices_non_dimers_val[:5]\n",
    "\n",
    "### Getting accessions of non-dimers\n",
    "accessions = [Df_test.loc[index].target_binder_id for index in indices_non_dimers_val]\n",
    "emb_b, emb_t, labels = testing_Dataset._get_by_name(accessions[:5])\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c0242-7d60-4c4e-930a-d843eebcae44",
   "metadata": {},
   "source": [
    "### Loading Meta validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7079a2a1-e9d1-4202-8aa3-3beb306857ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_binder</th>\n",
       "      <th>seq_target</th>\n",
       "      <th>target_id</th>\n",
       "      <th>binder_id</th>\n",
       "      <th>binder_label</th>\n",
       "      <th>seq_target_len</th>\n",
       "      <th>seq_binder_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIVEEAHKLLSRAMSEAMENDDPDKLRRANELYFKLEEALKNNDPK...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_124</td>\n",
       "      <td>True</td>\n",
       "      <td>101</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEELVEKVVEEILNSDLSNDQKILETHDRLMELHDQGKISKEEYYK...</td>\n",
       "      <td>LEEKKVCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYV...</td>\n",
       "      <td>EGFR_2</td>\n",
       "      <td>EGFR_2_149</td>\n",
       "      <td>False</td>\n",
       "      <td>621</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TINRVFHLHIQGDTEEARKAHEELVEEVRRWAEELAKRLNLTVRVT...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_339</td>\n",
       "      <td>False</td>\n",
       "      <td>101</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDLRKVERIASELAFFAAEQNDTKVAFTALELIHQLIRAIFHNDEE...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_1234</td>\n",
       "      <td>False</td>\n",
       "      <td>101</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEEVEELEELLEKAEDPRERAKLLRELAKLIRRDPRLRELATEVVA...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_48</td>\n",
       "      <td>False</td>\n",
       "      <td>165</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>SEDELRELVKEIRKVAEKQGDKELRTLWIEAYDLLASLWYGAADEL...</td>\n",
       "      <td>TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...</td>\n",
       "      <td>SARS_CoV2_RBD</td>\n",
       "      <td>SARS_CoV2_RBD_25</td>\n",
       "      <td>False</td>\n",
       "      <td>195</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>TEEEILKMLVELTAHMAGVPDVKVEIHNGTLRVTVNGDTREARSVL...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_2027</td>\n",
       "      <td>False</td>\n",
       "      <td>101</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>VEELKEARKLVEEVLRKKGDQIAEIWKDILEELEQRYQEGKLDPEE...</td>\n",
       "      <td>DYSFSCYSQLEVNGSQHSLTCAFEDPDVNTTNLEFEICGALVEVKC...</td>\n",
       "      <td>IL7Ra</td>\n",
       "      <td>IL7Ra_90</td>\n",
       "      <td>False</td>\n",
       "      <td>193</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>DAEEEIREIVEKLNDPLLREILRLLELAKEKGDPRLEAELYLAFEK...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_1605</td>\n",
       "      <td>False</td>\n",
       "      <td>101</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>DPEEIKQRAEEIKKEFQKKGVSPEIQFAIEQVIKYALEVGLSPKDI...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_1687</td>\n",
       "      <td>True</td>\n",
       "      <td>101</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3532 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             seq_binder  \\\n",
       "0     DIVEEAHKLLSRAMSEAMENDDPDKLRRANELYFKLEEALKNNDPK...   \n",
       "1     SEELVEKVVEEILNSDLSNDQKILETHDRLMELHDQGKISKEEYYK...   \n",
       "2     TINRVFHLHIQGDTEEARKAHEELVEEVRRWAEELAKRLNLTVRVT...   \n",
       "3     DDLRKVERIASELAFFAAEQNDTKVAFTALELIHQLIRAIFHNDEE...   \n",
       "4     DEEVEELEELLEKAEDPRERAKLLRELAKLIRRDPRLRELATEVVA...   \n",
       "...                                                 ...   \n",
       "3527  SEDELRELVKEIRKVAEKQGDKELRTLWIEAYDLLASLWYGAADEL...   \n",
       "3528  TEEEILKMLVELTAHMAGVPDVKVEIHNGTLRVTVNGDTREARSVL...   \n",
       "3529  VEELKEARKLVEEVLRKKGDQIAEIWKDILEELEQRYQEGKLDPEE...   \n",
       "3530  DAEEEIREIVEKLNDPLLREILRLLELAKEKGDPRLEAELYLAFEK...   \n",
       "3531  DPEEIKQRAEEIKKEFQKKGVSPEIQFAIEQVIKYALEVGLSPKDI...   \n",
       "\n",
       "                                             seq_target      target_id  \\\n",
       "0     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...          FGFR2   \n",
       "1     LEEKKVCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYV...         EGFR_2   \n",
       "2     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...          FGFR2   \n",
       "3     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...          FGFR2   \n",
       "4     ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...          IL2Ra   \n",
       "...                                                 ...            ...   \n",
       "3527  TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...  SARS_CoV2_RBD   \n",
       "3528  RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...          FGFR2   \n",
       "3529  DYSFSCYSQLEVNGSQHSLTCAFEDPDVNTTNLEFEICGALVEVKC...          IL7Ra   \n",
       "3530  RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...          FGFR2   \n",
       "3531  RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...          FGFR2   \n",
       "\n",
       "             binder_id  binder_label  seq_target_len  seq_binder_len  \n",
       "0            FGFR2_124          True             101              62  \n",
       "1           EGFR_2_149         False             621              58  \n",
       "2            FGFR2_339         False             101              65  \n",
       "3           FGFR2_1234         False             101              64  \n",
       "4             IL2Ra_48         False             165              65  \n",
       "...                ...           ...             ...             ...  \n",
       "3527  SARS_CoV2_RBD_25         False             195              63  \n",
       "3528        FGFR2_2027         False             101              65  \n",
       "3529          IL7Ra_90         False             193              63  \n",
       "3530        FGFR2_1605         False             101              65  \n",
       "3531        FGFR2_1687          True             101              62  \n",
       "\n",
       "[3532 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_df = pd.read_csv(\"/work3/s232958/data/meta_analysis/interaction_df_metaanal.csv\")[[\"A_seq\", \"B_seq\", \"target_id_mod\", \"target_binder_ID\", \"binder\"]].rename(columns = {\n",
    "    \"A_seq\" : \"seq_binder\",\n",
    "    \"B_seq\" : \"seq_target\",\n",
    "    \"target_binder_ID\" : \"binder_id\",\n",
    "    \"target_id_mod\" : \"target_id\",\n",
    "    \"binder\" : \"binder_label\"\n",
    "})\n",
    "interaction_df[\"seq_target_len\"] = [len(seq) for seq in interaction_df[\"seq_target\"].tolist()]\n",
    "interaction_df[\"seq_binder_len\"] = [len(seq) for seq in interaction_df[\"seq_binder\"].tolist()]\n",
    "\n",
    "# Targets df\n",
    "target_df = interaction_df[[\"target_id\",\"seq_target\"]].rename(columns={\"seq_target\":\"sequence\", \"target_id\" : \"ID\"})\n",
    "target_df[\"seq_len\"] = target_df[\"sequence\"].apply(len)\n",
    "target_df = target_df.drop_duplicates(subset=[\"ID\",\"sequence\"])\n",
    "target_df = target_df.set_index(\"ID\")\n",
    "\n",
    "# Binders df\n",
    "binder_df = interaction_df[[\"binder_id\",\"seq_binder\"]].rename(columns={\"seq_binder\":\"sequence\", \"binder_id\" : \"ID\"})\n",
    "binder_df[\"seq_len\"] = binder_df[\"sequence\"].apply(len)\n",
    "binder_df = binder_df.set_index(\"ID\")\n",
    "\n",
    "# target_df\n",
    "\n",
    "# Interaction Dict\n",
    "interaction_Dict = dict(enumerate(zip(interaction_df[\"target_id\"], interaction_df[\"binder_id\"]), start=1))\n",
    "interaction_df_shuffled = interaction_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "interaction_df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f0bee0-e259-44f9-ba13-aff0ec3c7686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Loading ESM2 embeddings: 100%|██████████████████████████████████████████████████████| 494/494 [00:02<00:00, 164.71it/s]\n"
     ]
    }
   ],
   "source": [
    "class CLIP_PPint_metaanal(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        paths,\n",
    "        embedding_dim=1280,\n",
    "        embedding_pad_value=-5000.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim = int(embedding_dim)\n",
    "        self.emb_pad = float(embedding_pad_value)\n",
    "        self.max_blen = self.dframe[\"seq_binder_len\"].max()\n",
    "        self.max_tlen = self.dframe[\"seq_target_len\"].max()\n",
    "\n",
    "        # paths\n",
    "        self.encoding_bpath, self.encoding_tpath = paths\n",
    "\n",
    "        # index & storage\n",
    "        self.dframe.set_index(\"binder_id\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings\"):\n",
    "            lbl = torch.tensor(int(self.dframe.loc[accession, \"binder_label\"]))\n",
    "            parts = accession.split(\"_\") # e.g. accession 7S8T_5_F_7S8T_5_G\n",
    "            tgt_id = \"_\".join(parts[:-1])\n",
    "            bnd_id = accession\n",
    "\n",
    "            ### --- embeddings (pad to fixed lengths) --- ###\n",
    "            \n",
    "            # laod embeddings\n",
    "            t_emb = np.load(os.path.join(self.encoding_tpath, f\"{tgt_id}.npy\"))     # [Lt, D]\n",
    "            b_emb = np.load(os.path.join(self.encoding_bpath, f\"{bnd_id}.npy\"))     # [Lb, D]\n",
    "\n",
    "            # quich check whether embedding dimmension is as it suppose to be\n",
    "            if t_emb.shape[1] != self.embedding_dim or b_emb.shape[1] != self.embedding_dim:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "\n",
    "            # add -5000 to all the padded target rows\n",
    "            if t_emb.shape[0] < self.max_tlen:\n",
    "                t_emb = np.concatenate([t_emb, np.full((self.max_tlen - t_emb.shape[0], t_emb.shape[1]), self.emb_pad, dtype=t_emb.dtype)], axis=0)\n",
    "            else:\n",
    "                t_emb = t_emb[: self.max_tlen] # no padding was used\n",
    "\n",
    "            # add -5000 to all the padded binder rows\n",
    "            if b_emb.shape[0] < self.max_blen:\n",
    "                b_emb = np.concatenate([b_emb, np.full((self.max_blen - b_emb.shape[0], b_emb.shape[1]), self.emb_pad, dtype=b_emb.dtype)], axis=0)\n",
    "            else:\n",
    "                b_emb = b_emb[: self.max_blen] # no padding was used\n",
    "\n",
    "            self.samples.append((b_emb, t_emb, lbl))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        b_arr, t_arr, lbls = self.samples[idx]\n",
    "        binder_emb, target_emb = torch.from_numpy(b_arr).float(), torch.from_numpy(t_arr).float()\n",
    "        return binder_emb, target_emb, lbls\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        b_list, t_list, lbl_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings\n",
    "        b  = torch.stack([torch.as_tensor(x) for x in b_list],  dim=0)  # [B, ...]\n",
    "        t  = torch.stack([torch.as_tensor(x) for x in t_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        labels = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return b, t, labels\n",
    "\n",
    "bemb_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_binders\"\n",
    "temb_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_targets\"\n",
    "\n",
    "validation_Dataset = CLIP_PPint_metaanal(\n",
    "    interaction_df_shuffled[:len(Df_test)],\n",
    "    # interaction_df_shuffled,\n",
    "    paths=[bemb_path, temb_path],\n",
    "    embedding_dim=1280\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509c9527-c9e9-4980-b273-70d66ae5464a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accessions_Meta = list(interaction_df_shuffled.binder_id)\n",
    "emb_b, emb_t, labels = validation_Dataset._get_by_name(accessions_Meta[:5])\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce237d4-35b3-41ce-a05e-67a4ea3449a4",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365067c-759c-4cdd-bfe1-5f35b2033fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_key_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings < (padding_value + offset)).all(dim=-1)\n",
    "\n",
    "def create_mean_of_non_masked(embeddings, padding_mask):\n",
    "    # Use masked select and mean to compute the mean of non-masked elements\n",
    "    # embeddings should be of shape (batch_size, seq_len, features)\n",
    "    seq_embeddings = []\n",
    "    for i in range(embeddings.shape[0]): # looping over all batch elements\n",
    "        non_masked_embeddings = embeddings[i][~padding_mask[i]] # shape [num_real_tokens, features]\n",
    "        if len(non_masked_embeddings) == 0:\n",
    "            print(\"You are masking all positions when creating sequence representation\")\n",
    "            sys.exit(1)\n",
    "        mean_embedding = non_masked_embeddings.mean(dim=0) # sequence is represented by the single vecotr [1152] [features]\n",
    "        seq_embeddings.append(mean_embedding)\n",
    "    return torch.stack(seq_embeddings)\n",
    "\n",
    "class MiniCLIP_w_transformer_crossattn(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, padding_value = -5000, embed_dimension=embedding_dimension, num_recycles=2):\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_recycles = num_recycles # how many times you iteratively refine embeddings with self- and cross-attention (ALPHA-Fold-style recycling).\n",
    "        self.padding_value = padding_value\n",
    "        self.embed_dimension = embed_dimension\n",
    "\n",
    "        self.logit_scale = nn.Parameter(torch.tensor(math.log(1/0.07)))  # ~CLIP init\n",
    "\n",
    "        self.transformerencoder =  nn.TransformerEncoderLayer(\n",
    "            d_model=self.embed_dimension,\n",
    "            nhead=8,\n",
    "            dropout=0.1,\n",
    "            batch_first=True,\n",
    "            dim_feedforward=self.embed_dimension\n",
    "            )\n",
    " \n",
    "        self.norm = nn.LayerNorm(self.embed_dimension)  # For residual additions\n",
    "\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=self.embed_dimension,\n",
    "            num_heads=8,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.prot_embedder = nn.Sequential(\n",
    "            nn.Linear(self.embed_dimension, 640),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(640, 320),\n",
    "        )\n",
    "        \n",
    "    def forward(self, pep_input, prot_input, label=None, pep_int_mask=None, prot_int_mask=None, int_prob=None, mem_save=True): # , pep_tokens, prot_tokens\n",
    "\n",
    "        pep_mask = create_key_padding_mask(embeddings=pep_input, padding_value=self.padding_value)\n",
    "        prot_mask = create_key_padding_mask(embeddings=prot_input, padding_value=self.padding_value)\n",
    " \n",
    "        # Initialize residual states\n",
    "        pep_emb = pep_input.clone()\n",
    "        prot_emb = prot_input.clone()\n",
    " \n",
    "        for _ in range(self.num_recycles):\n",
    "\n",
    "            # Transformer encoding with residual\n",
    "            pep_trans = self.transformerencoder(self.norm(pep_emb), src_key_padding_mask=pep_mask)\n",
    "            prot_trans = self.transformerencoder(self.norm(prot_emb), src_key_padding_mask=prot_mask)\n",
    "\n",
    "            # Cross-attention with residual\n",
    "            pep_cross, _ = self.cross_attn(query=self.norm(pep_trans), key=self.norm(prot_trans), value=self.norm(prot_trans), key_padding_mask=prot_mask)\n",
    "            prot_cross, _ = self.cross_attn(query=self.norm(prot_trans), key=self.norm(pep_trans), value=self.norm(pep_trans), key_padding_mask=pep_mask)\n",
    "            \n",
    "            # Additive update with residual connection\n",
    "            pep_emb = pep_emb + pep_cross  \n",
    "            prot_emb = prot_emb + prot_cross\n",
    "\n",
    "        pep_seq_coding = create_mean_of_non_masked(pep_emb, pep_mask)\n",
    "        prot_seq_coding = create_mean_of_non_masked(prot_emb, prot_mask)\n",
    "        \n",
    "        # Use self-attention outputs for embeddings\n",
    "        pep_seq_coding = F.normalize(self.prot_embedder(pep_seq_coding), dim=-1)\n",
    "        prot_seq_coding = F.normalize(self.prot_embedder(prot_seq_coding), dim=-1)\n",
    " \n",
    "        if mem_save:\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        scale = torch.exp(self.logit_scale).clamp(max=100.0)\n",
    "        logits = scale * (pep_seq_coding * prot_seq_coding).sum(dim=-1)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "    # def training_step(self, batch, device):\n",
    "    #     embedding_pep, embedding_prot, labels = batch\n",
    "    #     embedding_pep, embedding_prot = embedding_pep.to(device), embedding_prot.to(device)\n",
    "        \n",
    "    #     positive_logits = self.forward(embedding_pep, embedding_prot)\n",
    "        \n",
    "    #     # Negative indexes\n",
    "    #     rows, cols = torch.triu_indices(embedding_prot.size(0), embedding_prot.size(0), offset=1)         \n",
    "        \n",
    "    #     negative_logits = self(embedding_pep[rows,:,:], \n",
    "    #                       embedding_prot[cols,:,:], \n",
    "    #                       int_prob=0.0)\n",
    "\n",
    "    #     # loss of predicting partner using peptide\n",
    "    #     positive_loss = F.binary_cross_entropy_with_logits(positive_logits, torch.ones_like(positive_logits).to(device))\n",
    " \n",
    "    #     # loss of predicting peptide using partner\n",
    "    #     negative_loss =  F.binary_cross_entropy_with_logits(negative_logits, torch.zeros_like(negative_logits).to(device))\n",
    "        \n",
    "    #     loss = (positive_loss + negative_loss) / 2\n",
    " \n",
    "    #     # del partner_prediction_loss, peptide_prediction_loss, embedding_pep, embedding_prot\n",
    "    #     torch.cuda.empty_cache()\n",
    "    #     return loss\n",
    "\n",
    "    def training_step_CLIP_Loss(self, batch, device):\n",
    "        \n",
    "        embedding_pep, embedding_prot, labels = batch\n",
    "        \n",
    "        logits = self.forward(embedding_pep.to(device), embedding_prot.to(device))\n",
    "\n",
    "        labels = np.arange(n)\n",
    "        loss_i = cross_entropy_loss(logits, labels, axis=0)\n",
    "        loss_t = cross_entropy_loss(logits, labels, axis=1)\n",
    "        loss = (loss_i + loss_t)/2\n",
    "        \n",
    "        # Negative indexes\n",
    "        rows, cols = torch.triu_indices(embedding_prot.size(0), embedding_prot.size(0), offset=1)         \n",
    "        \n",
    "        negative_logits = self(embedding_pep[rows,:,:], embedding_prot[cols,:,:], int_prob=0.0)\n",
    "\n",
    "        # loss of predicting partner using peptide\n",
    "        positive_loss = F.binary_cross_entropy_with_logits(positive_logits, torch.ones_like(positive_logits).to(device))\n",
    " \n",
    "        # loss of predicting peptide using partner\n",
    "        negative_loss =  F.binary_cross_entropy_with_logits(negative_logits, torch.zeros_like(negative_logits).to(device))\n",
    "        \n",
    "        loss = (positive_loss + negative_loss) / 2\n",
    " \n",
    "        # del partner_prediction_loss, peptide_prediction_loss, embedding_pep, embedding_prot\n",
    "        torch.cuda.empty_cache()\n",
    "        return loss\n",
    "\n",
    "    def validation_step_PPint(self, batch, device):\n",
    "        # Predict on random batches of training batch size\n",
    "        embedding_pep, embedding_prot, labels = batch\n",
    "        embedding_pep, embedding_prot = embedding_pep.to(device), embedding_prot.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            positive_logits = self(embedding_pep, embedding_prot)\n",
    "            \n",
    "            # loss of predicting partner using peptide\n",
    "            positive_loss = F.binary_cross_entropy_with_logits(positive_logits, torch.ones_like(positive_logits).to(device))\n",
    "            \n",
    "            # Negaive indexes\n",
    "            rows, cols = torch.triu_indices(embedding_prot.size(0), embedding_prot.size(0), offset=1)\n",
    "            \n",
    "            negative_logits = self(embedding_pep[rows,:,:], embedding_prot[cols,:,:], int_prob=0.0)\n",
    "    \n",
    "            negative_loss =  F.binary_cross_entropy_with_logits(negative_logits, torch.zeros_like(negative_logits).to(device))\n",
    "\n",
    "            loss = (positive_loss + negative_loss) / 2\n",
    "           \n",
    "            logit_matrix = torch.zeros((embedding_pep.size(0),embedding_pep.size(0)),device=self.device)\n",
    "            logit_matrix[rows, cols] = negative_logits\n",
    "            logit_matrix[cols, rows] = negative_logits\n",
    "            \n",
    "            # Fill diagonal with positive scores\n",
    "            diag_indices = torch.arange(embedding_pep.size(0), device=self.device)\n",
    "            logit_matrix[diag_indices, diag_indices] = positive_logits.squeeze()\n",
    "\n",
    "            labels = torch.arange(embedding_prot.size(0)).to(self.device)\n",
    "            peptide_predictions = logit_matrix.argmax(dim=0)\n",
    "            peptide_ranks = logit_matrix.argsort(dim=0).diag() + 1\n",
    "            peptide_mrr = (peptide_ranks).float().pow(-1).mean()\n",
    "            \n",
    "            # partner_accuracy = partner_predictions.eq(labels).float().mean()\n",
    "            peptide_accuracy = peptide_predictions.eq(labels).float().mean()\n",
    "    \n",
    "            k = 3\n",
    "            peptide_topk_accuracy = torch.any((logit_matrix.topk(k, dim=0).indices - labels.reshape(1, -1)) == 0, dim=0).sum() / logit_matrix.shape[0]\n",
    "    \n",
    "            del logit_matrix,positive_logits,negative_logits,embedding_pep,embedding_prot\n",
    "\n",
    "            return loss, peptide_accuracy, peptide_topk_accuracy\n",
    "    \n",
    "    def validation_step_MetaDataset(self, batch, device):\n",
    "        embedding_binder, embedding_target, labels = batch\n",
    "        embedding_binder = embedding_binder.to(device)\n",
    "        embedding_target = embedding_target.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(embedding_binder, embedding_target)\n",
    "            logits = logits.float()\n",
    "            loss = F.binary_cross_entropy_with_logits(logits.view(-1), labels.view(-1))\n",
    "            return logits, loss\n",
    "\n",
    "    def calculate_logit_matrix(self,embedding_pep,embedding_prot):\n",
    "        rows, cols = torch.triu_indices(embedding_pep.size(0), embedding_pep.size(0), offset=1)\n",
    "        \n",
    "        positive_logits = self(embedding_pep, embedding_prot)\n",
    "        negative_logits = self(embedding_pep[rows,:,:], embedding_prot[cols,:,:], int_prob=0.0)\n",
    "        \n",
    "        logit_matrix = torch.zeros((embedding_pep.size(0),embedding_pep.size(0)),device=self.device)\n",
    "        logit_matrix[rows, cols] = negative_logits\n",
    "        logit_matrix[cols, rows] = negative_logits\n",
    "        \n",
    "        diag_indices = torch.arange(embedding_pep.size(0), device=self.device)\n",
    "        logit_matrix[diag_indices, diag_indices] = positive_logits.squeeze()\n",
    "        \n",
    "        return logit_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c2366-dc92-4347-82dc-72505eb1b4e9",
   "metadata": {},
   "source": [
    "### Adding both pep_trans and pep_cross to original embedidng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09adeb2-0fe7-4115-b224-2f45ca5e29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_key_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings < (padding_value + offset)).all(dim=-1)\n",
    "\n",
    "def create_mean_of_non_masked(embeddings, padding_mask):\n",
    "    # Use masked select and mean to compute the mean of non-masked elements\n",
    "    # embeddings should be of shape (batch_size, seq_len, features)\n",
    "    seq_embeddings = []\n",
    "    for i in range(embeddings.shape[0]): # looping over all batch elements\n",
    "        non_masked_embeddings = embeddings[i][~padding_mask[i]] # shape [num_real_tokens, features]\n",
    "        if len(non_masked_embeddings) == 0:\n",
    "            print(\"You are masking all positions when creating sequence representation\")\n",
    "            sys.exit(1)\n",
    "        mean_embedding = non_masked_embeddings.mean(dim=0) # sequence is represented by the single vecotr [1152] [features]\n",
    "        seq_embeddings.append(mean_embedding)\n",
    "    return torch.stack(seq_embeddings)\n",
    "\n",
    "class MiniCLIP_w_transformer_crossattn(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, padding_value = -5000, embed_dimension=embedding_dimension, num_recycles=2):\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_recycles = num_recycles # how many times you iteratively refine embeddings with self- and cross-attention (ALPHA-Fold-style recycling).\n",
    "        self.padding_value = padding_value\n",
    "        self.embed_dimension = embed_dimension\n",
    "\n",
    "        self.logit_scale = nn.Parameter(torch.tensor(math.log(1/0.07)))  # ~CLIP init\n",
    "\n",
    "        self.transformerencoder =  nn.TransformerEncoderLayer(\n",
    "            d_model=self.embed_dimension,\n",
    "            nhead=8,\n",
    "            dropout=0.1,\n",
    "            batch_first=True,\n",
    "            dim_feedforward=self.embed_dimension\n",
    "            )\n",
    " \n",
    "        self.norm = nn.LayerNorm(self.embed_dimension)  # For residual additions\n",
    "\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=self.embed_dimension,\n",
    "            num_heads=8,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.prot_embedder = nn.Sequential(\n",
    "            nn.Linear(self.embed_dimension, 640),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(640, 320),\n",
    "        )\n",
    "        \n",
    "    def forward(self, pep_input, prot_input, label=None, pep_int_mask=None, prot_int_mask=None, int_prob=None, mem_save=True): # , pep_tokens, prot_tokens\n",
    "\n",
    "        pep_mask = create_key_padding_mask(embeddings=pep_input, padding_value=self.padding_value)\n",
    "        prot_mask = create_key_padding_mask(embeddings=prot_input, padding_value=self.padding_value)\n",
    " \n",
    "        # Initialize residual states\n",
    "        pep_emb = pep_input.clone()\n",
    "        prot_emb = prot_input.clone()\n",
    " \n",
    "        for _ in range(self.num_recycles):\n",
    "\n",
    "            # Transformer encoding with residual\n",
    "            pep_trans = self.transformerencoder(self.norm(pep_emb), src_key_padding_mask=pep_mask)\n",
    "            prot_trans = self.transformerencoder(self.norm(prot_emb), src_key_padding_mask=prot_mask)\n",
    "\n",
    "            # Cross-attention with residual\n",
    "            pep_cross, _ = self.cross_attn(query=self.norm(pep_trans), key=self.norm(prot_trans), value=self.norm(prot_trans), key_padding_mask=prot_mask)\n",
    "            prot_cross, _ = self.cross_attn(query=self.norm(prot_trans), key=self.norm(pep_trans), value=self.norm(pep_trans), key_padding_mask=pep_mask)\n",
    "            \n",
    "            # Additive update with residual connection\n",
    "            pep_emb = pep_emb + pep_trans + pep_cross  \n",
    "            prot_emb = prot_emb + prot_trans + prot_cross\n",
    "\n",
    "        pep_seq_coding = create_mean_of_non_masked(pep_emb, pep_mask)\n",
    "        prot_seq_coding = create_mean_of_non_masked(prot_emb, prot_mask)\n",
    "        \n",
    "        # Use self-attention outputs for embeddings\n",
    "        pep_seq_coding = F.normalize(self.prot_embedder(pep_seq_coding), dim=-1)\n",
    "        prot_seq_coding = F.normalize(self.prot_embedder(prot_seq_coding), dim=-1)\n",
    " \n",
    "        if mem_save:\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        scale = torch.exp(self.logit_scale).clamp(max=100.0)\n",
    "        logits = scale * (pep_seq_coding * prot_seq_coding).sum(dim=-1)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, device):\n",
    "        embedding_pep, embedding_prot, labels = batch\n",
    "        embedding_pep, embedding_prot = embedding_pep.to(device), embedding_prot.to(device)\n",
    "        \n",
    "        positive_logits = self.forward(embedding_pep, embedding_prot)\n",
    "        \n",
    "        # Negative indexes\n",
    "        rows, cols = torch.triu_indices(embedding_prot.size(0), embedding_prot.size(0), offset=1)         \n",
    "        \n",
    "        negative_logits = self(embedding_pep[rows,:,:], \n",
    "                          embedding_prot[cols,:,:], \n",
    "                          int_prob=0.0)\n",
    "\n",
    "        # loss of predicting partner using peptide\n",
    "        positive_loss = F.binary_cross_entropy_with_logits(positive_logits, torch.ones_like(positive_logits).to(device))\n",
    " \n",
    "        # loss of predicting peptide using partner\n",
    "        negative_loss =  F.binary_cross_entropy_with_logits(negative_logits, torch.zeros_like(negative_logits).to(device))\n",
    "        \n",
    "        loss = (positive_loss + negative_loss) / 2\n",
    " \n",
    "        # del partner_prediction_loss, peptide_prediction_loss, embedding_pep, embedding_prot\n",
    "        torch.cuda.empty_cache()\n",
    "        return loss\n",
    "\n",
    "    def validation_step_PPint(self, batch, device):\n",
    "        # Predict on random batches of training batch size\n",
    "        embedding_pep, embedding_prot, labels = batch\n",
    "        embedding_pep, embedding_prot = embedding_pep.to(device), embedding_prot.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            positive_logits = self(embedding_pep, embedding_prot)\n",
    "            \n",
    "            # loss of predicting partner using peptide\n",
    "            positive_loss = F.binary_cross_entropy_with_logits(positive_logits, torch.ones_like(positive_logits).to(device))\n",
    "            \n",
    "            # Negaive indexes\n",
    "            rows, cols = torch.triu_indices(embedding_prot.size(0), embedding_prot.size(0), offset=1)\n",
    "            \n",
    "            negative_logits = self(embedding_pep[rows,:,:], embedding_prot[cols,:,:], int_prob=0.0)\n",
    "    \n",
    "            negative_loss =  F.binary_cross_entropy_with_logits(negative_logits, torch.zeros_like(negative_logits).to(device))\n",
    "\n",
    "            loss = (positive_loss + negative_loss) / 2\n",
    "           \n",
    "            logit_matrix = torch.zeros((embedding_pep.size(0),embedding_pep.size(0)),device=self.device)\n",
    "            logit_matrix[rows, cols] = negative_logits\n",
    "            logit_matrix[cols, rows] = negative_logits\n",
    "            \n",
    "            # Fill diagonal with positive scores\n",
    "            diag_indices = torch.arange(embedding_pep.size(0), device=self.device)\n",
    "            logit_matrix[diag_indices, diag_indices] = positive_logits.squeeze()\n",
    "\n",
    "            labels = torch.arange(embedding_prot.size(0)).to(self.device)\n",
    "            peptide_predictions = logit_matrix.argmax(dim=0)\n",
    "            peptide_ranks = logit_matrix.argsort(dim=0).diag() + 1\n",
    "            peptide_mrr = (peptide_ranks).float().pow(-1).mean()\n",
    "            \n",
    "            # partner_accuracy = partner_predictions.eq(labels).float().mean()\n",
    "            peptide_accuracy = peptide_predictions.eq(labels).float().mean()\n",
    "    \n",
    "            k = 3\n",
    "            peptide_topk_accuracy = torch.any((logit_matrix.topk(k, dim=0).indices - labels.reshape(1, -1)) == 0, dim=0).sum() / logit_matrix.shape[0]\n",
    "    \n",
    "            del logit_matrix,positive_logits,negative_logits,embedding_pep,embedding_prot\n",
    "\n",
    "            return loss, peptide_accuracy, peptide_topk_accuracy\n",
    "    \n",
    "    def validation_step_MetaDataset(self, batch, device):\n",
    "        embedding_binder, embedding_target, labels = batch\n",
    "        embedding_binder = embedding_binder.to(device)\n",
    "        embedding_target = embedding_target.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(embedding_binder, embedding_target)\n",
    "            logits = logits.float()\n",
    "            loss = F.binary_cross_entropy_with_logits(logits.view(-1), labels.view(-1))\n",
    "            return logits, loss\n",
    "\n",
    "    def calculate_logit_matrix(self,embedding_pep,embedding_prot):\n",
    "        rows, cols = torch.triu_indices(embedding_pep.size(0), embedding_pep.size(0), offset=1)\n",
    "        \n",
    "        positive_logits = self(embedding_pep, embedding_prot)\n",
    "        negative_logits = self(embedding_pep[rows,:,:], embedding_prot[cols,:,:], int_prob=0.0)\n",
    "        \n",
    "        logit_matrix = torch.zeros((embedding_pep.size(0),embedding_pep.size(0)),device=self.device)\n",
    "        logit_matrix[rows, cols] = negative_logits\n",
    "        logit_matrix[cols, rows] = negative_logits\n",
    "        \n",
    "        diag_indices = torch.arange(embedding_pep.size(0), device=self.device)\n",
    "        logit_matrix[diag_indices, diag_indices] = positive_logits.squeeze()\n",
    "        \n",
    "        return logit_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24222398-c484-4e4b-9256-987a529c19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniCLIP_w_transformer_crossattn(embed_dimension=embedding_dimension, num_recycles=number_of_recycles).to(\"cuda\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2460df-3d34-4548-807d-ca306e006c5d",
   "metadata": {},
   "source": [
    "### Trianing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817e401-cca6-44a7-a7d0-8bdf1d51cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    \"\"\"Takes any indexable iterable (e.g., a list of observation IDs) and yields contiguous slices of length n.\"\"\"\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "class TrainWrapper():\n",
    "\n",
    "    def __init__(self, \n",
    "                 model, \n",
    "                 train_loader,\n",
    "                 test_loader,\n",
    "                 val_loader,\n",
    "                 test_df,\n",
    "                 test_dataset,\n",
    "                 optimizer, \n",
    "                 epochs, \n",
    "                 runID, \n",
    "                 device, \n",
    "                 test_indexes_for_auROC = None,\n",
    "                 auROC_batch_size=10, \n",
    "                 model_save_steps=False, \n",
    "                 model_save_path=False, \n",
    "                 v=False, \n",
    "                 wandb_tracker=False):\n",
    "        \n",
    "        self.model = model \n",
    "        self.training_loader = train_loader\n",
    "        self.testing_loader = test_loader\n",
    "        self.validation_loader = val_loader\n",
    "        self.test_dataset = test_dataset\n",
    "        self.test_df = test_df\n",
    "        self.auROC_batch_size = auROC_batch_size\n",
    "        \n",
    "        self.EPOCHS = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        \n",
    "        self.wandb_tracker = wandb_tracker\n",
    "        self.model_save_steps = model_save_steps\n",
    "        self.verbose = v\n",
    "        self.best_vloss = 1_000_000\n",
    "        self.runID = runID\n",
    "        self.trained_model_dir = model_save_path\n",
    "        self.print_frequency_loss = 1\n",
    "        self.test_indexes_for_auROC = test_indexes_for_auROC\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "\n",
    "        self.model.train() \n",
    "        running_loss = 0\n",
    "\n",
    "        for batch in tqdm(self.training_loader, total=len(self.training_loader), desc=\"Running through epoch\"):\n",
    "            \n",
    "            if batch[0].size(0) == 1: \n",
    "                continue\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.model.training_step(batch, self.device)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            del loss, batch\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        return running_loss / len(self.training_loader)\n",
    "\n",
    "    def calc_auroc_aupr_on_indexes(self, model, dataset, dataframe, nondimer_indexes, batch_size = 10):\n",
    "\n",
    "        self.model.eval()\n",
    "        all_TP_scores, all_FP_scores = [], []\n",
    "        accessions = [dataframe.loc[index].target_binder_id for index in nondimer_indexes]  # <-- use dataframe\n",
    "        batches_local = batch(accessions, n=batch_size)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for index_batch in tqdm(batches_local, total=int(len(accessions)/batch_size), desc=\"Calculating AUC\"):\n",
    "\n",
    "                binder_emb, target_emb, labels = dataset._get_by_name(index_batch)\n",
    "                binder_emb, target_emb = binder_emb.to(self.device), target_emb.to(self.device)\n",
    "\n",
    "                # Make sure this matches your model's signature:\n",
    "                logit_matrix = self.model.calculate_logit_matrix(binder_emb, target_emb)\n",
    "                \n",
    "                TP_scores = logit_matrix.diag().detach().cpu().tolist()\n",
    "                all_TP_scores += TP_scores\n",
    "                \n",
    "                # Get FP scores from upper triangle (excluding diagonal)\n",
    "                n = logit_matrix.size(0)\n",
    "                rows, cols = torch.triu_indices(n, n, offset=1)\n",
    "                FP_scores = logit_matrix[rows, cols].detach().cpu().tolist()\n",
    "                all_FP_scores += FP_scores\n",
    "            \n",
    "        all_score_predictions = np.array(all_TP_scores + all_FP_scores)\n",
    "        all_labels = np.array([1]*len(all_TP_scores) + [0]*len(all_FP_scores))\n",
    "                \n",
    "        fpr, tpr, thresholds = metrics.roc_curve(all_labels, all_score_predictions)\n",
    "        auroc = metrics.roc_auc_score(all_labels, all_score_predictions)\n",
    "        aupr  = metrics.average_precision_score(all_labels, all_score_predictions)\n",
    "        \n",
    "        return auroc, aupr, all_TP_scores, all_FP_scores\n",
    "\n",
    "    def validate(self):\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        running_loss_Meta = 0.0\n",
    "        all_logits = []\n",
    "        all_lbls = []\n",
    "        used_batches_meta = 0\n",
    "\n",
    "        # --- MetaDataset validation ---\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.validation_loader, total=len(self.validation_loader)):\n",
    "                if batch[0].size(0) == 1:\n",
    "                    continue\n",
    "                embedding_binder, embedding_target, labels = batch\n",
    "                logits, loss = self.model.validation_step_MetaDataset(batch, self.device)\n",
    "                \n",
    "                running_loss_Meta += loss.item()\n",
    "                all_logits.append(logits.detach().view(-1).cpu())\n",
    "                all_lbls.append(labels.detach().view(-1).cpu())\n",
    "                used_batches_meta += 1\n",
    "                \n",
    "            if used_batches_meta > 0:\n",
    "                val_loss_Meta = running_loss_Meta / used_batches_meta\n",
    "                all_logits = torch.cat(all_logits).numpy()\n",
    "                all_lbls   = torch.cat(all_lbls).numpy()\n",
    "            \n",
    "                fpr, tpr, thresholds = metrics.roc_curve(all_lbls, all_logits)\n",
    "                meta_auroc = metrics.roc_auc_score(all_lbls, all_logits)\n",
    "                meta_aupr  = metrics.average_precision_score(all_lbls, all_logits)\n",
    "\n",
    "                y_pred = (all_logits >= 0).astype(int)\n",
    "                y_true = all_lbls.astype(int)\n",
    "                val_acc_Meta = (y_pred == y_true).mean()\n",
    "            else:\n",
    "                val_loss_Meta = float(\"nan\")\n",
    "                meta_auroc = float(\"nan\")\n",
    "                meta_aupr = float(\"nan\")\n",
    "                val_acc_Meta = float(\"nan\")\n",
    "\n",
    "        # --- PPint validation ---\n",
    "        running_loss_ValPPint = 0.0\n",
    "        running_accuracy_ValPPint = 0.0\n",
    "        running_topk_accuracy_ValPPint = 0.0\n",
    "        used_batches_ppint = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.testing_loader, total=len(self.testing_loader)):\n",
    "                if batch[0].size(0) == 1:\n",
    "                    continue\n",
    "                loss, partner_accuracy, peptide_topk_accuracy = self.model.validation_step_PPint(batch, self.device)\n",
    "                running_loss_ValPPint += loss.item()\n",
    "                running_accuracy_ValPPint += partner_accuracy.item()\n",
    "                running_topk_accuracy_ValPPint += peptide_topk_accuracy.item()\n",
    "                used_batches_ppint += 1\n",
    "                \n",
    "            if used_batches_ppint > 0:\n",
    "                val_loss_PPint = running_loss_ValPPint / used_batches_ppint\n",
    "                val_accuracy_PPint = running_accuracy_ValPPint / used_batches_ppint\n",
    "                val_topk_accuracy_PPint = running_topk_accuracy_ValPPint / used_batches_ppint\n",
    "            else:\n",
    "                val_loss_PPint = float(\"nan\")\n",
    "                val_accuracy_PPint = float(\"nan\")\n",
    "                val_topk_accuracy_PPint = float(\"nan\")\n",
    "\n",
    "        # --- AUROC on specific indexes (optional) ---\n",
    "        if self.test_indexes_for_auROC is not None:\n",
    "            non_dimer_auc, non_dimer_aupr, ___, ___ = self.calc_auroc_aupr_on_indexes(\n",
    "                model=self.model, \n",
    "                dataset=self.test_dataset,\n",
    "                dataframe=self.test_df,\n",
    "                nondimer_indexes=self.test_indexes_for_auROC,\n",
    "                batch_size=self.auROC_batch_size\n",
    "            )\n",
    "            \n",
    "            return (val_loss_PPint, val_accuracy_PPint, val_topk_accuracy_PPint,\n",
    "                    non_dimer_auc, non_dimer_aupr,\n",
    "                    val_loss_Meta, val_acc_Meta, meta_auroc, meta_aupr)\n",
    "\n",
    "        else:\n",
    "            return (val_loss_PPint, val_accuracy_PPint, val_topk_accuracy_PPint,\n",
    "                    val_loss_Meta, val_acc_Meta, meta_auroc, meta_aupr)\n",
    "\n",
    "    def train_model(self):\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Training model {str(self.runID)}\")\n",
    "\n",
    "        # --- initial validation before training\n",
    "        print(\"Initial validation before starting training\")\n",
    "        if self.test_indexes_for_auROC is not None:\n",
    "            (val_loss_PPint, val_accuracy_PPint, val_topk_accuracy_PPint,\n",
    "             non_dimer_auc, non_dimer_aupr,\n",
    "             val_loss_Meta, val_acc_Meta, meta_auroc, meta_aupr) = self.validate()\n",
    "        else:\n",
    "            (val_loss_PPint, val_accuracy_PPint, val_topk_accuracy_PPint,\n",
    "             val_loss_Meta, val_acc_Meta, meta_auroc, meta_aupr) = self.validate()\n",
    "            non_dimer_auc, non_dimer_aupr = None, None\n",
    "                \n",
    "        if self.verbose: \n",
    "            print(f'Before training:')\n",
    "            print(f'Meta Val-Loss {round(val_loss_Meta,4)}')\n",
    "            print(f'Meta Accuracy: {round(val_acc_Meta,4)}')\n",
    "            print(f'Meta AUROC: {round(meta_auroc,4)}')\n",
    "            print(f'Meta AUPR: {round(meta_aupr,4)}')\n",
    "            print(f'PPint Test-Loss: {round(val_loss_PPint,4)}')\n",
    "            print(f'PPint Accuracy: {round(val_accuracy_PPint,4)}')\n",
    "            if non_dimer_auc is not None:\n",
    "                print(f'PPint non-dimer AUROC: {round(non_dimer_auc,4)}')\n",
    "                print(f'PPint non-dimer AUPR: {round(non_dimer_aupr,4)}')\n",
    "        \n",
    "        if self.wandb_tracker:\n",
    "            metrics_to_log = {\n",
    "                \"PPint Test-Loss\": val_loss_PPint,\n",
    "                \"Meta Val-loss\": val_loss_Meta,\n",
    "                \"PPint Accuracy\": val_accuracy_PPint,\n",
    "                \"Meta Accuracy\": val_acc_Meta,\n",
    "                \"Meta Val-AUROC\": meta_auroc,\n",
    "                \"Meta Val-AUPR\": meta_aupr,\n",
    "            }\n",
    "            if non_dimer_auc is not None:\n",
    "                metrics_to_log.update({\n",
    "                    \"PPint non-dimer AUROC\": non_dimer_auc,\n",
    "                    \"PPint non-dimer AUPR\": non_dimer_aupr,\n",
    "                })\n",
    "            self.wandb_tracker.log(metrics_to_log, step=0)\n",
    "        \n",
    "        # --- training loop\n",
    "        for epoch in tqdm(range(1, self.EPOCHS + 1), total=self.EPOCHS, desc=\"Epochs\"):\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            train_loss = self.train_one_epoch()\n",
    "            \n",
    "            # validation after epoch\n",
    "            if self.test_indexes_for_auROC is not None:\n",
    "                (val_loss_PPint, val_accuracy_PPint, val_topk_accuracy_PPint,\n",
    "                 non_dimer_auc, non_dimer_aupr,\n",
    "                 val_loss_Meta, val_acc_Meta, meta_auroc, meta_aupr) = self.validate()\n",
    "            else:\n",
    "                (val_loss_PPint, val_accuracy_PPint, val_topk_accuracy_PPint,\n",
    "                 val_loss_Meta, val_acc_Meta, meta_auroc, meta_aupr) = self.validate()\n",
    "                non_dimer_auc, non_dimer_aupr = None, None\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # checkpoint save\n",
    "            if self.model_save_steps and epoch % self.model_save_steps == 0:\n",
    "                check_point_folder = os.path.join(self.trained_model_dir, f\"{str(self.runID)}_checkpoint_{str(epoch)}\")\n",
    "                if self.verbose:\n",
    "                    print(\"Saving model to:\", check_point_folder)\n",
    "                os.makedirs(check_point_folder, exist_ok=True)\n",
    "                checkpoint_path = os.path.join(check_point_folder, f\"{str(self.runID)}_checkpoint_epoch_{str(epoch)}.pth\")\n",
    "                torch.save({'epoch': epoch, \n",
    "                            'model_state_dict': self.model.state_dict(),\n",
    "                            'optimizer_state_dict': self.optimizer.state_dict(), \n",
    "                            'val_loss_PPint': val_loss_PPint,\n",
    "                            'val_loss_Meta': val_loss_Meta},\n",
    "                           checkpoint_path)\n",
    "            \n",
    "            # console logging\n",
    "            if self.verbose and epoch % self.print_frequency_loss == 0:\n",
    "                print(f'EPOCH {epoch}:')\n",
    "                print(f'Meta Val Loss {round(val_loss_Meta,4)}')\n",
    "                print(f'Meta Accuracy: {round(val_acc_Meta,4)}')\n",
    "                print(f'Meta AUROC: {round(meta_auroc,4)}')\n",
    "                print(f'Meta AUPR: {round(meta_aupr,4)}')\n",
    "                print(f'PPint Test-Loss: {round(val_loss_PPint,4)}')\n",
    "                print(f'PPint Accuracy: {round(val_accuracy_PPint,4)}')\n",
    "                if non_dimer_auc is not None:\n",
    "                    print(f'PPint non-dimer AUROC: {round(non_dimer_auc,4)}')\n",
    "                    print(f'PPint non-dimer AUPR: {round(non_dimer_aupr,4)}')\n",
    "            \n",
    "            # wandb logging\n",
    "            if self.wandb_tracker:\n",
    "                metrics_to_log_epoch = {\n",
    "                    \"PPint Train-loss\": train_loss,\n",
    "                    \"PPint Test-Loss\": val_loss_PPint,\n",
    "                    \"Meta Val-loss\": val_loss_Meta,\n",
    "                    \"PPint Accuracy\": val_accuracy_PPint,\n",
    "                    \"Meta Accuracy\": val_acc_Meta,\n",
    "                    \"Meta Val-AUROC\": meta_auroc,\n",
    "                    \"Meta Val-AUPR\": meta_aupr,\n",
    "                }\n",
    "                if non_dimer_auc is not None:\n",
    "                    metrics_to_log_epoch.update({\n",
    "                        \"PPint non-dimer AUROC\": non_dimer_auc,\n",
    "                        \"PPint non-dimer AUPR\": non_dimer_aupr,\n",
    "                    })\n",
    "                self.wandb_tracker.log(metrics_to_log_epoch, step=epoch)\n",
    "\n",
    "        if self.wandb_tracker:\n",
    "            self.wandb_tracker.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c80cc-d9fa-4fec-baef-e6c76311a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "EPOCHS = 6\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "batch_size = 10\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "train_dataloader = DataLoader(training_Dataset, batch_size=10, shuffle=True, drop_last = True)\n",
    "test_dataloader = DataLoader(testing_Dataset, batch_size=10, shuffle=False)\n",
    "val_dataloader = DataLoader(validation_Dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "# accelerator\n",
    "model, optimizer, train_dataloader, test_dataloader, val_dataloader = accelerator.prepare(model, optimizer, train_dataloader, test_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53b5bb7-5350-405e-9d05-ea7729a949e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in val_dataloader:\n",
    "    __, __, lbls = i\n",
    "    print(lbls.to(device))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590809f4-b427-4913-8103-b116cffaeeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb\n",
    "if use_wandb:\n",
    "    run = wandb.init(\n",
    "        project=\"CLIP_retrain_ESM2\",\n",
    "        name=f\"Original\",\n",
    "        config={\"learning_rate\": learning_rate, \n",
    "                \"batch_size\": batch_size, \n",
    "                \"epochs\": EPOCHS,\n",
    "                \"architecture\": \"MiniCLIP_w_transformer_crossattn\", \n",
    "                \"dataset\": \n",
    "                \"PPint\"},\n",
    "    )\n",
    "    wandb.watch(accelerator.unwrap_model(model), log=\"all\", log_freq=100)\n",
    "else:\n",
    "    run = None\n",
    "\n",
    "# train\n",
    "training_wrapper = TrainWrapper(\n",
    "            model=model,\n",
    "            train_loader=train_dataloader,\n",
    "            test_loader=test_dataloader,\n",
    "            val_loader=val_dataloader,\n",
    "            test_df=Df_test,\n",
    "            test_dataset=testing_Dataset,\n",
    "            optimizer=optimizer,\n",
    "            epochs=EPOCHS,\n",
    "            runID=runID,\n",
    "            device=device,\n",
    "            test_indexes_for_auROC=indices_non_dimers_val,\n",
    "            auROC_batch_size=10,\n",
    "            model_save_steps=model_save_steps,\n",
    "            model_save_path=trained_model_dir,\n",
    "            v=True,\n",
    "            wandb_tracker=wandb\n",
    ")\n",
    "\n",
    "training_wrapper.train_model() # start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198aeca9-ce23-4046-950e-8a4482a4552d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESM CUDA Env",
   "language": "python",
   "name": "esm_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
