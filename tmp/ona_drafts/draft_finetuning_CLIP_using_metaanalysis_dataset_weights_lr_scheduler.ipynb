{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63399e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'training_utils.train_utils' from '/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/training_utils/train_utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid, sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import torch\n",
    "torch.cuda.set_device(0)  # 0 == \"first visible\" -> actually GPU 3 on the node\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, TensorDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import AdamW\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from Levenshtein import distance as Ldistance\n",
    "\n",
    "import training_utils.dataset_utils as data_utils\n",
    "import training_utils.partitioning_utils as pat_utils\n",
    "\n",
    "import importlib\n",
    "import training_utils.train_utils as train_utils\n",
    "importlib.reload(train_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0f0d24-58f7-4fe9-bf14-44afca1c5cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.4000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=torch.float32)\n",
    "pos = (labels == 1).sum()\n",
    "neg = (labels == 0).sum()\n",
    "pos_weight = torch.tensor([neg / max(1, pos)])\n",
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e15a99b6-dba0-4e18-90ed-29d94fb99dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fd8c39-646a-4c81-bcca-e8e6bc2a3f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms232958\u001b[0m (\u001b[33ms232958-danmarks-tekniske-universitet-dtu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74898fc-5964-4839-a6b1-a8b9ad0caca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.5.1\n",
      "Using device: cuda\n",
      "Current location: /zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts\")\n",
    "# print(os.getcwd())\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print(\"Current location:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0463b05-0f5c-4f18-ab90-4065ffed6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "memory_verbose = False\n",
    "use_wandb = True # Used to track loss in real-time without printing\n",
    "model_save_steps = 1\n",
    "train_frac = 1.0\n",
    "test_frac = 1.0\n",
    "\n",
    "embedding_dimension = 1152 # 1280 | 960 | 1152\n",
    "number_of_recycles = 2\n",
    "padding_value = -5000\n",
    "\n",
    "# batch_size = 20\n",
    "learning_rate = 2e-5\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f31b2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Class\n",
    "### MiniClip \n",
    "def gaussian_kernel(x, sigma):\n",
    "    return np.exp(-x**2 / (2 * sigma**2))\n",
    "\n",
    "def transform_vector(vector, sigma):\n",
    "\n",
    "    interacting_indices = np.where(vector == 1)[0]   # positions where vector == 1\n",
    "    transformed_vector = np.zeros_like(vector, dtype=float)\n",
    "    \n",
    "    for i in range(len(vector)):\n",
    "        if vector[i] == 0:\n",
    "            distances = np.abs(interacting_indices - i)   # distance to all \"1\"s\n",
    "            min_distance = np.min(distances)              # closest \"1\"\n",
    "            transformed_vector[i] = gaussian_kernel(min_distance, sigma)\n",
    "        else:\n",
    "            transformed_vector[i] = 1.0\n",
    "    return transformed_vector\n",
    "\n",
    "def safe_shuffle(n, device):\n",
    "    shuffled = torch.randperm(n, device=device)\n",
    "    while torch.any(shuffled == torch.arange(n, device=device)):\n",
    "        shuffled = torch.randperm(n, device=device)\n",
    "    return shuffled\n",
    "\n",
    "def create_key_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings < (padding_value + offset)).all(dim=-1)\n",
    "\n",
    "def create_mean_of_non_masked(embeddings, padding_mask):\n",
    "    # Use masked select and mean to compute the mean of non-masked elements\n",
    "    # embeddings should be of shape (batch_size, seq_len, features)\n",
    "    seq_embeddings = []\n",
    "    for i in range(embeddings.shape[0]): # looping over all batch elements\n",
    "        non_masked_embeddings = embeddings[i][~padding_mask[i]] # shape [num_real_tokens, features]\n",
    "        if len(non_masked_embeddings) == 0:\n",
    "            print(\"You are masking all positions when creating sequence representation\")\n",
    "            sys.exit(1)\n",
    "        mean_embedding = non_masked_embeddings.mean(dim=0) # sequence is represented by the single vecotr [1152] [features]\n",
    "        seq_embeddings.append(mean_embedding)\n",
    "    return torch.stack(seq_embeddings)\n",
    "\n",
    "class MiniCLIP_w_transformer_crossattn(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, padding_value = -5000, embed_dimension=1152, num_recycles=1):\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_recycles = num_recycles # how many times you iteratively refine embeddings with self- and cross-attention (ALPHA-Fold-style recycling).\n",
    "        self.padding_value = padding_value\n",
    "        self.embed_dimension = embed_dimension\n",
    "\n",
    "        self.logit_scale = nn.Parameter(torch.tensor(math.log(1/0.07)))  # ~CLIP init\n",
    "\n",
    "        self.transformerencoder =  nn.TransformerEncoderLayer(\n",
    "            d_model=self.embed_dimension,\n",
    "            nhead=8,\n",
    "            dropout=0.1,\n",
    "            batch_first=True,\n",
    "            dim_feedforward=self.embed_dimension\n",
    "            )\n",
    " \n",
    "        self.norm = nn.LayerNorm(self.embed_dimension)  # For residual additions\n",
    "\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=self.embed_dimension,\n",
    "            num_heads=8,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.prot_embedder = nn.Sequential(\n",
    "            nn.Linear(self.embed_dimension, 640),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(640, 320),\n",
    "        )\n",
    "        \n",
    "    def forward(self, pep_input, prot_input, label=None, pep_int_mask=None, prot_int_mask=None, int_prob=None, mem_save=True): # , pep_tokens, prot_tokens\n",
    "\n",
    "        pep_mask = create_key_padding_mask(embeddings=pep_input, padding_value=self.padding_value)\n",
    "        prot_mask = create_key_padding_mask(embeddings=prot_input, padding_value=self.padding_value)\n",
    " \n",
    "        # Initialize residual states\n",
    "        pep_emb = pep_input.clone()\n",
    "        prot_emb = prot_input.clone()\n",
    " \n",
    "        for _ in range(self.num_recycles):\n",
    "\n",
    "            # Transformer encoding with residual\n",
    "            pep_trans = self.transformerencoder(self.norm(pep_emb), src_key_padding_mask=pep_mask)\n",
    "            prot_trans = self.transformerencoder(self.norm(prot_emb), src_key_padding_mask=prot_mask)\n",
    "\n",
    "            # Cross-attention with residual\n",
    "            pep_cross, _ = self.cross_attn(query=self.norm(pep_trans), key=self.norm(prot_trans), value=self.norm(prot_trans), key_padding_mask=prot_mask)\n",
    "            prot_cross, _ = self.cross_attn(query=self.norm(prot_trans), key=self.norm(pep_trans), value=self.norm(pep_trans), key_padding_mask=pep_mask)\n",
    "            \n",
    "            # Additive update with residual connection\n",
    "            pep_emb = pep_emb + pep_cross  \n",
    "            prot_emb = prot_emb + prot_cross\n",
    "\n",
    "        pep_seq_coding = create_mean_of_non_masked(pep_emb, pep_mask)\n",
    "        prot_seq_coding = create_mean_of_non_masked(prot_emb, prot_mask)\n",
    "        \n",
    "        # Use self-attention outputs for embeddings\n",
    "        pep_seq_coding = F.normalize(self.prot_embedder(pep_seq_coding))\n",
    "        prot_seq_coding = F.normalize(self.prot_embedder(prot_seq_coding))\n",
    " \n",
    "        if mem_save:\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        scale = torch.exp(self.logit_scale).clamp(max=100.0)\n",
    "        logits = scale * (pep_seq_coding * prot_seq_coding).sum(dim=-1) # Dot-Product for comparison\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, device):\n",
    "        # Passing the sequences to the models\n",
    "        embedding_pep = batch[0]\n",
    "        embedding_prot = batch[1]\n",
    "        binder_label = batch[2]\n",
    " \n",
    "        embedding_pep = embedding_pep.to(device)\n",
    "        embedding_prot = embedding_prot.to(device)\n",
    "        binder_label = binder_label.to(device)\n",
    "\n",
    "        logits = self.forward(embedding_pep, embedding_prot)\n",
    "        binder_labels = binder_label.view_as(logits)  \n",
    "        loss = F.binary_cross_entropy_with_logits(logits, binder_labels)\n",
    " \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, device):\n",
    "        # Predict on random batches of training batch size\n",
    "        embedding_pep, embedding_prot, binder_label = batch\n",
    " \n",
    "        # Move to device\n",
    "        embedding_pep  = embedding_pep.to(device)\n",
    "        embedding_prot = embedding_prot.to(device)\n",
    "        binder_label = binder_label.to(device).float() \n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(embedding_pep, embedding_prot)   # shape [B]\n",
    "            binder_labels = binder_label.view_as(logits)  \n",
    "            loss = F.binary_cross_entropy_with_logits(logits, binder_labels)\n",
    "            \n",
    "        return float(loss.item()), logits, binder_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb156f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output path\n",
    "trained_model_dir = \"/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts\"\n",
    "\n",
    "## Embeddings paths\n",
    "binders_embeddings = \"/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/data/meta_analysis/binders_embeddings\"\n",
    "targets_embeddings = \"/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/data/meta_analysis/targets_embeddings\"\n",
    "\n",
    "# ## Training variables\n",
    "runID = uuid.uuid4()\n",
    "\n",
    "def print_mem_consumption():\n",
    "    # 1. Total memory available on the GPU (device 0)\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    # 2. How much memory PyTorch has *reserved* from CUDA\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    # 3. How much of that reserved memory is actually *used* by tensors\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    # 4. Reserved but not currently allocated (so “free inside PyTorch’s pool”)\n",
    "    f = r - a\n",
    "\n",
    "    print(\"Total memory: \", t/1e9)      # total VRAM in GB\n",
    "    print(\"Reserved memory: \", r/1e9)   # PyTorch’s reserved pool in GB\n",
    "    print(\"Allocated memory: \", a//1e9) # actually in use (integer division)\n",
    "    print(\"Free memory: \", f/1e9)       # slack in the reserved pool in GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a2d71",
   "metadata": {},
   "source": [
    "#### Loading data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "332b707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the dataset\n",
    "interaction_df = pd.read_csv(\"../data/meta_analysis/interaction_df_metaanal.csv\", index_col = 0).drop(columns = [\"binder_id\", \"target_id\"]).rename(columns={\n",
    "    \"A_seq\" : \"binder_seq\",\n",
    "    \"B_seq\" : \"target_seq\"\n",
    "})\n",
    "\n",
    "all_targets = interaction_df.target_id_mod.unique()\n",
    "binder_nonbinder = interaction_df.binder.value_counts()\n",
    "target_binder_nonbinder_Dict = dict(interaction_df.groupby(\"target_id_mod\")[\"binder\"].value_counts())\n",
    "sorted_items = sorted(target_binder_nonbinder_Dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "# %%\n",
    "# Annotating each observation with a weight corresponding to whether it is considered a binder or not\n",
    "\n",
    "### Weights for binder/non-binders\n",
    "N_bins = len(interaction_df[\"binder\"].value_counts())\n",
    "pr_class_uniform_weight = 1 / N_bins\n",
    "pr_class_weight_informed_with_size_of_bins = pr_class_uniform_weight  / interaction_df[\"binder\"].value_counts()\n",
    "pr_class_weight_informed_with_size_of_bins = pr_class_weight_informed_with_size_of_bins.to_dict()\n",
    "interaction_df[\"class_weight\"] = interaction_df.binder.apply(lambda x: pr_class_weight_informed_with_size_of_bins[x])\n",
    "# binder_nonbinder_weights_Dict = dict(zip(interaction_df[\"target_binder_ID\"], interaction_df[\"class_weight\"]))\n",
    "\n",
    "### Weights for target\n",
    "N_bins = len(interaction_df[\"target_id_mod\"].value_counts())\n",
    "pr_class_uniform_weight = 1 / N_bins\n",
    "pr_class_weight_informed_with_size_of_bins = pr_class_uniform_weight  / interaction_df[\"target_id_mod\"].value_counts()\n",
    "pr_class_weight_informed_with_size_of_bins = pr_class_weight_informed_with_size_of_bins.to_dict()\n",
    "interaction_df[\"target_weight\"] = interaction_df.target_id_mod.apply(lambda x: pr_class_weight_informed_with_size_of_bins[x])\n",
    "\n",
    "### Combined weights\n",
    "interaction_df[\"combined_weight\"] = interaction_df[\"class_weight\"]*interaction_df[\"target_weight\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9f3b6d-b8a2-4010-996b-e5439eb9b0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binder_chain</th>\n",
       "      <th>target_chains</th>\n",
       "      <th>binder</th>\n",
       "      <th>binder_seq</th>\n",
       "      <th>target_seq</th>\n",
       "      <th>target_id_mod</th>\n",
       "      <th>target_binder_ID</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>target_weight</th>\n",
       "      <th>combined_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>LDFIVFAGPEKAIKFYKEMAKRNLEVKIWIDGDWAVVQVK</td>\n",
       "      <td>ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...</td>\n",
       "      <td>VirB8</td>\n",
       "      <td>VirB8_1</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>1.004956e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>SEQDETMHRIVRSVIQHAYKHNDEMAEYFAQNAAEIYKEQNKSEEA...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_1</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.686322e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>DYKQLKKHATKLLELAKKDPSSKRDLLRTAASYANKVLFEDSDPRA...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_2</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.686322e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>DEKEELERRANRVAFLAIQIQNEEYHRILAELYVQFMKAAENNDTE...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_3</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.686322e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>PDNKEKLMSIAVQLILRINEAARSEEQWRYANRAAFAAVEASSGSD...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_4</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.686322e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>DLRKYAAELVDRLAEKYNLDSDQYNALVRLASELVWQGKSKEEIEK...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_62</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1.507433e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>SKEEIKKEAEELIEELKKKGYNLPLRILEFALKEIEETNSEKYYEQ...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_63</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1.507433e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>SPEYKKFLELIKEAEAARKAGDLDKAKELLEKALELAKKMKAKSLI...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_64</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1.507433e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>DPLLAYKLLKLSQKALEKAYAEDRERAEELLEEAEAALRSLGDEAG...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_65</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1.507433e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>SEAARRARELFHEADELDKRGNPEEAEEVLREALELAREAGSPNLA...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_66</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1.507433e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3532 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     binder_chain target_chains  binder  \\\n",
       "0               A         [\"B\"]   False   \n",
       "1               A         [\"B\"]   False   \n",
       "2               A         [\"B\"]   False   \n",
       "3               A         [\"B\"]   False   \n",
       "4               A         [\"B\"]   False   \n",
       "...           ...           ...     ...   \n",
       "3527            A         [\"B\"]   False   \n",
       "3528            A         [\"B\"]   False   \n",
       "3529            A         [\"B\"]   False   \n",
       "3530            A         [\"B\"]   False   \n",
       "3531            A         [\"B\"]   False   \n",
       "\n",
       "                                             binder_seq  \\\n",
       "0              LDFIVFAGPEKAIKFYKEMAKRNLEVKIWIDGDWAVVQVK   \n",
       "1     SEQDETMHRIVRSVIQHAYKHNDEMAEYFAQNAAEIYKEQNKSEEA...   \n",
       "2     DYKQLKKHATKLLELAKKDPSSKRDLLRTAASYANKVLFEDSDPRA...   \n",
       "3     DEKEELERRANRVAFLAIQIQNEEYHRILAELYVQFMKAAENNDTE...   \n",
       "4     PDNKEKLMSIAVQLILRINEAARSEEQWRYANRAAFAAVEASSGSD...   \n",
       "...                                                 ...   \n",
       "3527  DLRKYAAELVDRLAEKYNLDSDQYNALVRLASELVWQGKSKEEIEK...   \n",
       "3528  SKEEIKKEAEELIEELKKKGYNLPLRILEFALKEIEETNSEKYYEQ...   \n",
       "3529  SPEYKKFLELIKEAEAARKAGDLDKAKELLEKALELAKKMKAKSLI...   \n",
       "3530  DPLLAYKLLKLSQKALEKAYAEDRERAEELLEEAEAALRSLGDEAG...   \n",
       "3531  SEAARRARELFHEADELDKRGNPEEAEEVLREALELAREAGSPNLA...   \n",
       "\n",
       "                                             target_seq target_id_mod  \\\n",
       "0     ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...         VirB8   \n",
       "1     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...         FGFR2   \n",
       "2     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...         FGFR2   \n",
       "3     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...         FGFR2   \n",
       "4     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...         FGFR2   \n",
       "...                                                 ...           ...   \n",
       "3527  ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...         IL2Ra   \n",
       "3528  ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...         IL2Ra   \n",
       "3529  ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...         IL2Ra   \n",
       "3530  ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...         IL2Ra   \n",
       "3531  ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...         IL2Ra   \n",
       "\n",
       "     target_binder_ID  class_weight  target_weight  combined_weight  \n",
       "0             VirB8_1      0.000159       0.000631     1.004956e-07  \n",
       "1             FGFR2_1      0.000159       0.000029     4.686322e-09  \n",
       "2             FGFR2_2      0.000159       0.000029     4.686322e-09  \n",
       "3             FGFR2_3      0.000159       0.000029     4.686322e-09  \n",
       "4             FGFR2_4      0.000159       0.000029     4.686322e-09  \n",
       "...               ...           ...            ...              ...  \n",
       "3527         IL2Ra_62      0.000159       0.000947     1.507433e-07  \n",
       "3528         IL2Ra_63      0.000159       0.000947     1.507433e-07  \n",
       "3529         IL2Ra_64      0.000159       0.000947     1.507433e-07  \n",
       "3530         IL2Ra_65      0.000159       0.000947     1.507433e-07  \n",
       "3531         IL2Ra_66      0.000159       0.000947     1.507433e-07  \n",
       "\n",
       "[3532 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7777220-1752-437c-83f3-00203d39a10b",
   "metadata": {},
   "source": [
    "# 13(leave-1-target-cluster-out)-fold CV training + weighting of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d549dd-9ca8-48c0-9838-7d9299c6da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [\n",
    "    [\"VirB8\"], [\"FGFR2\"], [\"IL7Ra\"], [\"InsulinR\"],\n",
    "    [\"EGFR\", \"EGFR_2\", \"EGFR_3\"],     # keep together\n",
    "    [\"SARS_CoV2_RBD\"], [\"Pdl1\"], [\"TrkA\"], [\"IL10Ra\"],\n",
    "    [\"LTK\"], [\"Mdm2\"],\n",
    "    [\"sntx\", \"sntx_2\"],               # keep together\n",
    "    [\"IL2Ra\"],\n",
    "]\n",
    "\n",
    "random.Random(0).shuffle(clusters)\n",
    "folds = np.array_split(np.array(clusters, dtype=object), len(clusters))   # list of np arrays\n",
    "targets_folds = []\n",
    "for f in folds:\n",
    "    flat = []\n",
    "    for group in f:\n",
    "        flat.extend(group)\n",
    "    targets_folds.append(flat)\n",
    "\n",
    "def build_cv_splits(targets_folds):\n",
    "    val_folds, train_folds = [], []\n",
    "    K = len(targets_folds)\n",
    "    for i in range(K):\n",
    "        val_targets = list(targets_folds[i])  # copy\n",
    "        train_targets = [t for j, fold in enumerate(targets_folds) if j != i for t in fold]\n",
    "        val_folds.append(val_targets)\n",
    "        train_folds.append(train_targets)\n",
    "    return val_folds, train_folds\n",
    "\n",
    "val_folds, train_folds = build_cv_splits(targets_folds)\n",
    "cv_splits = list(zip(val_folds, train_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9074fe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : training instances : 1409, validation instances : 2123\n",
      "Fold 2 : training instances : 3436, validation instances : 96\n",
      "Fold 3 : training instances : 3499, validation instances : 33\n",
      "Fold 4 : training instances : 3433, validation instances : 99\n",
      "Fold 5 : training instances : 3483, validation instances : 49\n",
      "Fold 6 : training instances : 3361, validation instances : 171\n",
      "Fold 7 : training instances : 3415, validation instances : 117\n",
      "Fold 8 : training instances : 3404, validation instances : 128\n",
      "Fold 9 : training instances : 3510, validation instances : 22\n",
      "Fold 10 : training instances : 3098, validation instances : 434\n",
      "Fold 11 : training instances : 3433, validation instances : 99\n",
      "Fold 12 : training instances : 3466, validation instances : 66\n",
      "Fold 13 : training instances : 3437, validation instances : 95\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(cv_splits)):\n",
    "    val_targets = cv_splits[idx][0]\n",
    "    vals = len(interaction_df[interaction_df.target_id_mod.isin(val_targets)])\n",
    "    trains = len(interaction_df) - vals\n",
    "    print(f\"Fold {idx+1} : training instances : {trains}, validation instances : {vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0f487f-fd6d-41e7-8355-bfa1f924a202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : validation targets : ['FGFR2']\n",
      "Fold 2 : validation targets : ['Mdm2']\n",
      "Fold 3 : validation targets : ['LTK']\n",
      "Fold 4 : validation targets : ['SARS_CoV2_RBD']\n",
      "Fold 5 : validation targets : ['sntx', 'sntx_2']\n",
      "Fold 6 : validation targets : ['IL7Ra']\n",
      "Fold 7 : validation targets : ['InsulinR']\n",
      "Fold 8 : validation targets : ['TrkA']\n",
      "Fold 9 : validation targets : ['IL10Ra']\n",
      "Fold 10 : validation targets : ['EGFR', 'EGFR_2', 'EGFR_3']\n",
      "Fold 11 : validation targets : ['VirB8']\n",
      "Fold 12 : validation targets : ['IL2Ra']\n",
      "Fold 13 : validation targets : ['Pdl1']\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(cv_splits)):\n",
    "    val_targets = cv_splits[idx][0]\n",
    "    train_targets = cv_splits[idx][1]\n",
    "    print(f\"Fold {idx+1} : validation targets : {val_targets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17abeb",
   "metadata": {},
   "source": [
    "#### Creating separate targets/ binder dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d5147ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets df\n",
    "target_df = interaction_df[[\"target_id_mod\",\"target_seq\"]].rename(columns={\"target_seq\":\"sequence\", \"target_id_mod\" : \"ID\"})\n",
    "target_df[\"seq_len\"] = target_df[\"sequence\"].apply(len)\n",
    "target_df = target_df.drop_duplicates(subset=[\"ID\",\"sequence\"])\n",
    "target_df = target_df.set_index(\"ID\")\n",
    "\n",
    "# Binders df\n",
    "binder_df = interaction_df[[\"target_binder_ID\",\"binder_seq\", \"binder\", \"class_weight\", \"target_weight\", \"combined_weight\"]].rename(columns={\"binder_seq\":\"sequence\", \"target_binder_ID\" : \"ID\", \"binder\" : \"label\"})\n",
    "binder_df[\"seq_len\"] = binder_df[\"sequence\"].apply(len)\n",
    "binder_df = binder_df.set_index(\"ID\")\n",
    "\n",
    "# Interaction Dict\n",
    "interaction_Dict = dict(enumerate(zip(interaction_df[\"target_id_mod\"], interaction_df[\"target_binder_ID\"]), start=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a793de7-ca60-4c83-9028-1f489f5caa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>target_weight</th>\n",
       "      <th>combined_weight</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VirB8_1</th>\n",
       "      <td>LDFIVFAGPEKAIKFYKEMAKRNLEVKIWIDGDWAVVQVK</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>1.004956e-07</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGFR2_1</th>\n",
       "      <td>SEQDETMHRIVRSVIQHAYKHNDEMAEYFAQNAAEIYKEQNKSEEA...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.686322e-09</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGFR2_2</th>\n",
       "      <td>DYKQLKKHATKLLELAKKDPSSKRDLLRTAASYANKVLFEDSDPRA...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.686322e-09</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGFR2_3</th>\n",
       "      <td>DEKEELERRANRVAFLAIQIQNEEYHRILAELYVQFMKAAENNDTE...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.686322e-09</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGFR2_4</th>\n",
       "      <td>PDNKEKLMSIAVQLILRINEAARSEEQWRYANRAAFAAVEASSGSD...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.686322e-09</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL2Ra_62</th>\n",
       "      <td>DLRKYAAELVDRLAEKYNLDSDQYNALVRLASELVWQGKSKEEIEK...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1.507433e-07</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL2Ra_63</th>\n",
       "      <td>SKEEIKKEAEELIEELKKKGYNLPLRILEFALKEIEETNSEKYYEQ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1.507433e-07</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL2Ra_64</th>\n",
       "      <td>SPEYKKFLELIKEAEAARKAGDLDKAKELLEKALELAKKMKAKSLI...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1.507433e-07</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL2Ra_65</th>\n",
       "      <td>DPLLAYKLLKLSQKALEKAYAEDRERAEELLEEAEAALRSLGDEAG...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1.507433e-07</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL2Ra_66</th>\n",
       "      <td>SEAARRARELFHEADELDKRGNPEEAEEVLREALELAREAGSPNLA...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1.507433e-07</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3532 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   sequence  label  \\\n",
       "ID                                                                   \n",
       "VirB8_1            LDFIVFAGPEKAIKFYKEMAKRNLEVKIWIDGDWAVVQVK  False   \n",
       "FGFR2_1   SEQDETMHRIVRSVIQHAYKHNDEMAEYFAQNAAEIYKEQNKSEEA...  False   \n",
       "FGFR2_2   DYKQLKKHATKLLELAKKDPSSKRDLLRTAASYANKVLFEDSDPRA...  False   \n",
       "FGFR2_3   DEKEELERRANRVAFLAIQIQNEEYHRILAELYVQFMKAAENNDTE...  False   \n",
       "FGFR2_4   PDNKEKLMSIAVQLILRINEAARSEEQWRYANRAAFAAVEASSGSD...  False   \n",
       "...                                                     ...    ...   \n",
       "IL2Ra_62  DLRKYAAELVDRLAEKYNLDSDQYNALVRLASELVWQGKSKEEIEK...  False   \n",
       "IL2Ra_63  SKEEIKKEAEELIEELKKKGYNLPLRILEFALKEIEETNSEKYYEQ...  False   \n",
       "IL2Ra_64  SPEYKKFLELIKEAEAARKAGDLDKAKELLEKALELAKKMKAKSLI...  False   \n",
       "IL2Ra_65  DPLLAYKLLKLSQKALEKAYAEDRERAEELLEEAEAALRSLGDEAG...  False   \n",
       "IL2Ra_66  SEAARRARELFHEADELDKRGNPEEAEEVLREALELAREAGSPNLA...  False   \n",
       "\n",
       "          class_weight  target_weight  combined_weight  seq_len  \n",
       "ID                                                               \n",
       "VirB8_1       0.000159       0.000631     1.004956e-07       40  \n",
       "FGFR2_1       0.000159       0.000029     4.686322e-09       62  \n",
       "FGFR2_2       0.000159       0.000029     4.686322e-09       61  \n",
       "FGFR2_3       0.000159       0.000029     4.686322e-09       64  \n",
       "FGFR2_4       0.000159       0.000029     4.686322e-09       64  \n",
       "...                ...            ...              ...      ...  \n",
       "IL2Ra_62      0.000159       0.000947     1.507433e-07       55  \n",
       "IL2Ra_63      0.000159       0.000947     1.507433e-07       56  \n",
       "IL2Ra_64      0.000159       0.000947     1.507433e-07       56  \n",
       "IL2Ra_65      0.000159       0.000947     1.507433e-07       57  \n",
       "IL2Ra_66      0.000159       0.000947     1.507433e-07       57  \n",
       "\n",
       "[3532 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b453e2b-b73b-42ad-a302-5499acaa20e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VirB8</th>\n",
       "      <td>ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGFR2</th>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL7Ra</th>\n",
       "      <td>DYSFSCYSQLEVNGSQHSLTCAFEDPDVNTTNLEFEICGALVEVKC...</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InsulinR</th>\n",
       "      <td>EVCPGMDIRNNLTRLHELENCSVIEGHLQILLMFKTRPEDFRDLSF...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGFR</th>\n",
       "      <td>RKVCNGIGIGEFKDSLSINATNIKHFKNCTSISGDLHILPVAFRGD...</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SARS_CoV2_RBD</th>\n",
       "      <td>TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pdl1</th>\n",
       "      <td>NAFTVTVPKDLYVVEYGSNMTIECKFPVEKQLDLAALIVYWEMEDK...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGFR_2</th>\n",
       "      <td>LEEKKVCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYV...</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrkA</th>\n",
       "      <td>VSFPASVQLHTAVEMHHWCIPFSVDGQPAPSLRWLFNGSVLNETSF...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL10Ra</th>\n",
       "      <td>GTELPSPPSVWFEAEFFHHILHWTPIPQQSESTCYEVALLRYGIES...</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTK</th>\n",
       "      <td>GSWLFSTCGASGRHGPTQTQCDGAYAGTSVVVTVGAAGQLRGVQLW...</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mdm2</th>\n",
       "      <td>ETLVRPKPLLLKLLKSVGAQKDTYTMKEVLFYLGQYIMTKRLYDEK...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGFR_3</th>\n",
       "      <td>VCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYVQRNYD...</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sntx</th>\n",
       "      <td>MICYNQQSSQPPTTKTCSETSCYKKTWRDHRGTIIERGCGCPKVKP...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sntx_2</th>\n",
       "      <td>MICHNQQSSQPPTTKTCSEGQCYKKTWRDHRGTIIERGCGCPTVKP...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL2Ra</th>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        sequence  seq_len\n",
       "ID                                                                       \n",
       "VirB8          ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...      138\n",
       "FGFR2          RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...      101\n",
       "IL7Ra          DYSFSCYSQLEVNGSQHSLTCAFEDPDVNTTNLEFEICGALVEVKC...      193\n",
       "InsulinR       EVCPGMDIRNNLTRLHELENCSVIEGHLQILLMFKTRPEDFRDLSF...      150\n",
       "EGFR           RKVCNGIGIGEFKDSLSINATNIKHFKNCTSISGDLHILPVAFRGD...      191\n",
       "SARS_CoV2_RBD  TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...      195\n",
       "Pdl1           NAFTVTVPKDLYVVEYGSNMTIECKFPVEKQLDLAALIVYWEMEDK...      115\n",
       "EGFR_2         LEEKKVCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYV...      621\n",
       "TrkA           VSFPASVQLHTAVEMHHWCIPFSVDGQPAPSLRWLFNGSVLNETSF...      101\n",
       "IL10Ra         GTELPSPPSVWFEAEFFHHILHWTPIPQQSESTCYEVALLRYGIES...      207\n",
       "LTK            GSWLFSTCGASGRHGPTQTQCDGAYAGTSVVVTVGAAGQLRGVQLW...      301\n",
       "Mdm2           ETLVRPKPLLLKLLKSVGAQKDTYTMKEVLFYLGQYIMTKRLYDEK...       85\n",
       "EGFR_3         VCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYVQRNYD...      157\n",
       "sntx           MICYNQQSSQPPTTKTCSETSCYKKTWRDHRGTIIERGCGCPKVKP...       60\n",
       "sntx_2         MICHNQQSSQPPTTKTCSEGQCYKKTWRDHRGTIIERGCGCPTVKP...       60\n",
       "IL2Ra          ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...      165"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613c58b2",
   "metadata": {},
   "source": [
    "#### Creating separate targets/ binder dataframes (for validation/ training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e81e9d12-9cc0-40de-9509-0d16f2b111b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Reading in ESM-embeddings from folder: 100%|█████████████████████████████████████████| 16/16 [00:00<00:00, 172.58it/s]\n",
      "# Reading in ESM-embeddings from folder: 100%|█████████████████████████████████████| 3532/3532 [00:06<00:00, 561.56it/s]\n"
     ]
    }
   ],
   "source": [
    "class CLIP_meta_analysis_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, sequence_df, esm_encoding_paths, embedding_dim=1152, padding_value=-5000):\n",
    "\n",
    "        super(CLIP_meta_analysis_dataset, self).__init__()\n",
    "\n",
    "        self.sequence_df = sequence_df # target/binder_df\n",
    "        self.max_length = sequence_df[\"seq_len\"].max()\n",
    "        self.sequence_df[\"index_num\"] = np.arange(len(self.sequence_df))\n",
    "        # print(self.sequence_df)\n",
    "        self.esm_encoding_paths = esm_encoding_paths\n",
    "        num_samples = len(self.sequence_df)\n",
    "        \n",
    "        self.x = torch.full((num_samples, self.max_length, embedding_dim), padding_value, dtype=torch.float32)\n",
    "\n",
    "        self.accessions = self.sequence_df.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        \n",
    "        # Load embeddings into the pre-allocated tensor\n",
    "        all_acc_list = self.accessions\n",
    "        all_acc_loaded_list = []\n",
    "\n",
    "        iterator = tqdm(all_acc_list, position=0, leave=True, total=num_samples, desc=\"# Reading in ESM-embeddings from folder\")\n",
    "        for i, accession in enumerate(iterator):\n",
    "            npy_path = os.path.join(esm_encoding_paths, f\"{accession}.npy\")\n",
    "            try:\n",
    "                embd = np.load(npy_path)[0]\n",
    "                length_to_pad = self.max_length - len(embd)\n",
    "                if length_to_pad > 0:\n",
    "                    zero_padding = np.ones((length_to_pad, embd.shape[1])) * padding_value\n",
    "                    padded_array = np.concatenate((embd, zero_padding), axis=0)\n",
    "                else:\n",
    "                    padded_array = embd[:self.max_length] \n",
    "                self.x[i] = torch.tensor(padded_array, dtype=torch.float32)\n",
    "                all_acc_loaded_list.append(accession)\n",
    "            except FileNotFoundError as e:\n",
    "                raise FileNotFoundError(f\"Embedding file {accession}.npy not found.\")\n",
    "            \n",
    "        missing = sorted(set(all_acc_list) - set(all_acc_loaded_list))\n",
    "        if missing:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Missing {len(missing)} embedding files in '{esm_encoding_paths}'. \"\n",
    "                f\"Examples: {missing}\")\n",
    "          \n",
    "    def __len__(self):\n",
    "        return int(self.x.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx]\n",
    "    \n",
    "    # add a helper:\n",
    "    def get_by_name(self, name: str):\n",
    "        return self.x[self.name_to_row[name]]\n",
    "\n",
    "targets_dataset = CLIP_meta_analysis_dataset(target_df, esm_encoding_paths=\"/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/data/meta_analysis/targets_embeddings\", embedding_dim=1152)\n",
    "binders_dataset = CLIP_meta_analysis_dataset(binder_df, esm_encoding_paths=\"/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/data/meta_analysis/binders_embeddings\", embedding_dim=1152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a8fc3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3036e-02, -2.4448e-03, -6.8176e-03,  ...,  5.2219e-03,\n",
       "          1.3421e-02,  1.3365e-02],\n",
       "        [ 3.5381e-03, -1.6180e-04, -2.7373e-02,  ...,  3.8627e-02,\n",
       "          1.8391e-02,  2.9930e-02],\n",
       "        [-5.4220e-03, -4.6685e-03, -5.6514e-02,  ...,  2.7079e-02,\n",
       "          3.4216e-02,  9.9046e-03],\n",
       "        ...,\n",
       "        [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "         -5.0000e+03, -5.0000e+03],\n",
       "        [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "         -5.0000e+03, -5.0000e+03],\n",
       "        [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "         -5.0000e+03, -5.0000e+03]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binders_dataset[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9972db2-40f6-451b-bcb4-27b2c11f889c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(targets_dataset[0], targets_dataset.get_by_name(\"VirB8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50a1e489-9e4c-4882-acf6-b32a5b388359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(binders_dataset[0], binders_dataset.get_by_name(\"VirB8_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f7095e3-cf51-4a85-a515-f82c117964bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def binder_to_target_name(bname: str) -> str:\n",
    "    parts = bname.split(\"_\")\n",
    "    if bname.startswith(\"SARS\"):\n",
    "        return \"SARS_CoV2_RBD\"\n",
    "    if len(parts) == 3:\n",
    "        return f\"{parts[0]}_{parts[1]}\"\n",
    "    return parts[0]\n",
    "\n",
    "def binder_target_label(targets_dataset, binders_dataset, binder_ids, interaction_df, stack=True):\n",
    "    \n",
    "    listof_bindertargetlabel = []\n",
    "    \n",
    "    for bname in binder_ids:\n",
    "        tname = binder_to_target_name(bname)\n",
    "\n",
    "        # get embeddings by name\n",
    "        b_emb = binders_dataset.get_by_name(bname)\n",
    "        t_emb = targets_dataset.get_by_name(tname)\n",
    "\n",
    "        # get label from df\n",
    "        s = interaction_df.loc[interaction_df['target_binder_ID'] == bname, 'binder']\n",
    "        # if s.empty:\n",
    "        #     raise ValueError(f\"No label found in interaction_df for binder id '{bname}'\")\n",
    "        lbl = torch.tensor(float(s.iat[0]), dtype=torch.float32)\n",
    "\n",
    "        listof_bindertargetlabel.append((b_emb, t_emb, lbl))\n",
    "\n",
    "    return listof_bindertargetlabel\n",
    "\n",
    "# validation_data_5clusters = []\n",
    "# training_data_5clusters = []\n",
    "\n",
    "# for i, split in enumerate(cv_splits):\n",
    "#     validation, training = split[0], split[1]\n",
    "    \n",
    "#     validation_binders = interaction_df.loc[interaction_df[\"target_id_mod\"].isin(validation), \"target_binder_ID\"].tolist()\n",
    "#     training_binders = interaction_df.loc[interaction_df[\"target_id_mod\"].isin(training), \"target_binder_ID\"].tolist()\n",
    "\n",
    "#     listof_bindertargetlabel = binder_target_label(targets_dataset, binders_dataset, validation_binders, interaction_df)\n",
    "#     validation_data_5clusters.append(listof_bindertargetlabel)\n",
    "    \n",
    "#     listof_bindertargetlabel = binder_target_label(targets_dataset, binders_dataset, training_binders, interaction_df)\n",
    "#     training_data_5clusters.append(listof_bindertargetlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1d7ca17-ddfc-495c-8c07-6c4fdaed73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(validation_data_5clusters)\n",
    "# >> 5 # 5 folds\n",
    "# len(validation_data_5clusters[0])\n",
    "# >> 249 # number of  instances per fold \"1\" used ofr validation\n",
    "# len(validation_data_5clusters[0][0])\n",
    "# >> 3 # binder_emb, target_emb, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d5a7adc-f98e-4c66-867e-d76e08e23189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(validation_data_5clusters)):\n",
    "#     print(f\"Run {i+1} : len(val_dataset) : {len(validation_data_5clusters[i])}, len(train_dataset) : {len(training_data_5clusters[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6447c91-2e92-4a16-a72c-43edde4ea057",
   "metadata": {},
   "source": [
    "### Loading pretrained model for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ad60385-875b-46bb-9217-d57ed12594dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniCLIP_w_transformer_crossattn(\n",
       "  (transformerencoder): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=1152, out_features=1152, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "    (norm1): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (norm): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
       "  (cross_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=1152, out_features=1152, bias=True)\n",
       "  )\n",
       "  (prot_embedder): Sequential(\n",
       "    (0): Linear(in_features=1152, out_features=640, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=640, out_features=320, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = '../PPI_PLM/models/CLIP_no_structural_information/a1d0549b-3f90-4ce2-b795-7bca2276cb07_checkpoint_4/a1d0549b-3f90-4ce2-b795-7bca2276cb07_checkpoint_epoch_4.pth'\n",
    "checkpoint = torch.load(ckpt_path, weights_only=False, map_location=\"cpu\")\n",
    "# print(list(checkpoint[\"model_state_dict\"]))\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = MiniCLIP_w_transformer_crossattn()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "torch.cuda.empty_cache()  # frees cached blocks (not live tensors)\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d1467-30c5-4dd4-b704-0b3e5a77e346",
   "metadata": {},
   "source": [
    "### Loading training and validation datasets (DataLoaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0cbd965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-7.4324e-03,  2.6254e-04, -7.7275e-03,  ...,  5.6024e-03,\n",
       "           1.3973e-02,  1.4799e-02],\n",
       "         [-1.3152e-02,  4.0290e-02,  1.1565e-02,  ...,  9.0204e-03,\n",
       "           2.5051e-02,  2.8246e-02],\n",
       "         [ 6.4436e-03,  1.9148e-02, -2.1045e-02,  ...,  4.0891e-04,\n",
       "           1.0381e-02, -4.7295e-03],\n",
       "         ...,\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03],\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03],\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03]]),\n",
       " tensor([[ 3.5021e-03, -1.8118e-03, -3.0359e-03,  ...,  1.7072e-04,\n",
       "           6.6654e-03,  1.2242e-02],\n",
       "         [ 2.2083e-02,  1.7457e-02, -3.6554e-03,  ...,  1.6579e-02,\n",
       "           3.6905e-04,  1.7242e-02],\n",
       "         [-6.4675e-03,  1.0692e-02, -8.5746e-04,  ...,  2.8062e-02,\n",
       "          -1.3191e-02,  7.7366e-04],\n",
       "         ...,\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03],\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03],\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03]]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_binders = interaction_df[\"target_binder_ID\"].tolist()\n",
    "# all dataset: binder_enb, target_emb, label\n",
    "ALL_btl_list = binder_target_label(targets_dataset, binders_dataset, all_binders, interaction_df)\n",
    "ALL_btl_list.__len__()\n",
    "ALL_btl_list.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47e5d912-11dd-4260-80a6-81948e93bf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-7.4324e-03,  2.6254e-04, -7.7275e-03,  ...,  5.6024e-03,\n",
       "           1.3973e-02,  1.4799e-02],\n",
       "         [-1.3152e-02,  4.0290e-02,  1.1565e-02,  ...,  9.0204e-03,\n",
       "           2.5051e-02,  2.8246e-02],\n",
       "         [ 6.4436e-03,  1.9148e-02, -2.1045e-02,  ...,  4.0891e-04,\n",
       "           1.0381e-02, -4.7295e-03],\n",
       "         ...,\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03],\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03],\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03]]),\n",
       " tensor([[ 3.5021e-03, -1.8118e-03, -3.0359e-03,  ...,  1.7072e-04,\n",
       "           6.6654e-03,  1.2242e-02],\n",
       "         [ 2.2083e-02,  1.7457e-02, -3.6554e-03,  ...,  1.6579e-02,\n",
       "           3.6905e-04,  1.7242e-02],\n",
       "         [-6.4675e-03,  1.0692e-02, -8.5746e-04,  ...,  2.8062e-02,\n",
       "          -1.3191e-02,  7.7366e-04],\n",
       "         ...,\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03],\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03],\n",
       "         [-5.0000e+03, -5.0000e+03, -5.0000e+03,  ..., -5.0000e+03,\n",
       "          -5.0000e+03, -5.0000e+03]]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binders = torch.stack([torch.as_tensor(b) for b,_,_ in ALL_btl_list])   # [N, L, D]\n",
    "targets = torch.stack([torch.as_tensor(t) for _,t,_ in ALL_btl_list])   # [N, L, D]\n",
    "labels  = torch.tensor([float(y) for *_,y in ALL_btl_list], dtype=torch.float32)  # [N]\n",
    "\n",
    "ALL_btl = TensorDataset(binders, targets, labels)\n",
    "ALL_btl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6087d215-24aa-495c-8d61-15afdc5aaa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairListDataset(torch.utils.data.Dataset):\n",
    "    # examples: list of (binder_emb, target_emb, label)\n",
    "    # target_ids: parallel list of target_id_mod (same order)\n",
    "    def __init__(self, examples, target_ids):\n",
    "        assert len(examples) == len(target_ids)\n",
    "        self.examples = examples\n",
    "        self.target_ids = list(map(str, target_ids))\n",
    "\n",
    "    def __len__(self): return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        b, t, y = self.examples[idx]\n",
    "        return (torch.as_tensor(b, dtype=torch.float32),\n",
    "                torch.as_tensor(t, dtype=torch.float32),\n",
    "                torch.tensor(float(y), dtype=torch.float32),\n",
    "                self.target_ids[idx])  # <- keep the id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7291fb43-71c5-4462-b16d-9e37cf7e108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binder_chain</th>\n",
       "      <th>target_chains</th>\n",
       "      <th>binder</th>\n",
       "      <th>binder_seq</th>\n",
       "      <th>target_seq</th>\n",
       "      <th>target_id_mod</th>\n",
       "      <th>target_binder_ID</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>target_weight</th>\n",
       "      <th>combined_weight</th>\n",
       "      <th>combined_weight_account_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>LDFIVFAGPEKAIKFYKEMAKRNLEVKIWIDGDWAVVQVK</td>\n",
       "      <td>ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...</td>\n",
       "      <td>VirB8</td>\n",
       "      <td>VirB8_1</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>SEQDETMHRIVRSVIQHAYKHNDEMAEYFAQNAAEIYKEQNKSEEA...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_1</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>DYKQLKKHATKLLELAKKDPSSKRDLLRTAASYANKVLFEDSDPRA...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_2</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>DEKEELERRANRVAFLAIQIQNEEYHRILAELYVQFMKAAENNDTE...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_3</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>PDNKEKLMSIAVQLILRINEAARSEEQWRYANRAAFAAVEASSGSD...</td>\n",
       "      <td>RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>FGFR2_4</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>DLRKYAAELVDRLAEKYNLDSDQYNALVRLASELVWQGKSKEEIEK...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_62</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>SKEEIKKEAEELIEELKKKGYNLPLRILEFALKEIEETNSEKYYEQ...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_63</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>SPEYKKFLELIKEAEAARKAGDLDKAKELLEKALELAKKMKAKSLI...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_64</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>DPLLAYKLLKLSQKALEKAYAEDRERAEELLEEAEAALRSLGDEAG...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_65</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>A</td>\n",
       "      <td>[\"B\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>SEAARRARELFHEADELDKRGNPEEAEEVLREALELAREAGSPNLA...</td>\n",
       "      <td>ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...</td>\n",
       "      <td>IL2Ra</td>\n",
       "      <td>IL2Ra_66</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3532 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     binder_chain target_chains  binder  \\\n",
       "0               A         [\"B\"]   False   \n",
       "1               A         [\"B\"]   False   \n",
       "2               A         [\"B\"]   False   \n",
       "3               A         [\"B\"]   False   \n",
       "4               A         [\"B\"]   False   \n",
       "...           ...           ...     ...   \n",
       "3527            A         [\"B\"]   False   \n",
       "3528            A         [\"B\"]   False   \n",
       "3529            A         [\"B\"]   False   \n",
       "3530            A         [\"B\"]   False   \n",
       "3531            A         [\"B\"]   False   \n",
       "\n",
       "                                             binder_seq  \\\n",
       "0              LDFIVFAGPEKAIKFYKEMAKRNLEVKIWIDGDWAVVQVK   \n",
       "1     SEQDETMHRIVRSVIQHAYKHNDEMAEYFAQNAAEIYKEQNKSEEA...   \n",
       "2     DYKQLKKHATKLLELAKKDPSSKRDLLRTAASYANKVLFEDSDPRA...   \n",
       "3     DEKEELERRANRVAFLAIQIQNEEYHRILAELYVQFMKAAENNDTE...   \n",
       "4     PDNKEKLMSIAVQLILRINEAARSEEQWRYANRAAFAAVEASSGSD...   \n",
       "...                                                 ...   \n",
       "3527  DLRKYAAELVDRLAEKYNLDSDQYNALVRLASELVWQGKSKEEIEK...   \n",
       "3528  SKEEIKKEAEELIEELKKKGYNLPLRILEFALKEIEETNSEKYYEQ...   \n",
       "3529  SPEYKKFLELIKEAEAARKAGDLDKAKELLEKALELAKKMKAKSLI...   \n",
       "3530  DPLLAYKLLKLSQKALEKAYAEDRERAEELLEEAEAALRSLGDEAG...   \n",
       "3531  SEAARRARELFHEADELDKRGNPEEAEEVLREALELAREAGSPNLA...   \n",
       "\n",
       "                                             target_seq target_id_mod  \\\n",
       "0     ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...         VirB8   \n",
       "1     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...         FGFR2   \n",
       "2     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...         FGFR2   \n",
       "3     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...         FGFR2   \n",
       "4     RSPHRPILQAGLPANASTVVGGDVEFVCKVYSDAQPHIQWIKHVPY...         FGFR2   \n",
       "...                                                 ...           ...   \n",
       "3527  ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...         IL2Ra   \n",
       "3528  ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...         IL2Ra   \n",
       "3529  ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...         IL2Ra   \n",
       "3530  ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...         IL2Ra   \n",
       "3531  ELCDDDPPEIPHATFKAMAYKEGTMLNCECKRGFRRIKSGSLYMLC...         IL2Ra   \n",
       "\n",
       "     target_binder_ID  class_weight  target_weight  combined_weight  \\\n",
       "0             VirB8_1      0.000159       0.000631         0.000395   \n",
       "1             FGFR2_1      0.000159       0.000029         0.000094   \n",
       "2             FGFR2_2      0.000159       0.000029         0.000094   \n",
       "3             FGFR2_3      0.000159       0.000029         0.000094   \n",
       "4             FGFR2_4      0.000159       0.000029         0.000094   \n",
       "...               ...           ...            ...              ...   \n",
       "3527         IL2Ra_62      0.000159       0.000947         0.000553   \n",
       "3528         IL2Ra_63      0.000159       0.000947         0.000553   \n",
       "3529         IL2Ra_64      0.000159       0.000947         0.000553   \n",
       "3530         IL2Ra_65      0.000159       0.000947         0.000553   \n",
       "3531         IL2Ra_66      0.000159       0.000947         0.000553   \n",
       "\n",
       "      combined_weight_account_pos  \n",
       "0                        0.000198  \n",
       "1                        0.000047  \n",
       "2                        0.000047  \n",
       "3                        0.000047  \n",
       "4                        0.000047  \n",
       "...                           ...  \n",
       "3527                     0.000277  \n",
       "3528                     0.000277  \n",
       "3529                     0.000277  \n",
       "3530                     0.000277  \n",
       "3531                     0.000277  \n",
       "\n",
       "[3532 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_df[\"combined_weight\"] = (interaction_df[\"class_weight\"]+interaction_df[\"target_weight\"])/2\n",
    "multipliers = []\n",
    "for binder in interaction_df[\"binder\"]:\n",
    "    if binder == False:\n",
    "        multipliers.append(0.5)\n",
    "    else:\n",
    "        multipliers.append(1)\n",
    "interaction_df[\"combined_weight_account_pos\"] = interaction_df[\"combined_weight\"] * multipliers\n",
    "interaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "605a5ca7-0eeb-40b3-a3d8-0bb42b0fef96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " binder target_id_mod  combined_weight_account_pos\n",
      "   True          EGFR                     0.000884\n",
      "  False          EGFR                     0.000162\n",
      "   True        EGFR_2                     0.000743\n",
      "  False        EGFR_2                     0.000092\n",
      "   True        EGFR_3                     0.008452\n",
      "  False         FGFR2                     0.000047\n",
      "   True         FGFR2                     0.000654\n",
      "   True        IL10Ra                     0.002060\n",
      "  False        IL10Ra                     0.000750\n",
      "   True         IL2Ra                     0.001113\n",
      "  False         IL2Ra                     0.000277\n",
      "  False         IL7Ra                     0.000131\n",
      "   True         IL7Ra                     0.000822\n",
      "   True      InsulinR                     0.000906\n",
      "  False      InsulinR                     0.000173\n",
      "  False           LTK                     0.000513\n",
      "   True           LTK                     0.001586\n",
      "  False          Mdm2                     0.000203\n",
      "   True          Mdm2                     0.000965\n",
      "   True          Pdl1                     0.000968\n",
      "  False          Pdl1                     0.000204\n",
      "   True SARS_CoV2_RBD                     0.000955\n",
      "  False SARS_CoV2_RBD                     0.000198\n",
      "   True          TrkA                     0.000884\n",
      "  False          TrkA                     0.000162\n",
      "   True         VirB8                     0.000955\n",
      "  False         VirB8                     0.000198\n",
      "   True          sntx                     0.005848\n",
      "  False        sntx_2                     0.000403\n",
      "   True        sntx_2                     0.001366\n"
     ]
    }
   ],
   "source": [
    "u = interaction_df[['binder', 'target_id_mod', 'combined_weight_account_pos']].drop_duplicates(subset=['target_id_mod', 'binder'])\n",
    "print(u.sort_values('target_id_mod').to_string(index=False))\n",
    "# or as a dict:\n",
    "weight_map = u.set_index('target_id_mod')['combined_weight_account_pos'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bceb4e35-10d6-4d00-b432-82b2f7c72b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: {'IL2Ra': 1, 'InsulinR': 1, 'FGFR2': 7, 'sntx': 1, 'Mdm2': 4, 'EGFR': 1, 'EGFR_2': 2, 'IL7Ra': 1, 'LTK': 1, 'VirB8': 1}  | positives=8 / 20\n",
      "Batch 1: {'FGFR2': 7, 'InsulinR': 2, 'TrkA': 3, 'EGFR_3': 1, 'Mdm2': 3, 'IL10Ra': 1, 'IL7Ra': 1, 'sntx_2': 1, 'EGFR': 1}  | positives=7 / 20\n",
      "Batch 2: {'TrkA': 1, 'Mdm2': 3, 'FGFR2': 7, 'EGFR_2': 2, 'EGFR': 1, 'IL2Ra': 2, 'SARS_CoV2_RBD': 1, 'IL7Ra': 2, 'VirB8': 1}  | positives=6 / 20\n",
      "Batch 3: {'EGFR_2': 3, 'InsulinR': 2, 'IL2Ra': 1, 'FGFR2': 7, 'Mdm2': 3, 'IL7Ra': 2, 'TrkA': 1, 'EGFR': 1}  | positives=5 / 20\n",
      "Batch 4: {'EGFR_2': 3, 'SARS_CoV2_RBD': 2, 'IL10Ra': 2, 'EGFR_3': 1, 'FGFR2': 9, 'sntx': 1, 'IL7Ra': 1, 'EGFR': 1}  | positives=6 / 20\n",
      "Batch 5: {'FGFR2': 8, 'IL2Ra': 3, 'IL10Ra': 1, 'SARS_CoV2_RBD': 1, 'Mdm2': 4, 'EGFR': 1, 'EGFR_2': 2}  | positives=3 / 20\n",
      "Batch 6: {'SARS_CoV2_RBD': 1, 'LTK': 1, 'InsulinR': 3, 'sntx_2': 2, 'FGFR2': 6, 'VirB8': 4, 'IL10Ra': 1, 'Mdm2': 1, 'IL7Ra': 1}  | positives=11 / 20\n",
      "Batch 7: {'EGFR_2': 1, 'FGFR2': 10, 'LTK': 1, 'SARS_CoV2_RBD': 2, 'VirB8': 1, 'TrkA': 1, 'sntx': 1, 'Mdm2': 1, 'sntx_2': 1, 'IL7Ra': 1}  | positives=10 / 20\n",
      "Batch 8: {'FGFR2': 6, 'IL7Ra': 3, 'Mdm2': 2, 'IL2Ra': 1, 'EGFR_2': 1, 'TrkA': 1, 'VirB8': 1, 'EGFR_3': 1, 'sntx': 1, 'LTK': 1, 'IL10Ra': 1, 'InsulinR': 1}  | positives=8 / 20\n",
      "Batch 9: {'EGFR_3': 2, 'Mdm2': 2, 'FGFR2': 6, 'VirB8': 1, 'IL2Ra': 1, 'IL10Ra': 2, 'EGFR_2': 2, 'IL7Ra': 1, 'EGFR': 2, 'sntx': 1}  | positives=10 / 20\n",
      "Batch 10: {'IL7Ra': 2, 'FGFR2': 8, 'VirB8': 2, 'EGFR_3': 3, 'sntx_2': 1, 'IL10Ra': 1, 'InsulinR': 1, 'IL2Ra': 2}  | positives=10 / 20\n"
     ]
    }
   ],
   "source": [
    "train_targets = cv_splits[12][1]\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "\n",
    "train_weights_class = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"class_weight\"].tolist()\n",
    "train_weights_target = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"target_weight\"].tolist()\n",
    "train_weights_combined = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"combined_weight\"].tolist()\n",
    "train_weights_combined_boosted = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"combined_weight_account_pos\"].tolist()\n",
    "\n",
    "train_idx = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets)].index.tolist()\n",
    "train_target_ids = interaction_df.loc[train_idx, \"target_id_mod\"].astype(str).tolist()\n",
    "train_binders_ds = PairListDataset([ALL_btl[idx] for idx in train_idx], target_ids=train_target_ids)\n",
    "\n",
    "train_sampler = WeightedRandomSampler(weights=train_weights_combined, num_samples=len(train_binders_ds), replacement=True, generator = g)\n",
    "train_loader   = DataLoader(train_binders_ds,  batch_size=20, sampler=train_sampler)\n",
    "\n",
    "for bi, batch in enumerate(train_loader):\n",
    "    _, _, labels, ids = batch\n",
    "    c = Counter(ids)\n",
    "    print(f\"Batch {bi}: {dict(c)}  | positives={int(labels.sum().item())} / {labels.numel()}\")\n",
    "    if bi == 10: break  # first 5 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e0a5f6d-510a-4449-9fa7-58cc2b277be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: {'EGFR_2': 2, 'IL2Ra': 1, 'LTK': 1, 'IL10Ra': 1, 'Mdm2': 3, 'sntx': 3, 'FGFR2': 6, 'EGFR': 1, 'sntx_2': 1, 'SARS_CoV2_RBD': 1}  | positives=10 / 20\n",
      "Batch 1: {'Mdm2': 3, 'FGFR2': 7, 'IL7Ra': 2, 'InsulinR': 1, 'VirB8': 2, 'SARS_CoV2_RBD': 2, 'EGFR_3': 1, 'sntx': 2}  | positives=15 / 20\n",
      "Batch 2: {'IL2Ra': 2, 'FGFR2': 3, 'VirB8': 3, 'SARS_CoV2_RBD': 2, 'LTK': 1, 'IL10Ra': 1, 'sntx': 4, 'InsulinR': 2, 'EGFR_3': 1, 'EGFR': 1}  | positives=10 / 20\n",
      "Batch 3: {'IL2Ra': 2, 'FGFR2': 6, 'sntx': 2, 'SARS_CoV2_RBD': 2, 'VirB8': 2, 'EGFR': 1, 'TrkA': 1, 'Mdm2': 1, 'IL7Ra': 1, 'InsulinR': 1, 'EGFR_3': 1}  | positives=13 / 20\n",
      "Batch 4: {'FGFR2': 6, 'SARS_CoV2_RBD': 1, 'EGFR_2': 4, 'LTK': 2, 'IL2Ra': 1, 'Mdm2': 1, 'VirB8': 1, 'EGFR': 2, 'TrkA': 1, 'sntx': 1}  | positives=8 / 20\n",
      "Batch 5: {'IL7Ra': 1, 'FGFR2': 10, 'Mdm2': 2, 'EGFR': 1, 'VirB8': 3, 'InsulinR': 2, 'TrkA': 1}  | positives=15 / 20\n",
      "Batch 6: {'Mdm2': 2, 'FGFR2': 8, 'EGFR_3': 1, 'IL7Ra': 1, 'VirB8': 1, 'IL10Ra': 2, 'IL2Ra': 1, 'TrkA': 1, 'SARS_CoV2_RBD': 1, 'InsulinR': 1, 'EGFR_2': 1}  | positives=10 / 20\n",
      "Batch 7: {'SARS_CoV2_RBD': 2, 'LTK': 1, 'FGFR2': 5, 'Mdm2': 3, 'InsulinR': 1, 'sntx': 1, 'EGFR_3': 2, 'IL7Ra': 2, 'IL2Ra': 2, 'TrkA': 1}  | positives=13 / 20\n",
      "Batch 8: {'IL10Ra': 1, 'EGFR_2': 1, 'LTK': 1, 'EGFR_3': 2, 'FGFR2': 7, 'IL7Ra': 3, 'EGFR': 1, 'InsulinR': 1, 'SARS_CoV2_RBD': 1, 'VirB8': 2}  | positives=13 / 20\n",
      "Batch 9: {'sntx_2': 1, 'FGFR2': 9, 'VirB8': 1, 'IL7Ra': 1, 'InsulinR': 1, 'SARS_CoV2_RBD': 1, 'Mdm2': 3, 'IL2Ra': 1, 'EGFR_3': 2}  | positives=12 / 20\n",
      "Batch 10: {'EGFR_2': 4, 'EGFR': 1, 'FGFR2': 6, 'sntx': 2, 'EGFR_3': 2, 'sntx_2': 1, 'IL7Ra': 1, 'VirB8': 1, 'Mdm2': 2}  | positives=11 / 20\n"
     ]
    }
   ],
   "source": [
    "train_sampler = WeightedRandomSampler(weights=train_weights_combined_boosted, num_samples=len(train_binders_ds), replacement=True, generator = g)\n",
    "train_loader   = DataLoader(train_binders_ds,  batch_size=20, sampler=train_sampler)\n",
    "\n",
    "for bi, batch in enumerate(train_loader):\n",
    "    _, _, labels, ids = batch\n",
    "    c = Counter(ids)\n",
    "    print(f\"Batch {bi}: {dict(c)}  | positives={int(labels.sum().item())} / {labels.numel()}\")\n",
    "    if bi == 10: break  # first 5 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8047c02d-fb9e-4b4a-a02b-4faa554ee474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_targets = cv_splits[0][0]\n",
    "# train_targets = cv_splits[0][1]\n",
    "\n",
    "# # indexes of validation binders\n",
    "# val_idx = interaction_df.loc[interaction_df.target_id_mod.isin(val_targets)].index.tolist()\n",
    "\n",
    "# # weights of validation binders\n",
    "# # val_weights = interaction_df.loc[interaction_df.target_id_mod.isin(val_targets), \"class_weight\"].tolist()\n",
    "\n",
    "# # validation dataset : binder_emb, target_emb, label\n",
    "# val_binders_ds = [ALL_btl[idx] for idx in val_idx]\n",
    "# val_binders_ds = PairListDataset(val_binders_ds)\n",
    "\n",
    "# # indexes of training binders\n",
    "# train_idx = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets)].index.tolist()\n",
    "\n",
    "# # weights of training binders\n",
    "# train_weights_class = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"class_weight\"].tolist()\n",
    "# train_weights_target = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"target_weight\"].tolist()\n",
    "# train_weights_combined = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"combined_weight\"].tolist()\n",
    "\n",
    "# # training dataset : binder_emb, target_emb, label\n",
    "# train_binders_ds = [ALL_btl[idx] for idx in train_idx]\n",
    "# train_binders_ds = PairListDataset(train_binders_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d89b27f6-f9b9-4642-800b-302bff86043b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory:  34.072559616\n",
      "Reserved memory:  0.065011712\n",
      "Allocated memory:  0.0\n",
      "Free memory:  0.008080896\n"
     ]
    }
   ],
   "source": [
    "import gc, torch\n",
    "# del obj  # any large temps you created in the cell\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "# print_mem_consumption()\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print_mem_consumption()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fd231-30a4-4408-a565-f508427e6750",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f811da79-c46e-47c6-af0a-c14ec3810026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=20):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "class TrainWrapper_MetaAnal():\n",
    "\n",
    "    def __init__(self, model, training_loader, validation_loader, test_dataset, \n",
    "                 optimizer, scheduler, EPOCHS, runID, device, test_indexes_for_auROC=None,\n",
    "                 auROC_batch_size=18, model_save_steps=False, model_save_path=False, \n",
    "                 v=False, wandb_tracker=False, split_id=None):\n",
    "        \n",
    "        self.model = model \n",
    "        self.training_loader = training_loader\n",
    "        self.validation_loader = validation_loader\n",
    "        self.EPOCHS = EPOCHS\n",
    "        self.wandb_tracker = wandb_tracker\n",
    "        self.model_save_steps = model_save_steps\n",
    "        self.verbose = v\n",
    "        self.split_id = split_id\n",
    "        self.best_vloss = 1e09\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.runID = runID\n",
    "        self.trained_model_dir = model_save_path\n",
    "        self.print_frequency_loss = 1\n",
    "        self.device = device\n",
    "        self.test_indexes_for_auROC = test_indexes_for_auROC\n",
    "        self.auROC_batch_size = auROC_batch_size\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch_data in self.training_loader:\n",
    "            if batch_data[0].size(0) == 1:\n",
    "                continue\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.model.training_step(batch_data, self.device)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step()\n",
    "\n",
    "        return running_loss / max(1, len(self.training_loader))\n",
    "\n",
    "    def calc_auroc_aupr_on_indexes(self, model, validation_dataset, batch_size=20, pad_value=-5000.0):\n",
    "\n",
    "        model.eval()\n",
    "        all_scores, all_labels = [], []\n",
    "        batched_data = batch(validation_dataset, n=batch_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for one_batch in batched_data:\n",
    "                items = [i for i in one_batch]\n",
    "                binders = torch.stack([binder_emb for (binder_emb, _, _) in items]).to(self.device)\n",
    "                targets = torch.stack([target_emb for (_, target_emb, _) in items]).to(self.device)\n",
    "                labels = np.array([float(lbl) for *_, lbl in items], dtype=np.float32)\n",
    "\n",
    "                logits = model.forward(binders, targets).detach().cpu().numpy()\n",
    "\n",
    "                all_scores.extend(logits.tolist())\n",
    "                all_labels.extend(labels.tolist())\n",
    "\n",
    "        all_scores = np.array(all_scores, dtype=np.float64)\n",
    "        all_labels = np.array(all_labels, dtype=np.int64)\n",
    "\n",
    "        fpr, tpr, _ = metrics.roc_curve(all_labels, all_scores)\n",
    "        auroc = metrics.roc_auc_score(all_labels, all_scores)\n",
    "        aupr  = metrics.average_precision_score(all_labels, all_scores)\n",
    "\n",
    "        return auroc, aupr, fpr, tpr\n",
    "    \n",
    "    def validate(self, dataloader, indexes_for_auc=False, auROC_dataset=False):\n",
    "        self.model.eval()\n",
    "        running_loss, n_loss = 0.0, 0\n",
    "        all_scores, all_labels = [], []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for one_batch in dataloader:\n",
    "                loss, logits, labels = self.model.validation_step(one_batch, self.device)\n",
    "                running_loss += float(loss)\n",
    "                n_loss += 1\n",
    "                all_scores.append(logits.detach().float().cpu())\n",
    "                all_labels.append(labels.detach().long().cpu())\n",
    "    \n",
    "        val_loss = running_loss / max(1, n_loss)\n",
    "    \n",
    "        if all_scores:\n",
    "            scores = torch.cat(all_scores).numpy()\n",
    "            labs   = torch.cat(all_labels).numpy()\n",
    "            val_auroc = metrics.roc_auc_score(labs, scores)\n",
    "            val_aupr  = metrics.average_precision_score(labs, scores)\n",
    "        else:\n",
    "            scores = np.array([], dtype=np.float32)   # ensure defined\n",
    "            labs   = np.array([], dtype=np.int64)\n",
    "            val_auroc = float(\"nan\")\n",
    "            val_aupr  = float(\"nan\")\n",
    "    \n",
    "        return val_loss, val_auroc, val_aupr, scores, labs\n",
    "\n",
    "    def train_model(self):\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Training model {str(self.runID)}\")\n",
    "        \n",
    "        # Pre-training snapshot\n",
    "        val_loss, val_auroc, val_aupr, scores, labs = self.validate(\n",
    "            dataloader=self.validation_loader,\n",
    "            indexes_for_auc=self.test_indexes_for_auROC,\n",
    "            auROC_dataset=self.test_dataset\n",
    "        )\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f'Before training - Val Loss {val_loss:.4f} | '\n",
    "                f'Val AUROC {val_auroc if val_auroc==val_auroc else float(\"nan\"):.4f} | '\n",
    "                f'Val AUPR {val_aupr if val_aupr==val_aupr else float(\"nan\"):.4f}'\n",
    "            )\n",
    "            \n",
    "        if self.wandb_tracker:\n",
    "            self.wandb_tracker.log(\n",
    "                {\"Val Loss\": val_loss, \"Val AUROC\": val_auroc, \"Val AUPR\": val_aupr},\n",
    "                step=0\n",
    "            )\n",
    "            \n",
    "        # --- Epoch loop ---\n",
    "        for epoch in range(1, self.EPOCHS + 1):\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            train_loss = self.train_one_epoch()\n",
    "            val_loss, val_auroc, val_aupr, scores, labs = self.validate(\n",
    "                dataloader=self.validation_loader,\n",
    "                indexes_for_auc=self.test_indexes_for_auROC,\n",
    "                auROC_dataset=self.test_dataset\n",
    "            )\n",
    "    \n",
    "            if self.verbose and (epoch % self.print_frequency_loss == 0):\n",
    "                print(\n",
    "                    f'EPOCH {epoch} - Train Loss {train_loss:.4f} | '\n",
    "                    f'Val Loss {val_loss:.4f} | Val AUROC {val_auroc if val_auroc==val_auroc else float(\"nan\"):.4f} | '\n",
    "                    f'Val AUPR {val_aupr if val_aupr==val_aupr else float(\"nan\"):.4f}'\n",
    "                )\n",
    "\n",
    "            if self.scheduler is not None and self.wandb_tracker:\n",
    "                lr = float(self.optimizer.param_groups[0][\"lr\"])\n",
    "                self.wandb_tracker.log({\"learning_rate\": lr}, step=epoch)\n",
    "\n",
    "            if scores.size and labs.size:\n",
    "                pos_mask = labs == 1\n",
    "                neg_mask = labs == 0\n",
    "                median_pos = float(np.median(scores[pos_mask])) if pos_mask.any() else float(\"nan\")\n",
    "                median_neg = float(np.median(scores[neg_mask])) if neg_mask.any() else float(\"nan\")\n",
    "                gap = median_pos - median_neg if np.isfinite(median_pos) and np.isfinite(median_neg) else float(\"nan\")\n",
    "            else:\n",
    "                median_pos = median_neg = gap = float(\"nan\")\n",
    "\n",
    "            if self.wandb_tracker:\n",
    "                log_items = {\n",
    "                    \"Train Loss\": train_loss,\n",
    "                    \"Val Loss\": val_loss,\n",
    "                    \"Val AUROC\": val_auroc,\n",
    "                    \"Val AUPR\": val_aupr,\n",
    "                    \"val_pos_median_logit\": median_pos,\n",
    "                    \"val_neg_median_logit\": median_neg,\n",
    "                    \"val_logit_gap\": gap,\n",
    "                }\n",
    "                self.wandb_tracker.log(log_items, step=epoch)\n",
    "    \n",
    "        if self.wandb_tracker:\n",
    "            self.wandb_tracker.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63b6ed21-de2e-456d-9419-c8cda2fbd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairListDataset(Dataset):\n",
    "    def __init__(self, examples, weights=None):\n",
    "        self.examples = examples\n",
    "        self.weights = weights  # optional per-sample weights (list/array)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        b, t, y = self.examples[idx]\n",
    "        b = torch.as_tensor(b, dtype=torch.float32)\n",
    "        t = torch.as_tensor(t, dtype=torch.float32)\n",
    "        y = torch.tensor(float(y), dtype=torch.float32)\n",
    "        if self.weights is None:\n",
    "            return b, t, y\n",
    "        else:\n",
    "            w = torch.tensor(float(self.weights[idx]), dtype=torch.float32)\n",
    "            return b, t, y, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f41bacd-203c-4747-9b2f-5b61ca0134c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_114129-s8do9xk2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/s8do9xk2' target=\"_blank\">CV_split1_FGFR2_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/s8do9xk2' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/s8do9xk2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 9.9593 | Val AUROC 0.4751 | Val AUPR 0.0824\n",
      "EPOCH 1 - Train Loss 0.9805 | Val Loss 0.9979 | Val AUROC 0.5594 | Val AUPR 0.0995\n",
      "EPOCH 2 - Train Loss 0.5084 | Val Loss 0.4123 | Val AUROC 0.5260 | Val AUPR 0.0906\n",
      "EPOCH 3 - Train Loss 0.4628 | Val Loss 0.5752 | Val AUROC 0.5655 | Val AUPR 0.1010\n",
      "EPOCH 4 - Train Loss 0.4123 | Val Loss 0.4040 | Val AUROC 0.4840 | Val AUPR 0.0831\n",
      "EPOCH 5 - Train Loss 0.3987 | Val Loss 0.4304 | Val AUROC 0.5010 | Val AUPR 0.0860\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▂▂▁▁</td></tr><tr><td>Val AUPR</td><td>▁▇▄█▁▂</td></tr><tr><td>Val AUROC</td><td>▁█▅█▂▃</td></tr><tr><td>Val Loss</td><td>█▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>█▅█▁▃</td></tr><tr><td>val_neg_median_logit</td><td>█▂▄▁▂</td></tr><tr><td>val_pos_median_logit</td><td>█▂▅▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.39865</td></tr><tr><td>Val AUPR</td><td>0.08601</td></tr><tr><td>Val AUROC</td><td>0.50101</td></tr><tr><td>Val Loss</td><td>0.43039</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>-0.0221</td></tr><tr><td>val_neg_median_logit</td><td>-0.98652</td></tr><tr><td>val_pos_median_logit</td><td>-1.00862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split1_FGFR2_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/s8do9xk2' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/s8do9xk2</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_114129-s8do9xk2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_114401-6lk9bkv5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/6lk9bkv5' target=\"_blank\">CV_split2_Mdm2_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/6lk9bkv5' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/6lk9bkv5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 3.8928 | Val AUROC 0.5330 | Val AUPR 0.6146\n",
      "EPOCH 1 - Train Loss 0.7235 | Val Loss 0.7487 | Val AUROC 0.5836 | Val AUPR 0.6744\n",
      "EPOCH 2 - Train Loss 0.5248 | Val Loss 0.6802 | Val AUROC 0.5472 | Val AUPR 0.6527\n",
      "EPOCH 3 - Train Loss 0.4647 | Val Loss 0.7691 | Val AUROC 0.5175 | Val AUPR 0.6346\n",
      "EPOCH 4 - Train Loss 0.4014 | Val Loss 0.7039 | Val AUROC 0.4949 | Val AUPR 0.6095\n",
      "EPOCH 5 - Train Loss 0.3600 | Val Loss 0.6984 | Val AUROC 0.5317 | Val AUPR 0.6404\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>▂█▆▄▁▄</td></tr><tr><td>Val AUROC</td><td>▄█▅▃▁▄</td></tr><tr><td>Val Loss</td><td>█▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>█▅▆▁▅</td></tr><tr><td>val_neg_median_logit</td><td>█▁█▂▂</td></tr><tr><td>val_pos_median_logit</td><td>█▁█▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.36003</td></tr><tr><td>Val AUPR</td><td>0.64044</td></tr><tr><td>Val AUROC</td><td>0.53171</td></tr><tr><td>Val Loss</td><td>0.69845</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>0.00912</td></tr><tr><td>val_neg_median_logit</td><td>0.46494</td></tr><tr><td>val_pos_median_logit</td><td>0.47406</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split2_Mdm2_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/6lk9bkv5' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/6lk9bkv5</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_114401-6lk9bkv5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_114723-ek480ytv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/ek480ytv' target=\"_blank\">CV_split3_LTK_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/ek480ytv' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/ek480ytv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 9.1940 | Val AUROC 1.0000 | Val AUPR 1.0000\n",
      "EPOCH 1 - Train Loss 0.7077 | Val Loss 0.6807 | Val AUROC 0.9889 | Val AUPR 0.9167\n",
      "EPOCH 2 - Train Loss 0.5026 | Val Loss 0.3102 | Val AUROC 0.9667 | Val AUPR 0.6389\n",
      "EPOCH 3 - Train Loss 0.4538 | Val Loss 0.4582 | Val AUROC 0.3333 | Val AUPR 0.0874\n",
      "EPOCH 4 - Train Loss 0.3895 | Val Loss 0.4145 | Val AUROC 0.5111 | Val AUPR 0.1176\n",
      "EPOCH 5 - Train Loss 0.3553 | Val Loss 0.3031 | Val AUROC 0.6778 | Val AUPR 0.1693\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>█▇▅▁▁▂</td></tr><tr><td>Val AUROC</td><td>███▁▃▅</td></tr><tr><td>Val Loss</td><td>█▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>▆█▁▂▄</td></tr><tr><td>val_neg_median_logit</td><td>█▄▅▄▁</td></tr><tr><td>val_pos_median_logit</td><td>█▆▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.35533</td></tr><tr><td>Val AUPR</td><td>0.16934</td></tr><tr><td>Val AUROC</td><td>0.67778</td></tr><tr><td>Val Loss</td><td>0.3031</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>0.12218</td></tr><tr><td>val_neg_median_logit</td><td>-2.33522</td></tr><tr><td>val_pos_median_logit</td><td>-2.21303</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split3_LTK_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/ek480ytv' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/ek480ytv</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_114723-ek480ytv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_115048-k8o46d6y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/k8o46d6y' target=\"_blank\">CV_split4_SARS_CoV2_RBD_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/k8o46d6y' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/k8o46d6y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 9.7368 | Val AUROC 0.4444 | Val AUPR 0.0852\n",
      "EPOCH 1 - Train Loss 0.6761 | Val Loss 4.1571 | Val AUROC 0.3765 | Val AUPR 0.0759\n",
      "EPOCH 2 - Train Loss 0.4687 | Val Loss 2.7565 | Val AUROC 0.3284 | Val AUPR 0.0706\n",
      "EPOCH 3 - Train Loss 0.4384 | Val Loss 2.7837 | Val AUROC 0.3259 | Val AUPR 0.0704\n",
      "EPOCH 4 - Train Loss 0.3786 | Val Loss 1.9100 | Val AUROC 0.3444 | Val AUPR 0.0724\n",
      "EPOCH 5 - Train Loss 0.3229 | Val Loss 1.7231 | Val AUROC 0.3346 | Val AUPR 0.0713\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>█▄▁▁▂▁</td></tr><tr><td>Val AUROC</td><td>█▄▁▁▂▂</td></tr><tr><td>Val Loss</td><td>█▃▂▂▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>█▇▁▃▃</td></tr><tr><td>val_neg_median_logit</td><td>█▅▄▂▁</td></tr><tr><td>val_pos_median_logit</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.32294</td></tr><tr><td>Val AUPR</td><td>0.07128</td></tr><tr><td>Val AUROC</td><td>0.33457</td></tr><tr><td>Val Loss</td><td>1.7231</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>-0.95816</td></tr><tr><td>val_neg_median_logit</td><td>0.73724</td></tr><tr><td>val_pos_median_logit</td><td>-0.22092</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split4_SARS_CoV2_RBD_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/k8o46d6y' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/k8o46d6y</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_115048-k8o46d6y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_115410-iz2bvo9a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/iz2bvo9a' target=\"_blank\">CV_split5_sntx_sntx_2_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/iz2bvo9a' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/iz2bvo9a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 7.9645 | Val AUROC 0.8571 | Val AUPR 0.4869\n",
      "EPOCH 1 - Train Loss 0.7152 | Val Loss 0.3003 | Val AUROC 0.9558 | Val AUPR 0.7878\n",
      "EPOCH 2 - Train Loss 0.5453 | Val Loss 0.4484 | Val AUROC 0.7959 | Val AUPR 0.3428\n",
      "EPOCH 3 - Train Loss 0.4643 | Val Loss 0.4808 | Val AUROC 0.7041 | Val AUPR 0.2690\n",
      "EPOCH 4 - Train Loss 0.4189 | Val Loss 0.5275 | Val AUROC 0.7449 | Val AUPR 0.3023\n",
      "EPOCH 5 - Train Loss 0.3765 | Val Loss 0.5610 | Val AUROC 0.7211 | Val AUPR 0.2697\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>▄█▂▁▁▁</td></tr><tr><td>Val AUROC</td><td>▅█▄▁▂▁</td></tr><tr><td>Val Loss</td><td>█▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>█▅▁▆▃</td></tr><tr><td>val_neg_median_logit</td><td>█▃▆▄▁</td></tr><tr><td>val_pos_median_logit</td><td>█▃▃▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.37652</td></tr><tr><td>Val AUPR</td><td>0.2697</td></tr><tr><td>Val AUROC</td><td>0.72109</td></tr><tr><td>Val Loss</td><td>0.56099</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>0.89109</td></tr><tr><td>val_neg_median_logit</td><td>-3.42676</td></tr><tr><td>val_pos_median_logit</td><td>-2.53567</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split5_sntx_sntx_2_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/iz2bvo9a' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/iz2bvo9a</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_115410-iz2bvo9a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_115734-wdmb33fd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/wdmb33fd' target=\"_blank\">CV_split6_IL7Ra_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/wdmb33fd' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/wdmb33fd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 9.1998 | Val AUROC 0.3201 | Val AUPR 0.1611\n",
      "EPOCH 1 - Train Loss 0.7053 | Val Loss 0.7713 | Val AUROC 0.3021 | Val AUPR 0.1680\n",
      "EPOCH 2 - Train Loss 0.4930 | Val Loss 0.7667 | Val AUROC 0.3118 | Val AUPR 0.1635\n",
      "EPOCH 3 - Train Loss 0.4355 | Val Loss 0.9893 | Val AUROC 0.3188 | Val AUPR 0.1695\n",
      "EPOCH 4 - Train Loss 0.3838 | Val Loss 1.1601 | Val AUROC 0.3310 | Val AUPR 0.1687\n",
      "EPOCH 5 - Train Loss 0.3271 | Val Loss 1.1457 | Val AUROC 0.3310 | Val AUPR 0.1707\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>▁▆▃▇▇█</td></tr><tr><td>Val AUROC</td><td>▅▁▃▅██</td></tr><tr><td>Val Loss</td><td>█▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>██▄▁▂</td></tr><tr><td>val_neg_median_logit</td><td>▇█▃▄▁</td></tr><tr><td>val_pos_median_logit</td><td>▇█▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.32706</td></tr><tr><td>Val AUPR</td><td>0.17067</td></tr><tr><td>Val AUROC</td><td>0.33102</td></tr><tr><td>Val Loss</td><td>1.14572</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>-2.30029</td></tr><tr><td>val_neg_median_logit</td><td>-2.06</td></tr><tr><td>val_pos_median_logit</td><td>-4.3603</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split6_IL7Ra_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/wdmb33fd' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/wdmb33fd</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_115734-wdmb33fd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_120055-6zj7fxoi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/6zj7fxoi' target=\"_blank\">CV_split7_InsulinR_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/6zj7fxoi' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/6zj7fxoi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 7.5294 | Val AUROC 0.3799 | Val AUPR 0.1421\n",
      "EPOCH 1 - Train Loss 0.6821 | Val Loss 0.6457 | Val AUROC 0.4546 | Val AUPR 0.1736\n",
      "EPOCH 2 - Train Loss 0.4927 | Val Loss 0.8434 | Val AUROC 0.4964 | Val AUPR 0.1994\n",
      "EPOCH 3 - Train Loss 0.4354 | Val Loss 1.2821 | Val AUROC 0.4433 | Val AUPR 0.1582\n",
      "EPOCH 4 - Train Loss 0.3793 | Val Loss 1.0494 | Val AUROC 0.4809 | Val AUPR 0.1816\n",
      "EPOCH 5 - Train Loss 0.3466 | Val Loss 0.7119 | Val AUROC 0.4912 | Val AUPR 0.1826\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>▁▅█▃▆▆</td></tr><tr><td>Val AUROC</td><td>▁▅█▅▇█</td></tr><tr><td>Val Loss</td><td>█▁▁▂▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>▁█▅▅▆</td></tr><tr><td>val_neg_median_logit</td><td>▁▄█▆▁</td></tr><tr><td>val_pos_median_logit</td><td>▁▅█▆▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.34655</td></tr><tr><td>Val AUPR</td><td>0.1826</td></tr><tr><td>Val AUROC</td><td>0.49124</td></tr><tr><td>Val Loss</td><td>0.71186</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>-0.03559</td></tr><tr><td>val_neg_median_logit</td><td>-0.16405</td></tr><tr><td>val_pos_median_logit</td><td>-0.19963</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split7_InsulinR_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/6zj7fxoi' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/6zj7fxoi</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_120055-6zj7fxoi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_120417-p2wozex2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/p2wozex2' target=\"_blank\">CV_split8_TrkA_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/p2wozex2' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/p2wozex2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 11.1430 | Val AUROC 0.4435 | Val AUPR 0.0761\n",
      "EPOCH 1 - Train Loss 0.7023 | Val Loss 0.4537 | Val AUROC 0.3212 | Val AUPR 0.0558\n",
      "EPOCH 2 - Train Loss 0.5074 | Val Loss 0.7502 | Val AUROC 0.3389 | Val AUPR 0.0577\n",
      "EPOCH 3 - Train Loss 0.4355 | Val Loss 0.8657 | Val AUROC 0.3595 | Val AUPR 0.0621\n",
      "EPOCH 4 - Train Loss 0.3796 | Val Loss 0.8078 | Val AUROC 0.3539 | Val AUPR 0.0605\n",
      "EPOCH 5 - Train Loss 0.3519 | Val Loss 0.8418 | Val AUROC 0.3847 | Val AUPR 0.0629\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>█▁▂▃▃▃</td></tr><tr><td>Val AUROC</td><td>█▁▂▃▃▅</td></tr><tr><td>Val Loss</td><td>█▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>█▅▇▁▅</td></tr><tr><td>val_neg_median_logit</td><td>▂█▅▄▁</td></tr><tr><td>val_pos_median_logit</td><td>▃█▆▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.35192</td></tr><tr><td>Val AUPR</td><td>0.06294</td></tr><tr><td>Val AUROC</td><td>0.38469</td></tr><tr><td>Val Loss</td><td>0.84175</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>-0.38573</td></tr><tr><td>val_neg_median_logit</td><td>-1.43784</td></tr><tr><td>val_pos_median_logit</td><td>-1.82357</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split8_TrkA_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/p2wozex2' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/p2wozex2</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_120417-p2wozex2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_120739-y8k1k9jz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/y8k1k9jz' target=\"_blank\">CV_split9_IL10Ra_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/y8k1k9jz' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/y8k1k9jz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 7.8833 | Val AUROC 1.0000 | Val AUPR 1.0000\n",
      "EPOCH 1 - Train Loss 0.6764 | Val Loss 0.5927 | Val AUROC 0.4000 | Val AUPR 0.1099\n",
      "EPOCH 2 - Train Loss 0.5024 | Val Loss 0.4847 | Val AUROC 0.9500 | Val AUPR 0.5833\n",
      "EPOCH 3 - Train Loss 0.4444 | Val Loss 0.3751 | Val AUROC 1.0000 | Val AUPR 1.0000\n",
      "EPOCH 4 - Train Loss 0.3839 | Val Loss 0.2600 | Val AUROC 1.0000 | Val AUPR 1.0000\n",
      "EPOCH 5 - Train Loss 0.3447 | Val Loss 0.2376 | Val AUROC 1.0000 | Val AUPR 1.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>█▁▅███</td></tr><tr><td>Val AUROC</td><td>█▁▇███</td></tr><tr><td>Val Loss</td><td>█▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>▁▂▅██</td></tr><tr><td>val_neg_median_logit</td><td>█▇▇▁▂</td></tr><tr><td>val_pos_median_logit</td><td>▁▃█▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.34469</td></tr><tr><td>Val AUPR</td><td>1</td></tr><tr><td>Val AUROC</td><td>1</td></tr><tr><td>Val Loss</td><td>0.23756</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>2.45877</td></tr><tr><td>val_neg_median_logit</td><td>-2.18918</td></tr><tr><td>val_pos_median_logit</td><td>0.26959</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split9_IL10Ra_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/y8k1k9jz' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/y8k1k9jz</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_120739-y8k1k9jz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_121103-0okbclss</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/0okbclss' target=\"_blank\">CV_split10_EGFR_EGFR_2_EGFR_3_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/0okbclss' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/0okbclss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 10.3282 | Val AUROC 0.6088 | Val AUPR 0.1140\n",
      "EPOCH 1 - Train Loss 0.7487 | Val Loss 0.8408 | Val AUROC 0.5303 | Val AUPR 0.0868\n",
      "EPOCH 2 - Train Loss 0.5263 | Val Loss 0.8890 | Val AUROC 0.5223 | Val AUPR 0.0717\n",
      "EPOCH 3 - Train Loss 0.4606 | Val Loss 0.7391 | Val AUROC 0.5693 | Val AUPR 0.0893\n",
      "EPOCH 4 - Train Loss 0.4201 | Val Loss 0.5707 | Val AUROC 0.5493 | Val AUPR 0.0723\n",
      "EPOCH 5 - Train Loss 0.3748 | Val Loss 0.5307 | Val AUROC 0.5754 | Val AUPR 0.0766\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>█▄▁▄▁▂</td></tr><tr><td>Val AUROC</td><td>█▂▁▅▃▅</td></tr><tr><td>Val Loss</td><td>█▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>▄▁▄▄█</td></tr><tr><td>val_neg_median_logit</td><td>▇█▆▁▁</td></tr><tr><td>val_pos_median_logit</td><td>██▆▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.37481</td></tr><tr><td>Val AUPR</td><td>0.07656</td></tr><tr><td>Val AUROC</td><td>0.57539</td></tr><tr><td>Val Loss</td><td>0.53074</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>0.3918</td></tr><tr><td>val_neg_median_logit</td><td>-0.97267</td></tr><tr><td>val_pos_median_logit</td><td>-0.58087</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split10_EGFR_EGFR_2_EGFR_3_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/0okbclss' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/0okbclss</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_121103-0okbclss/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_121418-lxsoayoz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/lxsoayoz' target=\"_blank\">CV_split11_VirB8_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/lxsoayoz' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/lxsoayoz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 11.2007 | Val AUROC 0.5383 | Val AUPR 0.1048\n",
      "EPOCH 1 - Train Loss 0.7092 | Val Loss 6.0638 | Val AUROC 0.5420 | Val AUPR 0.1050\n",
      "EPOCH 2 - Train Loss 0.4870 | Val Loss 4.7308 | Val AUROC 0.5235 | Val AUPR 0.0982\n",
      "EPOCH 3 - Train Loss 0.4341 | Val Loss 3.9553 | Val AUROC 0.5160 | Val AUPR 0.0960\n",
      "EPOCH 4 - Train Loss 0.3790 | Val Loss 3.4885 | Val AUROC 0.5333 | Val AUPR 0.1002\n",
      "EPOCH 5 - Train Loss 0.3628 | Val Loss 3.1657 | Val AUROC 0.4741 | Val AUPR 0.0888\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▂▁▁</td></tr><tr><td>Val AUPR</td><td>██▅▄▆▁</td></tr><tr><td>Val AUROC</td><td>██▆▅▇▁</td></tr><tr><td>Val Loss</td><td>█▄▂▂▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>▃▄▁█▅</td></tr><tr><td>val_neg_median_logit</td><td>█▅▃▂▁</td></tr><tr><td>val_pos_median_logit</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.36278</td></tr><tr><td>Val AUPR</td><td>0.08882</td></tr><tr><td>Val AUROC</td><td>0.47407</td></tr><tr><td>Val Loss</td><td>3.16566</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>0.09053</td></tr><tr><td>val_neg_median_logit</td><td>3.4025</td></tr><tr><td>val_pos_median_logit</td><td>3.49304</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split11_VirB8_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/lxsoayoz' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/lxsoayoz</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_121418-lxsoayoz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_121740-3awnqnxz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/3awnqnxz' target=\"_blank\">CV_split12_IL2Ra_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/3awnqnxz' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/3awnqnxz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 10.5325 | Val AUROC 0.9278 | Val AUPR 0.4323\n",
      "EPOCH 1 - Train Loss 0.7370 | Val Loss 0.8923 | Val AUROC 0.7833 | Val AUPR 0.2227\n",
      "EPOCH 2 - Train Loss 0.5163 | Val Loss 0.3665 | Val AUROC 0.8056 | Val AUPR 0.2255\n",
      "EPOCH 3 - Train Loss 0.4466 | Val Loss 0.2652 | Val AUROC 0.7556 | Val AUPR 0.1872\n",
      "EPOCH 4 - Train Loss 0.4083 | Val Loss 0.2685 | Val AUROC 0.7778 | Val AUPR 0.2083\n",
      "EPOCH 5 - Train Loss 0.3595 | Val Loss 0.2801 | Val AUROC 0.7389 | Val AUPR 0.1800\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>█▂▂▁▂▁</td></tr><tr><td>Val AUROC</td><td>█▃▃▂▂▁</td></tr><tr><td>Val Loss</td><td>█▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>▁▅▃██</td></tr><tr><td>val_neg_median_logit</td><td>█▅▃▁▁</td></tr><tr><td>val_pos_median_logit</td><td>█▅▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.3595</td></tr><tr><td>Val AUPR</td><td>0.18001</td></tr><tr><td>Val AUROC</td><td>0.73889</td></tr><tr><td>Val Loss</td><td>0.28012</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>0.84735</td></tr><tr><td>val_neg_median_logit</td><td>-3.37515</td></tr><tr><td>val_pos_median_logit</td><td>-2.52779</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split12_IL2Ra_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/3awnqnxz' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/3awnqnxz</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_121740-3awnqnxz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20250928_122105-enrxrl95</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/enrxrl95' target=\"_blank\">CV_split13_Pdl1_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/enrxrl95' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/enrxrl95</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model fc69aac7-4547-4dfc-a36a-dc6f33b1b453\n",
      "Before training - Val Loss 9.6539 | Val AUROC 0.4106 | Val AUPR 0.1174\n",
      "EPOCH 1 - Train Loss 0.7175 | Val Loss 0.6069 | Val AUROC 0.4267 | Val AUPR 0.1240\n",
      "EPOCH 2 - Train Loss 0.5019 | Val Loss 1.2884 | Val AUROC 0.3996 | Val AUPR 0.1331\n",
      "EPOCH 3 - Train Loss 0.4318 | Val Loss 1.0117 | Val AUROC 0.4739 | Val AUPR 0.1569\n",
      "EPOCH 4 - Train Loss 0.3869 | Val Loss 0.8364 | Val AUROC 0.5231 | Val AUPR 0.1912\n",
      "EPOCH 5 - Train Loss 0.3363 | Val Loss 0.8263 | Val AUROC 0.5512 | Val AUPR 0.2610\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Val AUPR</td><td>▁▁▂▃▅█</td></tr><tr><td>Val AUROC</td><td>▂▂▁▄▇█</td></tr><tr><td>Val Loss</td><td>█▁▂▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>val_logit_gap</td><td>▁▂▅▅█</td></tr><tr><td>val_neg_median_logit</td><td>▁█▆▄▃</td></tr><tr><td>val_pos_median_logit</td><td>▁█▇▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.33635</td></tr><tr><td>Val AUPR</td><td>0.26104</td></tr><tr><td>Val AUROC</td><td>0.5512</td></tr><tr><td>Val Loss</td><td>0.82628</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>val_logit_gap</td><td>0.26613</td></tr><tr><td>val_neg_median_logit</td><td>0.17516</td></tr><tr><td>val_pos_median_logit</td><td>0.44128</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CV_split13_Pdl1_fc69aac7-4547-4dfc-a36a-dc6f33b1b453</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/enrxrl95' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV/runs/enrxrl95</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/MetaAnal_leave1OutCV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250928_122105-enrxrl95/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "learning_rate = 2e-5\n",
    "EPOCHS = 5\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "\n",
    "# login once (env var preferred)\n",
    "if use_wandb:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "\n",
    "for i in range(len(cv_splits)):\n",
    "\n",
    "    val_target_name = \"_\".join(cv_splits[i][0])\n",
    "    \n",
    "    # NEW model per split\n",
    "    model = MiniCLIP_w_transformer_crossattn()\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # validation\n",
    "    val_targets = cv_splits[i][0]\n",
    "    val_idx = interaction_df.loc[interaction_df.target_id_mod.isin(val_targets)].index.tolist()\n",
    "    val_binders = [ALL_btl[idx] for idx in val_idx]\n",
    "    val_binders = PairListDataset(val_binders)\n",
    "\n",
    "    # training\n",
    "    train_targets = cv_splits[i][1]\n",
    "\n",
    "    # train_weights_class = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"class_weight\"].tolist()\n",
    "    # train_weights_target = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"target_weight\"].tolist()\n",
    "    # train_weights_combined = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"combined_weight\"].tolist()\n",
    "    train_weights_combined_boost_positives = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets), \"combined_weight_account_pos\"].tolist()\n",
    "\n",
    "    train_idx = interaction_df.loc[interaction_df.target_id_mod.isin(train_targets)].index.tolist()\n",
    "    train_binders = [ALL_btl[idx] for idx in train_idx]\n",
    "    train_binders = PairListDataset(train_binders)\n",
    "\n",
    "    # loaders\n",
    "    ### no weighting\n",
    "    # train_loader   = DataLoader(train_binders, batch_size=20, shuffle=True)\n",
    "\n",
    "    ### class weighting\n",
    "    # train_sampler = WeightedRandomSampler(weights=train_weights_class, num_samples=train_binders.__len__(), replacement=True)\n",
    "    # train_loader   = DataLoader(train_binders,   batch_size=20, sampler=train_sampler)\n",
    "\n",
    "    ### target weighting\n",
    "    # train_sampler = WeightedRandomSampler(weights=train_weights_target, num_samples=train_binders.__len__(), replacement=True)\n",
    "    # train_loader   = DataLoader(train_binders,   batch_size=20, sampler=train_sampler)\n",
    "\n",
    "    ### combined weighting\n",
    "    train_sampler = WeightedRandomSampler(weights=train_weights_combined_boost_positives, num_samples=train_binders.__len__(), replacement=True, generator = g)\n",
    "    train_loader   = DataLoader(train_binders,   batch_size=20, sampler=train_sampler)\n",
    "    \n",
    "    val_loader   = DataLoader(val_binders,   batch_size=20, shuffle=False, drop_last = False)\n",
    "\n",
    "    # accelerator\n",
    "    accelerator = Accelerator()\n",
    "    device = accelerator.device\n",
    "    model, optimizer, train_loader, val_loader, scheduler = accelerator.prepare(model, optimizer, train_loader, val_loader, scheduler)\n",
    "\n",
    "    # wandb\n",
    "    if use_wandb:\n",
    "        run = wandb.init(\n",
    "            project=\"MetaAnal_leave1OutCV\",\n",
    "            name=f\"CV_split{i+1}_{val_target_name}_{runID}\",\n",
    "            group=\"cv_splits\",\n",
    "            config={\"learning_rate\": learning_rate, \"batch_size\": batch_size, \"epochs\": EPOCHS,\n",
    "                    \"architecture\": \"MiniCLIP_w_transformer_crossattn\", \"dataset\": \"Meta analysis\"},\n",
    "        )\n",
    "        wandb.watch(accelerator.unwrap_model(model), log=\"all\", log_freq=100)\n",
    "    else:\n",
    "        run = None\n",
    "\n",
    "    # train\n",
    "    training_wrapper = TrainWrapper_MetaAnal(\n",
    "        model=model,\n",
    "        training_loader=train_loader,\n",
    "        validation_loader=val_loader,\n",
    "        test_dataset=val_binders,   # ok if you truly want “full val”\n",
    "        optimizer=optimizer,\n",
    "        scheduler = scheduler,\n",
    "        EPOCHS=EPOCHS,\n",
    "        runID=runID,\n",
    "        device=device,\n",
    "        model_save_steps=model_save_steps,\n",
    "        model_save_path=trained_model_dir,\n",
    "        v=True,\n",
    "        wandb_tracker=run,\n",
    "        split_id=i+1\n",
    "    )\n",
    "    training_wrapper.train_model()\n",
    "\n",
    "    # cleanup between splits\n",
    "    if use_wandb:\n",
    "        wandb.finish()\n",
    "    del training_wrapper, model, optimizer, train_loader, val_loader, scheduler\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    try:\n",
    "        accelerator.free_memory()\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
