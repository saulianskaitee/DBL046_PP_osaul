{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f838074-e829-40d5-9b15-949a9bfe9708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import uuid, sys, os\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "\n",
    "from transformers import EsmModel, AutoTokenizer # huggingface\n",
    "import esm\n",
    "\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.cuda.set_device(0)  # 0 == \"first visible\" -> actually GPU 2 on the node\n",
    "torch.manual_seed(0)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import AdamW\n",
    "from accelerate import Accelerator\n",
    "import training_utils.partitioning_utils as pat_utils\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "# LoRA\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d0770f-c901-45f7-b5e7-801a2f8f261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1+cu128\n",
      "Using device: cuda\n",
      "Current location: /zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch:\", torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print(\"Current location:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da12c27-b0c9-4166-bf60-a7e182e83805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /zhome/c9/0/203261/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms232958\u001b[0m (\u001b[33ms232958-danmarks-tekniske-universitet-dtu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://api.wandb.ai/status\").status_code\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"f8a6d759fe657b095d56bddbdb4d586dfaebd468\", relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a771b897-1647-4594-b648-41d2639d5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting a seed to have the same initiation of weights\n",
    "\n",
    "def set_seed(seed: int = 0):\n",
    "    # Python & NumPy\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "\n",
    "    # CuDNN settings (for convolution etc.)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # (Optional) for some Python hashing randomness\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "SEED = 0\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfc6c69-e492-4bf1-a23e-e8ee41a27d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "memory_verbose = False\n",
    "use_wandb = True # Used to track loss in real-time without printing\n",
    "\n",
    "seq_embed_dimension = 1280 #| 960 | 1152\n",
    "# struct_embed_dimension = 256\n",
    "number_of_recycles = 2\n",
    "padding_value = -5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b152a01f-a72c-4d75-9e1c-6b6f937515eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory:  34.072559616\n",
      "Reserved memory:  0.0\n",
      "Allocated memory:  0.0\n",
      "Free memory:  0.0\n"
     ]
    }
   ],
   "source": [
    "# ## Training variables\n",
    "runID = uuid.uuid4()\n",
    "\n",
    "def print_mem_consumption():\n",
    "    # 1. Total memory available on the GPU (device 0)\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    # 2. How much memory PyTorch has *reserved* from CUDA\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    # 3. How much of that reserved memory is actually *used* by tensors\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    # 4. Reserved but not currently allocated (so “free inside PyTorch’s pool”)\n",
    "    f = r - a\n",
    "\n",
    "    print(\"Total memory: \", t/1e9)      # total VRAM in GB\n",
    "    print(\"Reserved memory: \", r/1e9)   # PyTorch’s reserved pool in GB\n",
    "    print(\"Allocated memory: \", a//1e9) # actually in use (integer division)\n",
    "    print(\"Free memory: \", f/1e9)       # slack in the reserved pool in GB\n",
    "print_mem_consumption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b001f70e-d769-4c9e-ad66-6e6c919a0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_key_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings < (padding_value + offset)).all(dim=-1)\n",
    "\n",
    "def create_mean_of_non_masked(embeddings, padding_mask):\n",
    "    # Use masked select and mean to compute the mean of non-masked elements\n",
    "    # embeddings should be of shape (batch_size, seq_len, features)\n",
    "    seq_embeddings = []\n",
    "    for i in range(embeddings.shape[0]): # looping over all batch elements\n",
    "        non_masked_embeddings = embeddings[i][~padding_mask[i]] # shape [num_real_tokens, features]\n",
    "        if len(non_masked_embeddings) == 0:\n",
    "            print(\"You are masking all positions when creating sequence representation\")\n",
    "            sys.exit(1)\n",
    "        mean_embedding = non_masked_embeddings.mean(dim=0) # sequence is represented by the single vecotr [1152] [features]\n",
    "        seq_embeddings.append(mean_embedding)\n",
    "    return torch.stack(seq_embeddings)\n",
    "\n",
    "def non_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings > (padding_value + offset)).all(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349b030-2126-46c1-bb65-8d25e7fb6c0e",
   "metadata": {},
   "source": [
    "### Loading Data for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1277c85e-2ea7-44f6-8523-8b1362106edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interface_id</th>\n",
       "      <th>PDB</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>seq_target</th>\n",
       "      <th>seq_target_len</th>\n",
       "      <th>seq_pdb_target</th>\n",
       "      <th>pdb_target_len</th>\n",
       "      <th>target_chain</th>\n",
       "      <th>seq_binder</th>\n",
       "      <th>seq_binder_len</th>\n",
       "      <th>seq_pdb_binder</th>\n",
       "      <th>pdb_binder_len</th>\n",
       "      <th>binder_chain</th>\n",
       "      <th>pdb_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6IDB_0</td>\n",
       "      <td>6IDB</td>\n",
       "      <td>6IDB_0_A</td>\n",
       "      <td>6IDB_0_B</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "      <td>6IDB_A</td>\n",
       "      <td>GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...</td>\n",
       "      <td>172</td>\n",
       "      <td>GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...</td>\n",
       "      <td>172</td>\n",
       "      <td>6IDB_B</td>\n",
       "      <td>6idb.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2WZP_3</td>\n",
       "      <td>2WZP</td>\n",
       "      <td>2WZP_3_D</td>\n",
       "      <td>2WZP_3_G</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "      <td>2WZP_D</td>\n",
       "      <td>TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...</td>\n",
       "      <td>266</td>\n",
       "      <td>TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...</td>\n",
       "      <td>266</td>\n",
       "      <td>2WZP_G</td>\n",
       "      <td>2wzp.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ZKP_0</td>\n",
       "      <td>1ZKP</td>\n",
       "      <td>1ZKP_0_A</td>\n",
       "      <td>1ZKP_0_C</td>\n",
       "      <td>LYFQSNAKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLA...</td>\n",
       "      <td>246</td>\n",
       "      <td>LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...</td>\n",
       "      <td>251</td>\n",
       "      <td>1ZKP_A</td>\n",
       "      <td>AKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQKYI...</td>\n",
       "      <td>240</td>\n",
       "      <td>AMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQK...</td>\n",
       "      <td>245</td>\n",
       "      <td>1ZKP_C</td>\n",
       "      <td>1zkp.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6GRH_3</td>\n",
       "      <td>6GRH</td>\n",
       "      <td>6GRH_3_C</td>\n",
       "      <td>6GRH_3_D</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "      <td>6GRH_C</td>\n",
       "      <td>MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...</td>\n",
       "      <td>396</td>\n",
       "      <td>MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...</td>\n",
       "      <td>396</td>\n",
       "      <td>6GRH_D</td>\n",
       "      <td>6grh.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8R57_1</td>\n",
       "      <td>8R57</td>\n",
       "      <td>8R57_1_M</td>\n",
       "      <td>8R57_1_f</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "      <td>8R57_M</td>\n",
       "      <td>PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...</td>\n",
       "      <td>64</td>\n",
       "      <td>PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...</td>\n",
       "      <td>64</td>\n",
       "      <td>8R57_f</td>\n",
       "      <td>8r57.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>4YO8_0</td>\n",
       "      <td>4YO8</td>\n",
       "      <td>4YO8_0_A</td>\n",
       "      <td>4YO8_0_B</td>\n",
       "      <td>HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...</td>\n",
       "      <td>238</td>\n",
       "      <td>HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...</td>\n",
       "      <td>238</td>\n",
       "      <td>4YO8_A</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "      <td>4YO8_B</td>\n",
       "      <td>4yo8.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>3CKI_0</td>\n",
       "      <td>3CKI</td>\n",
       "      <td>3CKI_0_A</td>\n",
       "      <td>3CKI_0_B</td>\n",
       "      <td>DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...</td>\n",
       "      <td>256</td>\n",
       "      <td>DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...</td>\n",
       "      <td>256</td>\n",
       "      <td>3CKI_A</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "      <td>3CKI_B</td>\n",
       "      <td>3cki.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>7MHY_1</td>\n",
       "      <td>7MHY</td>\n",
       "      <td>7MHY_1_M</td>\n",
       "      <td>7MHY_1_N</td>\n",
       "      <td>QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...</td>\n",
       "      <td>118</td>\n",
       "      <td>QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...</td>\n",
       "      <td>118</td>\n",
       "      <td>7MHY_M</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "      <td>7MHY_N</td>\n",
       "      <td>7mhy.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>7MHY_2</td>\n",
       "      <td>7MHY</td>\n",
       "      <td>7MHY_2_O</td>\n",
       "      <td>7MHY_2_P</td>\n",
       "      <td>IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...</td>\n",
       "      <td>100</td>\n",
       "      <td>IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...</td>\n",
       "      <td>100</td>\n",
       "      <td>7MHY_O</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "      <td>7MHY_P</td>\n",
       "      <td>7mhy.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>6O42_0</td>\n",
       "      <td>6O42</td>\n",
       "      <td>6O42_0_L</td>\n",
       "      <td>6O42_0_H</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>214</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>214</td>\n",
       "      <td>6O42_L</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "      <td>6O42_H</td>\n",
       "      <td>6o42.pdb.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1977 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     interface_id   PDB       ID1       ID2  \\\n",
       "0          6IDB_0  6IDB  6IDB_0_A  6IDB_0_B   \n",
       "1          2WZP_3  2WZP  2WZP_3_D  2WZP_3_G   \n",
       "2          1ZKP_0  1ZKP  1ZKP_0_A  1ZKP_0_C   \n",
       "3          6GRH_3  6GRH  6GRH_3_C  6GRH_3_D   \n",
       "4          8R57_1  8R57  8R57_1_M  8R57_1_f   \n",
       "...           ...   ...       ...       ...   \n",
       "1972       4YO8_0  4YO8  4YO8_0_A  4YO8_0_B   \n",
       "1973       3CKI_0  3CKI  3CKI_0_A  3CKI_0_B   \n",
       "1974       7MHY_1  7MHY  7MHY_1_M  7MHY_1_N   \n",
       "1975       7MHY_2  7MHY  7MHY_2_O  7MHY_2_P   \n",
       "1976       6O42_0  6O42  6O42_0_L  6O42_0_H   \n",
       "\n",
       "                                             seq_target  seq_target_len  \\\n",
       "0     DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...             317   \n",
       "1     VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...             122   \n",
       "2     LYFQSNAKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLA...             246   \n",
       "3     SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...             266   \n",
       "4     DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...             118   \n",
       "...                                                 ...             ...   \n",
       "1972  HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...             238   \n",
       "1973  DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...             256   \n",
       "1974  QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...             118   \n",
       "1975  IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...             100   \n",
       "1976  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...             214   \n",
       "\n",
       "                                         seq_pdb_target  pdb_target_len  \\\n",
       "0     DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...             317   \n",
       "1     VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...             122   \n",
       "2     LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...             251   \n",
       "3     SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...             266   \n",
       "4     DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...             118   \n",
       "...                                                 ...             ...   \n",
       "1972  HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...             238   \n",
       "1973  DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...             256   \n",
       "1974  QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...             118   \n",
       "1975  IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...             100   \n",
       "1976  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...             214   \n",
       "\n",
       "     target_chain                                         seq_binder  \\\n",
       "0          6IDB_A  GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...   \n",
       "1          2WZP_D  TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...   \n",
       "2          1ZKP_A  AKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQKYI...   \n",
       "3          6GRH_C  MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...   \n",
       "4          8R57_M  PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...   \n",
       "...           ...                                                ...   \n",
       "1972       4YO8_A  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...   \n",
       "1973       3CKI_A  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...   \n",
       "1974       7MHY_M  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...   \n",
       "1975       7MHY_O  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...   \n",
       "1976       6O42_L  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...   \n",
       "\n",
       "      seq_binder_len                                     seq_pdb_binder  \\\n",
       "0                172  GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...   \n",
       "1                266  TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...   \n",
       "2                240  AMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQK...   \n",
       "3                396  MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...   \n",
       "4                 64  PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...   \n",
       "...              ...                                                ...   \n",
       "1972             242  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...   \n",
       "1973             121  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...   \n",
       "1974             109  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...   \n",
       "1975              94  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...   \n",
       "1976             220  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...   \n",
       "\n",
       "      pdb_binder_len binder_chain     pdb_path  \n",
       "0                172       6IDB_B  6idb.pdb.gz  \n",
       "1                266       2WZP_G  2wzp.pdb.gz  \n",
       "2                245       1ZKP_C  1zkp.pdb.gz  \n",
       "3                396       6GRH_D  6grh.pdb.gz  \n",
       "4                 64       8R57_f  8r57.pdb.gz  \n",
       "...              ...          ...          ...  \n",
       "1972             242       4YO8_B  4yo8.pdb.gz  \n",
       "1973             121       3CKI_B  3cki.pdb.gz  \n",
       "1974             109       7MHY_N  7mhy.pdb.gz  \n",
       "1975              94       7MHY_P  7mhy.pdb.gz  \n",
       "1976             220       6O42_H  6o42.pdb.gz  \n",
       "\n",
       "[1977 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_train = pd.read_csv(\"/work3/s232958/data/PPint_DB/PPint_train_w_pbd_lens.csv\",index_col=0).reset_index(drop=True)\n",
    "Df_test = pd.read_csv(\"/work3/s232958/data/PPint_DB/PPint_test_w_pbd_lens.csv\",index_col=0).reset_index(drop=True)\n",
    "\n",
    "Df_train[\"target_chain\"] = [str(row.ID1[:5]+row.ID1[-1]) for __, row in Df_train.iterrows()]\n",
    "Df_train[\"binder_chain\"] = [str(row.ID2[:5]+row.ID2[-1]) for __, row in Df_train.iterrows()]\n",
    "\n",
    "Df_test[\"target_chain\"] = [str(row.ID1[:5]+row.ID1[-1]) for __, row in Df_test.iterrows()]\n",
    "Df_test[\"binder_chain\"] = [str(row.ID2[:5]+row.ID2[-1]) for __, row in Df_test.iterrows()]\n",
    "\n",
    "Df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2dc3459-94e9-4184-88a3-b13120177122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SKVVKFSYMWTINNFSFCREEMGEVIKSSTFSSKLKWCLRVNPKGLDSKDYLSLYLLLVSCPKEVRAKFKFSILNAKGEETKAMESQRAYRFVQGKDWGFKKFIRRGFLLDEANGLLPDDKLTLFCEVSVVQDSQTMNMVKVPECRLADELGGLWENSRFTDCCLCVAGQEFQAHKAILAARSPVFSAMFEHKNRVEINDVEPEVFKEMMCFIYTGKAPNLDKMADDLLAAADKYALERLKVMCEDALCSNLSVENAAEILILADLHSADQLKTQAVDFINYHA'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_train[Df_train.ID1.str.startswith(\"3HU6\")].seq_target.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab57963-a7cc-4b28-b250-bf5f5529f82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6IDB_A</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2WZP_D</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ZKP_A</td>\n",
       "      <td>LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6GRH_C</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8R57_M</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>4YO8_B</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>3CKI_B</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>7MHY_N</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>7MHY_P</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>6O42_H</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3949 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                           sequence  seq_len\n",
       "0     6IDB_A  DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...      317\n",
       "1     2WZP_D  VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...      122\n",
       "2     1ZKP_A  LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...      251\n",
       "3     6GRH_C  SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...      266\n",
       "4     8R57_M  DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...      118\n",
       "...      ...                                                ...      ...\n",
       "3949  4YO8_B  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...      242\n",
       "3950  3CKI_B  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...      121\n",
       "3951  7MHY_N  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...      109\n",
       "3952  7MHY_P  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...       94\n",
       "3953  6O42_H  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...      220\n",
       "\n",
       "[3949 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Df1 = Df_train[[\"target_chain\", \"seq_pdb_target\", \"pdb_target_len\"]].rename(columns = {\n",
    "    \"seq_pdb_target\" : \"sequence\",\n",
    "    \"target_chain\" : \"ID\",\n",
    "    \"pdb_target_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "train_Df2 = Df_train[[\"binder_chain\", \"seq_pdb_binder\", \"pdb_binder_len\"]].rename(columns = {\n",
    "    \"seq_pdb_binder\" : \"sequence\",\n",
    "    \"binder_chain\" : \"ID\",\n",
    "    \"pdb_binder_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "Df_train_LONG = pd.concat([train_Df1, train_Df2], axis=0, ignore_index=True).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "Df_train_LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9355a32-db3d-4962-b5b3-6c7515eb52c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1NNW_A</td>\n",
       "      <td>VYVAVLANIAGNLPALTAALSRIEEMREEGYEIEKYYILGNIVGLF...</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3UCN_A</td>\n",
       "      <td>TADLSPLLEANRKWADECAAKDSTYFSKVAGSQAPEYLYIGCADSR...</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1POV_1</td>\n",
       "      <td>QHRSRSESSIESFFARGACVTIMTVDNPASTTNKDKLFAVWKITYK...</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3R6Y_C</td>\n",
       "      <td>VRIEKDFLGEKEIPKDAYYGVQTIRATENFPITGYRIHPELIKSLG...</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5YHI_A</td>\n",
       "      <td>PMRYPVDVYTGKIQVDGELMLTELGLEGDGPDRALCHYPREHYLYW...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>3GXE_F</td>\n",
       "      <td>GLPGMKGHRGF</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>6LY5_l</td>\n",
       "      <td>ANFIKPYNDDPFVGHLATPITSSAVTRSLLKNLPAYRFGLTPLLRG...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>5MLK_B</td>\n",
       "      <td>ARISKVLVANRGEIAVRVIRAARDAGLPSVAVYAEPDAESPHVRLA...</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>8BS4_B</td>\n",
       "      <td>GHPVLEKLKAAHSYNPKEFEWNLKSGRVFIIKSYSEDDIHRSIKYS...</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>6WDS_H</td>\n",
       "      <td>VQLVESGGGLVKPGGLRLSCAASGFTFSTYIMTWVRQAPGRGLEWV...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                           sequence  seq_len\n",
       "0    1NNW_A  VYVAVLANIAGNLPALTAALSRIEEMREEGYEIEKYYILGNIVGLF...      251\n",
       "1    3UCN_A  TADLSPLLEANRKWADECAAKDSTYFSKVAGSQAPEYLYIGCADSR...      222\n",
       "2    1POV_1  QHRSRSESSIESFFARGACVTIMTVDNPASTTNKDKLFAVWKITYK...      235\n",
       "3    3R6Y_C  VRIEKDFLGEKEIPKDAYYGVQTIRATENFPITGYRIHPELIKSLG...      383\n",
       "4    5YHI_A  PMRYPVDVYTGKIQVDGELMLTELGLEGDGPDRALCHYPREHYLYW...      202\n",
       "..      ...                                                ...      ...\n",
       "983  3GXE_F                                        GLPGMKGHRGF       11\n",
       "984  6LY5_l  ANFIKPYNDDPFVGHLATPITSSAVTRSLLKNLPAYRFGLTPLLRG...      144\n",
       "985  5MLK_B  ARISKVLVANRGEIAVRVIRAARDAGLPSVAVYAEPDAESPHVRLA...      384\n",
       "986  8BS4_B  GHPVLEKLKAAHSYNPKEFEWNLKSGRVFIIKSYSEDDIHRSIKYS...      193\n",
       "987  6WDS_H  VQLVESGGGLVKPGGLRLSCAASGFTFSTYIMTWVRQAPGRGLEWV...      115\n",
       "\n",
       "[985 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Df1 = Df_test[[\"target_chain\", \"seq_pdb_target\", \"pdb_target_len\"]].rename(columns = {\n",
    "    \"seq_pdb_target\" : \"sequence\",\n",
    "    \"target_chain\" : \"ID\",\n",
    "    \"pdb_target_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "test_Df2 = Df_test[[\"binder_chain\", \"seq_pdb_binder\", \"pdb_binder_len\"]].rename(columns = {\n",
    "    \"seq_pdb_binder\" : \"sequence\",\n",
    "    \"binder_chain\" : \"ID\",\n",
    "    \"pdb_binder_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "Df_test_LONG = pd.concat([test_Df1, test_Df2], axis=0, ignore_index=True).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "Df_test_LONG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ed436-2f6a-42d8-912c-a0e9ff15b06a",
   "metadata": {},
   "source": [
    "#### Loading seqeunce, structural_embeddings & using pooled embeddings for CLIP (PPint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d15e1e2-6358-47d8-9fc5-e9e3f977566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Loading ESM2 embeddings and contacts: 100%|███████████████████████████████████████| 3949/3949 [00:12<00:00, 308.73it/s]\n",
      "#Loading ESM2 embeddings and contacts: 100%|█████████████████████████████████████████| 985/985 [00:03<00:00, 297.82it/s]\n"
     ]
    }
   ],
   "source": [
    "class CLIP_PPint_w_esmIF(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        paths,\n",
    "        embedding_dim_struct=512,\n",
    "        embedding_dim_seq=1280,\n",
    "        embedding_pad_value=-5000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim_seq = embedding_dim_seq\n",
    "        self.embedding_dim_struct = embedding_dim_struct\n",
    "        self.emb_pad = embedding_pad_value\n",
    "\n",
    "        # lengths\n",
    "        self.max_len = self.dframe[\"seq_len\"].max()+2\n",
    "\n",
    "        # paths\n",
    "        self.seq_encodings_path, self.struct_encodings_path = paths\n",
    "\n",
    "        # index & storage\n",
    "        self.dframe.set_index(\"ID\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings and contacts\"):\n",
    "\n",
    "            # laod embeddings\n",
    "            emb_struct = np.load(os.path.join(self.struct_encodings_path, f\"{accession}.npy\"))[1:-1, :] # remove EOS BOS, to use only real aa token for cos-sim\n",
    "            sequence = self.dframe.loc[accession].sequence\n",
    "\n",
    "            if len(sequence) != emb_struct.shape[0]:\n",
    "                print(sequence, emb_struct.shape[0])\n",
    "\n",
    "            if emb_struct.shape[1] != self.embedding_dim_struct:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "\n",
    "            if emb_struct.shape[0] < self.max_len:\n",
    "                emb_struct = np.concatenate([emb_struct, np.full((self.max_len - emb_struct.shape[0], emb_struct.shape[1]), self.emb_pad, dtype=emb_struct.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_struct = emb_struct[: self.max_len] # no padding was used\n",
    "\n",
    "            self.samples.append((sequence, emb_struct))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, emb_struct = self.samples[idx]\n",
    "        emb_struct = torch.from_numpy(emb_struct).float()\n",
    "        label = torch.tensor(1, dtype=torch.float32)  # single scalar labe        \n",
    "        return sequence, emb_struct, label\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        # emb_seq_list, emb_struct_list, label_list = zip(*out)\n",
    "        sequence_list, emb_struct_list, lbl_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings    \n",
    "        emb_struct_stacked  = torch.stack([torch.as_tensor(x) for x in emb_struct_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        lbl_stacked = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return list(sequence_list), emb_struct_stacked, lbl_stacked\n",
    "\n",
    "emb_seq_path = \"/work3/s232958/data/PPint_DB/embeddings_esm2\"\n",
    "emb_struct_path = \"/work3/s232958/data/PPint_DB/esmif_embeddings_noncanonical\"\n",
    "\n",
    "train_Dataset = CLIP_PPint_w_esmIF(\n",
    "    Df_train_LONG,\n",
    "    paths=[emb_seq_path, emb_struct_path],\n",
    "    embedding_dim_seq=1280,\n",
    "    embedding_dim_struct=512\n",
    ")\n",
    "\n",
    "test_Dataset = CLIP_PPint_w_esmIF(\n",
    "    Df_test_LONG,\n",
    "    paths=[emb_seq_path, emb_struct_path],\n",
    "    embedding_dim_seq=1280,\n",
    "    embedding_dim_struct=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f9021-6e1b-4dd5-a207-1f3d976d9c37",
   "metadata": {},
   "source": [
    "#### Loading seqeunce, structural_embeddings & using pooled embeddings for CLIP (meta-anlaysis dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c2f4cb1-1c4f-4a30-8d41-dca5e0704a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGFR2_124</td>\n",
       "      <td>DIVEEAHKLLSRAMSEAMENDDPDKLRRANELYFKLEEALKNNDPK...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EGFR_2_149</td>\n",
       "      <td>SEELVEKVVEEILNSDLSNDQKILETHDRLMELHDQGKISKEEYYK...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FGFR2_339</td>\n",
       "      <td>TINRVFHLHIQGDTEEARKAHEELVEEVRRWAEELAKRLNLTVRVT...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FGFR2_1234</td>\n",
       "      <td>DDLRKVERIASELAFFAAEQNDTKVAFTALELIHQLIRAIFHNDEE...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IL2Ra_48</td>\n",
       "      <td>DEEVEELEELLEKAEDPRERAKLLRELAKLIRRDPRLRELATEVVA...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>t_SARS_CoV2_RBD</td>\n",
       "      <td>TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>t_VirB8</td>\n",
       "      <td>ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>t_sntx_2</td>\n",
       "      <td>MICHNQQSSQPPTTKTCSEGQCYKKTWRDHRGTIIERGCGCPTVKP...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>t_sntx</td>\n",
       "      <td>MICYNQQSSQPPTTKTCSETSCYKKTWRDHRGTIIERGCGCPKVKP...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>t_EGFR_3</td>\n",
       "      <td>VCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYVQRNYD...</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3548 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                           sequence  \\\n",
       "0           FGFR2_124  DIVEEAHKLLSRAMSEAMENDDPDKLRRANELYFKLEEALKNNDPK...   \n",
       "1          EGFR_2_149  SEELVEKVVEEILNSDLSNDQKILETHDRLMELHDQGKISKEEYYK...   \n",
       "2           FGFR2_339  TINRVFHLHIQGDTEEARKAHEELVEEVRRWAEELAKRLNLTVRVT...   \n",
       "3          FGFR2_1234  DDLRKVERIASELAFFAAEQNDTKVAFTALELIHQLIRAIFHNDEE...   \n",
       "4            IL2Ra_48  DEEVEELEELLEKAEDPRERAKLLRELAKLIRRDPRLRELATEVVA...   \n",
       "...               ...                                                ...   \n",
       "3543  t_SARS_CoV2_RBD  TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...   \n",
       "3544          t_VirB8  ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...   \n",
       "3545         t_sntx_2  MICHNQQSSQPPTTKTCSEGQCYKKTWRDHRGTIIERGCGCPTVKP...   \n",
       "3546           t_sntx  MICYNQQSSQPPTTKTCSETSCYKKTWRDHRGTIIERGCGCPKVKP...   \n",
       "3547         t_EGFR_3  VCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYVQRNYD...   \n",
       "\n",
       "      seq_len  \n",
       "0          62  \n",
       "1          58  \n",
       "2          65  \n",
       "3          64  \n",
       "4          65  \n",
       "...       ...  \n",
       "3543      195  \n",
       "3544      138  \n",
       "3545       60  \n",
       "3546       60  \n",
       "3547      157  \n",
       "\n",
       "[3548 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.read_csv(\"/work3/s232958/data/meta_analysis/interaction_df_metaanal_w_pbd_lens.csv\").drop(columns = [\"binder_id\", \"target_id\"]).rename(columns = {\n",
    "    \"target_id_mod\" : \"target_id\",\n",
    "    \"target_binder_ID\" : \"binder_id\",\n",
    "})\n",
    "\n",
    "meta_df[\"target_id_mod\"] = [str(\"t_\"+row.target_id) for __, row in meta_df.iterrows()]\n",
    "\n",
    "# Interaction Dict\n",
    "meta_df_shuffled = meta_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "meta_df_shuffled_LONG_binder = meta_df_shuffled[[\"binder_id\", \"binder_seq\", \"seq_len_binder\"]].rename(columns = {\n",
    "    \"binder_id\" : \"ID\",\n",
    "    \"binder_seq\" : \"sequence\",\n",
    "    \"seq_len_binder\": \"seq_len\",\n",
    "})\n",
    "\n",
    "meta_df_shuffled_LONG_taget = meta_df_shuffled[[\"target_id_mod\", \"target_seq\", \"seq_len_target\"]].rename(columns = {\n",
    "    \"target_id_mod\" : \"ID\",\n",
    "    \"target_seq\" : \"sequence\",\n",
    "    \"seq_len_target\": \"seq_len\",\n",
    "}).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "\n",
    "meta_df_shuffled_LONG = pd.concat([meta_df_shuffled_LONG_binder, meta_df_shuffled_LONG_taget], axis=0, ignore_index=True)\n",
    "meta_sample_Df = meta_df_shuffled_LONG.sample(n=len(Df_test_LONG), random_state=0).reset_index(drop=True)\n",
    "meta_df_shuffled_LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf42816b-7572-41d0-9752-6c36b26bdfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Loading ESM2 embeddings and contacts: 100%|█████████████████████████████████████████| 985/985 [00:02<00:00, 447.28it/s]\n"
     ]
    }
   ],
   "source": [
    "class CLIP_Meta_w_esmIF(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        embedding_dim_struct=512,\n",
    "        embedding_dim_seq=1280,\n",
    "        embedding_pad_value=-5000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim_seq = embedding_dim_seq\n",
    "        self.embedding_dim_struct = embedding_dim_struct\n",
    "        self.emb_pad = embedding_pad_value\n",
    "\n",
    "        # lengths\n",
    "        self.max_len = self.dframe[\"seq_len\"].max()\n",
    "\n",
    "        # index & storage\n",
    "        \n",
    "        self.dframe.set_index(\"ID\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings and contacts\"):\n",
    "            \n",
    "            if accession.startswith(\"t_\"):\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_targets\"\n",
    "                \n",
    "                # emb_struct = np.load(os.path.join(esmIF_path, f\"{accession[2:]}.npy\"))\n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession[2:]}.npy\"))[1:-1, :] # remove EOS BOS, to use only real aa token for cos-sim\n",
    "                sequence = str(self.dframe.loc[accession].sequence)\n",
    "\n",
    "            else:\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "\n",
    "                # emb_struct = np.load(os.path.join(esmIF_path, f\"{accession}.npy\"))     # [Lb, D]\n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession}.npy\"))[1:-1, :] # remove EOS BOS, to use only real aa token for cos-sim\n",
    "                sequence = str(self.dframe.loc[accession].sequence)            \n",
    "\n",
    "            if len(sequence) != emb_struct.shape[0]:\n",
    "                print(str(sequence), len(sequence), emb_struct.shape[0])\n",
    "\n",
    "            if emb_struct.shape[1] != self.embedding_dim_struct:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "\n",
    "            if emb_struct.shape[0] < self.max_len:\n",
    "                emb_struct = np.concatenate([emb_struct, np.full((self.max_len - emb_struct.shape[0], emb_struct.shape[1]), self.emb_pad, dtype=emb_struct.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_struct = emb_struct[: self.max_len] # no padding was used\n",
    "\n",
    "            self.samples.append((sequence, emb_struct))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, emb_struct = self.samples[idx]\n",
    "        emb_struct = torch.from_numpy(emb_struct).float()\n",
    "        label = torch.tensor(1, dtype=torch.float32)  # single scalar labe        \n",
    "        return sequence, emb_struct, label\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        # emb_seq_list, emb_struct_list, label_list = zip(*out)\n",
    "        sequence_list, emb_struct_list, lbl_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings    \n",
    "        emb_struct_stacked  = torch.stack([torch.as_tensor(x) for x in emb_struct_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        lbl_stacked = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return list(sequence_list), emb_struct_stacked, lbl_stacked\n",
    "\n",
    "esm2_path_binders = \"/work3/s232958/data/meta_analysis/embeddings_esm2_binders\"\n",
    "esm2_path_targets = \"/work3/s232958/data/meta_analysis/embeddings_esm2_targets\"\n",
    "\n",
    "## Contact maps paths\n",
    "esmIF_path_binders = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "esmIF_path_targets = \"/work3/s232958/data/meta_analysis/esmif_embeddings_targets\"\n",
    "\n",
    "# meta_Dataset_train = CLIP_Meta_w_esmIF(\n",
    "#     meta_df_shuffled_LONG_train,\n",
    "#     embedding_dim_seq=1280,\n",
    "#     embedding_dim_struct=512\n",
    "# )\n",
    "\n",
    "meta_Dataset = CLIP_Meta_w_esmIF(\n",
    "    meta_sample_Df,\n",
    "    embedding_dim_seq=1280,\n",
    "    embedding_dim_struct=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d71f96-2474-4724-8a83-129fbe9ddf5d",
   "metadata": {},
   "source": [
    "### Contrastive Sequence-Structure Pre-training (CSSP)\n",
    "- combined loss = CLIP loss + token_level loss\n",
    "- stop training of `seq_down` after `4 epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cfd101c-a7ed-4708-afb0-ed6703649e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESM2EncoderLoRA(nn.Module):\n",
    "    def __init__(self, padding_value=-5000.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "        self.model = EsmModel.from_pretrained(\n",
    "            \"facebook/esm2_t33_650M_UR50D\",\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n",
    "        # Freeze original weights\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # LoRA on top layers\n",
    "        lora_cfg = LoraConfig(\n",
    "            task_type=\"FEATURE_EXTRACTION\",\n",
    "            inference_mode=False,\n",
    "            r=4,\n",
    "            lora_alpha=1,\n",
    "            lora_dropout=0.1,\n",
    "            bias=\"none\",\n",
    "            # target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            layers_to_transform=list(range(25, 33)),\n",
    "        )\n",
    "\n",
    "        self.model = get_peft_model(self.model, lora_cfg)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attentions(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs, output_attentions=True)\n",
    "        return out.attentions   # list[num_layers] → [B, num_heads, L, L]\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs)\n",
    "        reps = out.hidden_states[-1]                  # [B, Ltok, 1280]\n",
    "        reps = reps[:, 1:-1, :]                       # remove CLS/EOS\n",
    "\n",
    "        seq_lengths = [len(s) for s in sequences]\n",
    "        Lmax = max(seq_lengths)\n",
    "\n",
    "        B, D = reps.size(0), reps.size(-1)\n",
    "        padded = torch.full((B, Lmax, D), self.padding_value, device=reps.device)\n",
    "\n",
    "        for i, (r, real_len) in enumerate(zip(reps, seq_lengths)):\n",
    "            padded[i, :real_len] = r[:real_len]\n",
    "\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e3a74c-27ff-474d-a87b-9119229ca907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings > (padding_value + offset)).all(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cee6ce23-8969-4fee-aae7-231abe416d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSSPBoostingESM(nn.Module):\n",
    "    def __init__(self, seq_embed_dim=1280, struct_embed_dim=512, padding_value=-5000):\n",
    "        super().__init__()\n",
    "        self.padding_value = padding_value\n",
    "        self.struct_embed_dim = 512\n",
    "        self.seq_encoder = ESM2EncoderLoRA()\n",
    "        self.seq_down = nn.Linear(seq_embed_dim, struct_embed_dim)  \n",
    "        self.logit_scale = nn.Parameter(torch.tensor(math.log(1/0.07)))\n",
    "\n",
    "    def forward(self, sequences, struct_embed):\n",
    "    \n",
    "        # ---- encode sequence ----\n",
    "        seq_embed = self.seq_encoder(sequences)          # [B, Lseq, 1280]\n",
    "        B, Lseq, _ = seq_embed.shape\n",
    "        _, Lstr, D = struct_embed.shape                  # D = 512\n",
    "    \n",
    "        # ---- masks ----\n",
    "        seq_mask = non_padding_mask(seq_embed, self.padding_value)      # True = real\n",
    "        struct_mask = non_padding_mask(struct_embed, self.padding_value)  # True = real\n",
    "    \n",
    "        # enforce residue alignment\n",
    "        assert (\n",
    "            seq_mask.sum(dim=1).cpu().tolist()\n",
    "            == struct_mask.sum(dim=1).cpu().tolist()\n",
    "        ), \"Sequence and structure residue counts do not match\"\n",
    "    \n",
    "        # ---- project seq + pad to structure length ----\n",
    "        seq_embed_proj = torch.full(\n",
    "            (B, Lstr, D),\n",
    "            self.padding_value,\n",
    "            device=seq_embed.device,\n",
    "            dtype=seq_embed.dtype,\n",
    "        )\n",
    "    \n",
    "        for i in range(B):\n",
    "            real_seq = seq_embed[i][seq_mask[i]]     # [Li, 1280]\n",
    "            proj = self.seq_down(real_seq)            # [Li, 512]\n",
    "            seq_embed_proj[i, :proj.size(0)] = proj   # align positions\n",
    "    \n",
    "        seq_pooled = create_mean_of_non_masked(seq_embed_proj, create_key_padding_mask(seq_embed_proj))\n",
    "        struct_pooled = create_mean_of_non_masked(struct_embed, create_key_padding_mask(struct_embed))\n",
    "    \n",
    "        seq_full = F.normalize(seq_pooled, dim=-1)\n",
    "        struct_full = F.normalize(struct_pooled, dim=-1)\n",
    "    \n",
    "        scale = torch.exp(self.logit_scale).clamp(max=100)\n",
    "        logits_seq = scale * (seq_full @ struct_full.T)\n",
    "        logits_struct = scale * (struct_full @ seq_full.T)\n",
    "    \n",
    "        return logits_seq, logits_struct, seq_embed_proj, struct_embed, struct_mask\n",
    "\n",
    "    def training_step(self, batch, device):\n",
    "    \n",
    "        sequences, struct_embed, _ = batch\n",
    "        struct_embed = struct_embed.to(device)\n",
    "    \n",
    "        logits_seq, logits_struct, seq_embed_proj, struct_embed, struct_mask = self.forward(sequences, struct_embed)\n",
    "    \n",
    "        # ---- CLIP loss ----\n",
    "        B = logits_seq.size(0)\n",
    "        labels = torch.arange(B, device=device)\n",
    "    \n",
    "        loss_seq = F.cross_entropy(logits_seq, labels)\n",
    "        loss_struct = F.cross_entropy(logits_struct, labels)\n",
    "        clip_loss = 0.5 * (loss_seq + loss_struct)\n",
    "    \n",
    "        # ---- token-level cosine loss (aligned positions) ----\n",
    "        cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Lstr]\n",
    "        cos = cos * struct_mask.float()                                   # mask padding\n",
    "    \n",
    "        per_token_loss = 1.0 - (cos.sum(dim=1) / struct_mask.sum(dim=1)).mean()\n",
    "    \n",
    "        return clip_loss + per_token_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63c9aec4-8272-45ec-9906-08a0631d504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logit_scale', 'seq_encoder.model.base_model.model.embeddings.word_embeddings.weight', 'seq_encoder.model.base_model.model.embeddings.position_embeddings.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.rotary_embeddings.inv_freq']\n",
      "['logit_scale', 'seq_encoder.model.base_model.model.embeddings.word_embeddings.weight', 'seq_encoder.model.base_model.model.embeddings.position_embeddings.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.rotary_embeddings.inv_freq']\n"
     ]
    }
   ],
   "source": [
    "### Loading model pre-tarined for 50 epochs\n",
    "model_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_combinedLoss02/2d2b1f23-4d4e-49b0-a768-7625349e0800/model_cos-sim0.35.pt\"\n",
    "model_checkpoint_dict = torch.load(model_checkpoint_path, map_location=\"cuda\")\n",
    "\n",
    "model = CSSPBoostingESM(\n",
    "    seq_embed_dim=1280,\n",
    "    struct_embed_dim=512,\n",
    "    padding_value=-5000,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(model_checkpoint_dict)\n",
    "# model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "print(list(model_checkpoint_dict.keys())[:10])\n",
    "print(list(model.state_dict().keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b423a4f3-eb4e-44ce-a9d6-36f74372f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "runID = uuid.uuid4()\n",
    "learning_rate = 2e-5\n",
    "EPOCHS = 200\n",
    "batch_size = 10\n",
    "# model = CSSPBoostingESM(seq_embed_dim=1280, struct_embed_dim=512).to(\"cuda\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = optimizer.lr_scheduler.MultiStepLR(optimizer, milestones=[3], gamma=4.0)\n",
    "# seq_down_params = set(model.seq_down.parameters())\n",
    "# other_params = [p for p in model.parameters() if p not in seq_down_params]\n",
    "# optimizer = torch.optim.AdamW([\n",
    "#     {\"params\": other_params, \"lr\": learning_rate},\n",
    "#     {\"params\": model.seq_down.parameters(),\"lr\": 2e-5},\n",
    "# ])\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "train_dataloader = DataLoader(train_Dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_Dataset, batch_size=10, shuffle=False)\n",
    "val_dataloader = DataLoader(meta_Dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9072c55-5d54-4a1e-9e63-d11d04e0c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- token-lvl cos-siminilarity\n",
    "- train seq_down for 4 epochs and then freeze all parameters\n",
    "- train in total for 50 epochs, save model every 5 epochs and plot progress in W&B\n",
    "\"\"\"\n",
    "\n",
    "class TrainWrapper():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=model,\n",
    "        train_loader=train_dataloader,\n",
    "        test_loader=test_dataloader,\n",
    "        val_loader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        epochs=EPOCHS,\n",
    "        device=device,\n",
    "        wandb_tracker=False,\n",
    "        save_at = []\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.training_loader = train_loader\n",
    "        self.testing_loader = test_loader\n",
    "        self.validation_loader = val_loader\n",
    "        self.EPOCHS = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.wandb_tracker = wandb_tracker\n",
    "        self.save_at = set(save_at)\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "\n",
    "        self.model.train()\n",
    "        self.model.seq_encoder.train()\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        for batch in tqdm(self.training_loader, total=len(self.training_loader), desc=\"Running through epoch\"):\n",
    "\n",
    "            sequences, struct_embed, labels = batch\n",
    "            struct_embed = struct_embed.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.model.training_step((sequences, struct_embed, labels), self.device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        return running_loss / len(self.training_loader)\n",
    "    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_embeddings_cos_similariy(self, loader=None, loader_name=\"test\"):\n",
    "    \n",
    "        if loader is None:\n",
    "            loader = self.testing_loader\n",
    "    \n",
    "        self.model.eval()\n",
    "        self.model.seq_encoder.eval()\n",
    "    \n",
    "        all_embeds = []\n",
    "        cosine_similarities = []\n",
    "    \n",
    "        for batch in tqdm(loader, desc=f\"Computing cosine similarity & embeddings ({loader_name})\"):\n",
    "    \n",
    "            seqs, struct_embed, _ = batch\n",
    "            struct_embed = struct_embed.to(self.device)      # [B, Ls, 512]\n",
    "    \n",
    "            # ---- sequence embeddings ----\n",
    "            seq_embed = self.model.seq_encoder(seqs)         # [B, Lq, 1280]\n",
    "            B, Lq, _ = seq_embed.shape\n",
    "            _, Ls, Ds = struct_embed.shape\n",
    "    \n",
    "            seq_mask = non_padding_mask(seq_embed, self.model.padding_value)   # [B, Lq]\n",
    "            str_mask = non_padding_mask(struct_embed, self.model.padding_value)  # [B, Ls]\n",
    "    \n",
    "            # enforce residue-wise alignment\n",
    "            assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "    \n",
    "            # ---- project seq tokens + pad to structure length ----\n",
    "            seq_embed_proj = torch.full((B, Ls, Ds), self.model.padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "            for i in range(B):\n",
    "                real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "                proj = self.model.seq_down(real_seq)      # [Li, 512]\n",
    "                seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "    \n",
    "            # ---- token-level cosine similarity (aligned positions) ----\n",
    "            cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "            cos = cos * str_mask.float()   # mask padding\n",
    "    \n",
    "            per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "            cosine_similarities.extend(per_seq_cos.cpu().tolist())\n",
    "    \n",
    "            # ---- pooled sequence embeddings (projected space) ----\n",
    "            seq_pooled = create_mean_of_non_masked(seq_embed_proj, create_key_padding_mask(seq_embed_proj))\n",
    "            seq_full = F.normalize(seq_pooled, dim=-1)\n",
    "            all_embeds.append(seq_full.cpu())\n",
    "    \n",
    "        all_embeds = torch.cat(all_embeds, dim=0)\n",
    "    \n",
    "        avg_cos = float(np.mean(cosine_similarities))\n",
    "        std_cos = float(np.std(cosine_similarities))\n",
    "    \n",
    "        return all_embeds, cosine_similarities, avg_cos, std_cos\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval_train_loss(self):\n",
    "        self.model.eval()\n",
    "        running = 0.0\n",
    "        for sequences, struct_embed, labels in tqdm(self.training_loader, total=len(self.training_loader), desc=f\"Computing Training Loss before training\"):\n",
    "            struct_embed = struct_embed.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            loss = self.model.training_step((sequences, struct_embed, labels), self.device)\n",
    "            running += loss.item()\n",
    "        return running / len(self.training_loader)\n",
    "\n",
    "    def plot_embeddings_drift_cos_similarity_change(self, start_embeddings, end_embeddings, cosine_similarities):\n",
    "\n",
    "        drift = (end_embeddings - start_embeddings).norm(dim=1).cpu().numpy()\n",
    "        cosine_similarities = np.array(cosine_similarities)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "        ax[0].hist(drift, bins=30, color=\"steelblue\", alpha=0.8)\n",
    "        ax[0].set_title(\"Embedding Drift per Sequence\", fontsize=8)\n",
    "        ax[0].set_xlabel(\"L2 Norm Drift\", fontsize=8)\n",
    "        ax[0].set_ylabel(\"Density\", fontsize=8)\n",
    "\n",
    "        ax[1].hist(cosine_similarities, bins=40, color=\"darkorange\", alpha=0.7, density=True)\n",
    "        ax[1].set_title(\"Cosine Similarities (ESM-2 vs ESM-IF)\", fontsize=8)\n",
    "        ax[1].set_xlabel(\"Cosine Similarity\", fontsize=8)\n",
    "        ax[1].set_ylabel(\"Density\", fontsize=8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def train_model(self, save_every: int = 5):\n",
    "    \n",
    "        # run_dir = f\"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_combinedLoss02/{runID}/\"\n",
    "        run_dir = f\"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_combinedLoss02/2d2b1f23-4d4e-49b0-a768-7625349e0800/\"\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "    \n",
    "        print(\"\\nTrainable parameters inside seq_encoder (LoRA layers):\")\n",
    "        for name, p in self.model.seq_encoder.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                print(\"  \", name)\n",
    "    \n",
    "        # ---- Save checkpoint BEFORE training (epoch 0) ----\n",
    "        # save_path_encoder = os.path.join(run_dir, \"seq_encoder_before_training.pt\")\n",
    "        # save_path_projhead = os.path.join(run_dir, \"seq_down_before_training.pt\")\n",
    "        # torch.save(self.model.seq_encoder.state_dict(), save_path_encoder)\n",
    "        # torch.save(self.model.seq_down.state_dict(), save_path_projhead)\n",
    "        # print(f\"Saved seq_encoder checkpoint before training -> {save_path_encoder}\")\n",
    "        # print(f\"Saved proj head checkpoint before training -> {save_path_projhead}\")\n",
    "    \n",
    "        # ---- START embeddings/cos-sim for both loaders ----\n",
    "        # print(\"Computing Loss before training:\")\n",
    "        # train_loss = self.eval_train_loss()\n",
    "        # print(f\"[TRAIN] Loss {train_loss}\")\n",
    "        \n",
    "        # print(\"\\nExtracting START embeddings & cosine similarities (val + test)...\")\n",
    "        # start_val_emb, start_val_cos, start_val_avg, start_val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "        # print(f\"[VAL]  avg cos: {start_val_avg:.4f}, std: {start_val_std:.4f}\")\n",
    "        # self.plot_embeddings_drift_cos_similarity_change(start_val_emb, start_val_emb, start_val_cos)\n",
    "    \n",
    "        # start_test_emb, start_test_cos, start_test_avg, start_test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "        # print(f\"[TEST] avg cos: {start_test_avg:.4f}, std: {start_test_std:.4f}\")\n",
    "        # # self.plot_embeddings_drift_cos_similarity_change(start_test_emb, start_test_emb, start_test_cos)\n",
    "\n",
    "        # if self.wandb_tracker:\n",
    "        #     self.wandb_tracker.log({\n",
    "        #         \"train/loss\": train_loss,\n",
    "        #         \"val/cos_avg\": start_val_avg,\n",
    "        #         \"val/cos_std\": start_val_std,\n",
    "        #         \"test/cos_avg\": start_test_avg,\n",
    "        #         \"test/cos_std\": start_test_std,\n",
    "        #     }, step=0)\n",
    "    \n",
    "        for epoch in range(1, self.EPOCHS + 1):\n",
    "        \n",
    "            # if epoch == 5:\n",
    "            if epoch == 1:\n",
    "                print(f\"\\nFreezing projection head (seq_down) after {epoch-1} epoch(s), continuing training of the rest...\")\n",
    "                for p in self.model.seq_down.parameters():\n",
    "                    p.requires_grad = False\n",
    "                self.optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "            train_loss = self.train_one_epoch()\n",
    "            print(f\"Epoch {epoch}: loss={train_loss:.4f}\")\n",
    "    \n",
    "            # Optional: monitor cos-sim each epoch (val + test)\n",
    "            if epoch % 5 ==0:\n",
    "                val_emb, val_cos, val_avg, val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "                print(f\"[VAL]  avg cos: {val_avg:.4f}, std: {val_std:.4f}\")\n",
    "        \n",
    "                test_emb, test_cos, test_avg, test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "                print(f\"[TEST] avg cos: {test_avg:.4f}, std: {test_std:.4f}\")\n",
    "        \n",
    "                # ---- Save checkpoints when ----            \n",
    "                value = round(val_avg, 2)\n",
    "                if value in self.save_at:\n",
    "                    save_path_encoder = os.path.join(run_dir, f\"seq_encoder_cos-sim{value}.pt\")\n",
    "                    save_path_projhead = os.path.join(run_dir, f\"seq_down_cos-sim{value}.pt\")\n",
    "                    save_path_model = os.path.join(run_dir, f\"model_cos-sim{value}.pt\")\n",
    "                    torch.save(self.model.state_dict(), save_path_model)\n",
    "                    torch.save(self.model.seq_encoder.state_dict(), save_path_encoder)\n",
    "                    torch.save(self.model.seq_down.state_dict(), save_path_projhead)\n",
    "                    print(f\"Saved whole model checkpoint -> {save_path_model}\")\n",
    "                    print(f\"Saved seq_encoder checkpoint -> {save_path_encoder}\")\n",
    "                    print(f\"Saved proj head checkpoint -> {save_path_projhead}\")\n",
    "                    self.save_at.remove(value)\n",
    "    \n",
    "                if self.wandb_tracker:\n",
    "                    self.wandb_tracker.log({\n",
    "                        \"train/loss\": train_loss,\n",
    "                        \"val/cos_avg\": val_avg,\n",
    "                        \"val/cos_std\": val_std,\n",
    "                        \"test/cos_avg\": test_avg,\n",
    "                        \"test/cos_std\": test_std,\n",
    "                    }, step=epoch)\n",
    "\n",
    "                if len(self.save_at)==0:\n",
    "                    # ---- END embeddings/cos-sim for both loaders ----\n",
    "                    print(\"\\nExtracting END embeddings & cosine similarities (val + test)...\")\n",
    "                    end_val_emb, end_val_cos, val_avg, val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "                    print(f\"[VAL]  avg cos: {val_avg:.4f}, std: {val_std:.4f}\")\n",
    "                    self.plot_embeddings_drift_cos_similarity_change(start_val_emb, end_val_emb, end_val_cos)\n",
    "            \n",
    "                    end_test_emb, end_test_cos, test_avg, test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "                    print(f\"[TEST] avg cos: {test_avg:.4f}, std: {test_std:.4f}\")\n",
    "                \n",
    "                    # Return test triplet like your original expectation:\n",
    "                    return (start_val_emb, end_val_emb, end_val_cos), (start_test_emb, end_test_emb, end_test_cos)\n",
    "    \n",
    "        # ---- END embeddings/cos-sim for both loaders ----\n",
    "        print(\"\\nExtracting END embeddings & cosine similarities (val + test)...\")\n",
    "        end_val_emb, end_val_cos, val_avg, val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "        print(f\"[VAL]  avg cos: {val_avg:.4f}, std: {val_std:.4f}\")\n",
    "        self.plot_embeddings_drift_cos_similarity_change(start_val_emb, end_val_emb, end_val_cos)\n",
    "\n",
    "        end_test_emb, end_test_cos, test_avg, test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "        print(f\"[TEST] avg cos: {test_avg:.4f}, std: {test_std:.4f}\")\n",
    "    \n",
    "        # Return test triplet like your original expectation:\n",
    "        return (start_val_emb, end_val_emb, end_val_cos), (start_test_emb, end_test_emb, end_test_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34b248-273c-40b5-9bf8-6dff944745b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20260119_181241-q02plzs4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF_02/runs/q02plzs4' target=\"_blank\">freeze_projhead_after_epoch4_c8e5cd1a-75ab-4d4c-bb9f-b1a71595fb25</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF_02' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF_02' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF_02</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF_02/runs/q02plzs4' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_2_w_ESM_IF_02/runs/q02plzs4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters inside seq_encoder (LoRA layers):\n",
      "   model.base_model.model.encoder.layer.25.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.output.dense.lora_B.default.weight\n",
      "\n",
      "Freezing projection head (seq_down) after 0 epoch(s), continuing training of the rest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:36<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.7497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:29<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=0.7499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:30<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss=0.7444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:30<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: loss=0.7492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:31<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: loss=0.7476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:41<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.3492, std: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:57<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.3094, std: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:26<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: loss=0.7452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:28<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: loss=0.7461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:29<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: loss=0.7410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:35<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: loss=0.7423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:28<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: loss=0.7367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:41<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.3529, std: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:57<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.3131, std: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:28<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: loss=0.7353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:28<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: loss=0.7436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:28<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: loss=0.7318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:27<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: loss=0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:35<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: loss=0.7319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:40<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.3564, std: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:57<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.3169, std: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:27<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: loss=0.7311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [10:29<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: loss=0.7347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch:   7%|███▉                                                       | 26/395 [00:41<09:57,  1.62s/it]"
     ]
    }
   ],
   "source": [
    "### wandb\n",
    "if use_wandb:\n",
    "    run = wandb.init(\n",
    "        project=\"Boosting_ESM_2_w_ESM_IF_02\",\n",
    "        name=f\"freeze_projhead_after_epoch4_{runID}\",\n",
    "        config={\"learning_rate\": learning_rate, \n",
    "                \"batch_size\": batch_size, \n",
    "                \"epochs\": EPOCHS,\n",
    "                \"architecture\": \"MiniCLIP_w_transformer_crossattn\", \n",
    "                \"dataset\": \n",
    "                \"PPint\"},\n",
    "    )\n",
    "    wandb.watch(accelerator.unwrap_model(model), log=\"all\", log_freq=100)\n",
    "else:\n",
    "    run = None\n",
    "\n",
    "# accelerator\n",
    "model, optimizer, train_dataloader, test_dataloader, val_dataloader = accelerator.prepare(model, optimizer, train_dataloader, test_dataloader, val_dataloader)\n",
    "\n",
    "training_wrapper = TrainWrapper(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    test_loader=test_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=EPOCHS,\n",
    "    device=device,\n",
    "    wandb_tracker=wandb,\n",
    "    save_at = [0.37, 0.40, 0.43, 0.47, 0.50, 0.60, 0.70, 0.80, 0.90, 1.00]\n",
    ")\n",
    "\n",
    "val_params, test_params = training_wrapper.train_model(save_every=[5, 10, 25, 50, 60, 70, 80, 90, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5a908-af2d-4029-8319-9fb40f8d5f0d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc18de4-01c3-4749-b67d-b5dff72cc7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGFR2_124</td>\n",
       "      <td>DIVEEAHKLLSRAMSEAMENDDPDKLRRANELYFKLEEALKNNDPK...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EGFR_2_149</td>\n",
       "      <td>SEELVEKVVEEILNSDLSNDQKILETHDRLMELHDQGKISKEEYYK...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FGFR2_339</td>\n",
       "      <td>TINRVFHLHIQGDTEEARKAHEELVEEVRRWAEELAKRLNLTVRVT...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FGFR2_1234</td>\n",
       "      <td>DDLRKVERIASELAFFAAEQNDTKVAFTALELIHQLIRAIFHNDEE...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IL2Ra_48</td>\n",
       "      <td>DEEVEELEELLEKAEDPRERAKLLRELAKLIRRDPRLRELATEVVA...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>t_SARS_CoV2_RBD</td>\n",
       "      <td>TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>t_VirB8</td>\n",
       "      <td>ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>t_sntx_2</td>\n",
       "      <td>MICHNQQSSQPPTTKTCSEGQCYKKTWRDHRGTIIERGCGCPTVKP...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>t_sntx</td>\n",
       "      <td>MICYNQQSSQPPTTKTCSETSCYKKTWRDHRGTIIERGCGCPKVKP...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>t_EGFR_3</td>\n",
       "      <td>VCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYVQRNYD...</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3548 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                           sequence  \\\n",
       "0           FGFR2_124  DIVEEAHKLLSRAMSEAMENDDPDKLRRANELYFKLEEALKNNDPK...   \n",
       "1          EGFR_2_149  SEELVEKVVEEILNSDLSNDQKILETHDRLMELHDQGKISKEEYYK...   \n",
       "2           FGFR2_339  TINRVFHLHIQGDTEEARKAHEELVEEVRRWAEELAKRLNLTVRVT...   \n",
       "3          FGFR2_1234  DDLRKVERIASELAFFAAEQNDTKVAFTALELIHQLIRAIFHNDEE...   \n",
       "4            IL2Ra_48  DEEVEELEELLEKAEDPRERAKLLRELAKLIRRDPRLRELATEVVA...   \n",
       "...               ...                                                ...   \n",
       "3543  t_SARS_CoV2_RBD  TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...   \n",
       "3544          t_VirB8  ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...   \n",
       "3545         t_sntx_2  MICHNQQSSQPPTTKTCSEGQCYKKTWRDHRGTIIERGCGCPTVKP...   \n",
       "3546           t_sntx  MICYNQQSSQPPTTKTCSETSCYKKTWRDHRGTIIERGCGCPKVKP...   \n",
       "3547         t_EGFR_3  VCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYVQRNYD...   \n",
       "\n",
       "      seq_len  \n",
       "0          62  \n",
       "1          58  \n",
       "2          65  \n",
       "3          64  \n",
       "4          65  \n",
       "...       ...  \n",
       "3543      195  \n",
       "3544      138  \n",
       "3545       60  \n",
       "3546       60  \n",
       "3547      157  \n",
       "\n",
       "[3548 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.read_csv(\"/work3/s232958/data/meta_analysis/interaction_df_metaanal_w_pbd_lens.csv\").drop(columns = [\"binder_id\", \"target_id\"]).rename(columns = {\n",
    "    \"target_id_mod\" : \"target_id\",\n",
    "    \"target_binder_ID\" : \"binder_id\",\n",
    "})\n",
    "\n",
    "meta_df[\"target_id_mod\"] = [str(\"t_\"+row.target_id) for __, row in meta_df.iterrows()]\n",
    "\n",
    "# Interaction Dict\n",
    "meta_df_shuffled = meta_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "meta_df_shuffled_LONG_binder = meta_df_shuffled[[\"binder_id\", \"binder_seq\", \"seq_len_binder\"]].rename(columns = {\n",
    "    \"binder_id\" : \"ID\",\n",
    "    \"binder_seq\" : \"sequence\",\n",
    "    \"seq_len_binder\": \"seq_len\",\n",
    "})\n",
    "\n",
    "meta_df_shuffled_LONG_taget = meta_df_shuffled[[\"target_id_mod\", \"target_seq\", \"seq_len_target\"]].rename(columns = {\n",
    "    \"target_id_mod\" : \"ID\",\n",
    "    \"target_seq\" : \"sequence\",\n",
    "    \"seq_len_target\": \"seq_len\",\n",
    "}).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "\n",
    "meta_df_shuffled_LONG = pd.concat([meta_df_shuffled_LONG_binder, meta_df_shuffled_LONG_taget], axis=0, ignore_index=True)\n",
    "meta_df_shuffled_LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f71035-c096-4bcb-ba16-b8eb70424ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESM2EncoderLoRA(nn.Module):\n",
    "    def __init__(self, padding_value=-5000.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "        self.model = EsmModel.from_pretrained(\n",
    "            \"facebook/esm2_t33_650M_UR50D\",\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n",
    "        # Freeze original weights\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # LoRA on top layers\n",
    "        lora_cfg = LoraConfig(\n",
    "            task_type=\"FEATURE_EXTRACTION\",\n",
    "            inference_mode=False,\n",
    "            r=4,\n",
    "            lora_alpha=1,\n",
    "            lora_dropout=0.1,\n",
    "            bias=\"none\",\n",
    "            # target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            layers_to_transform=list(range(25, 33)),\n",
    "        )\n",
    "\n",
    "        self.model = get_peft_model(self.model, lora_cfg)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attentions(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs, output_attentions=True)\n",
    "        return out.attentions   # list[num_layers] → [B, num_heads, L, L]\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs)\n",
    "        reps = out.hidden_states[-1]                  # [B, Ltok, 1280]\n",
    "        reps = reps[:, 1:-1, :]                       # remove CLS/EOS\n",
    "\n",
    "        seq_lengths = [len(s) for s in sequences]\n",
    "        Lmax = max(seq_lengths)\n",
    "\n",
    "        B, D = reps.size(0), reps.size(-1)\n",
    "        padded = torch.full((B, Lmax, D), self.padding_value, device=reps.device)\n",
    "\n",
    "        for i, (r, real_len) in enumerate(zip(reps, seq_lengths)):\n",
    "            padded[i, :real_len] = r[:real_len]\n",
    "\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "500eb040-da96-416e-9dba-6bf91914e1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Loading ESM2 embeddings and contacts: 100%|████████████████████████████████████████████████████| 3548/3548 [00:21<00:00, 163.56it/s]\n"
     ]
    }
   ],
   "source": [
    "class CLIP_PPint_w_esmIF(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        paths,\n",
    "        embedding_dim_struct=512,\n",
    "        embedding_dim_seq=1280,\n",
    "        embedding_pad_value=-5000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim_seq = embedding_dim_seq\n",
    "        self.embedding_dim_struct = embedding_dim_struct\n",
    "        self.emb_pad = embedding_pad_value\n",
    "\n",
    "        # lengths\n",
    "        self.seq_len = self.dframe[\"seq_len\"].max()\n",
    "\n",
    "        # index & storage\n",
    "        self.dframe.set_index(\"ID\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings and contacts\"):\n",
    "\n",
    "            # laod embeddings\n",
    "            if accession.startswith(\"t_\"):\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_targets\"\n",
    "                esm2_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_targets\"\n",
    "               \n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession[2:]}.npy\"))[1:-1, :]\n",
    "                emb_seq = np.load(os.path.join(esm2_path, f\"{accession[2:]}.npy\"))[1:-1, :]\n",
    "                sequence = str(self.dframe.loc[accession].sequence)\n",
    "\n",
    "                assert (emb_struct.shape[0]== emb_seq.shape[0] == len(sequence))\n",
    "\n",
    "            else:\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "                esm2_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_binders\"\n",
    "\n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession}.npy\"))[1:-1, :]\n",
    "                emb_seq = np.load(os.path.join(esm2_path, f\"{accession}.npy\"))[1:-1, :] \n",
    "                sequence = str(self.dframe.loc[accession].sequence)\n",
    "\n",
    "                # print(emb_struct.shape, emb_seq.shape)\n",
    "                assert (emb_struct.shape[0]== emb_seq.shape[0] == len(sequence))\n",
    "\n",
    "            # quich check whether embedding dimmension is as it suppose to be\n",
    "            if emb_seq.shape[1] != self.embedding_dim_seq:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim_seq'.\")\n",
    "            if emb_struct.shape[1] != self.embedding_dim_struct:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "                \n",
    "            # add -5000 to all the padded target rows\n",
    "            if emb_seq.shape[0] < self.seq_len:\n",
    "                emb_seq = np.concatenate([emb_seq, np.full((self.seq_len - emb_seq.shape[0], emb_seq.shape[1]), self.emb_pad, dtype=emb_seq.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_seq = emb_seq[: self.seq_len] # no padding was usedd\n",
    "\n",
    "            if emb_struct.shape[0] < self.seq_len:\n",
    "                emb_struct = np.concatenate([emb_struct, np.full((self.seq_len - emb_struct.shape[0], emb_struct.shape[1]), self.emb_pad, dtype=emb_struct.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_struct = emb_struct[: self.seq_len] # no padding was used\n",
    "\n",
    "            self.samples.append((emb_seq, sequence, emb_struct))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb_seq, seq, emb_struct = self.samples[idx]\n",
    "        emb_seq, emb_struct = torch.from_numpy(emb_seq).float(), torch.from_numpy(emb_struct).float()\n",
    "        # label = torch.tensor(1, dtype=torch.float32)  # single scalar labe\n",
    "        return emb_seq, seq, emb_struct\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        # emb_seq_list, emb_struct_list, label_list = zip(*out)\n",
    "        emb_seq_list, seqs_list, emb_struct_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings\n",
    "        emb_seq_stacked  = torch.stack([torch.as_tensor(x) for x in emb_seq_list],  dim=0)  # [B, ...]        \n",
    "        emb_struct_stacked  = torch.stack([torch.as_tensor(x) for x in emb_struct_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        # labels = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return emb_seq_stacked, seqs_list, emb_struct_stacked\n",
    "\n",
    "emb_seq_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_binders\"\n",
    "emb_struct_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "\n",
    "meta_Dataset = CLIP_PPint_w_esmIF(\n",
    "    meta_df_shuffled_LONG,\n",
    "    paths=[emb_seq_path, emb_struct_path],\n",
    "    embedding_dim_seq=1280,\n",
    "    embedding_dim_struct=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21333b2d-5dd8-4455-bf85-7329f1310f3e",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb44f545-4476-4782-b9e9-747a8ba862da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=512, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "### Training seq_down for 1 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_1.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_1.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1280, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca76ebd-44d4-4e39-bd14-a703cd47e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                        | 0/355 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'non_padding_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m B, Lq, _ \u001b[38;5;241m=\u001b[39m seq_embed\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     13\u001b[0m _, Ls, Ds \u001b[38;5;241m=\u001b[39m struct_embed\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 15\u001b[0m seq_mask \u001b[38;5;241m=\u001b[39m \u001b[43mnon_padding_mask\u001b[49m(seq_embed, padding_value)   \u001b[38;5;66;03m# [B, Lq]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m str_mask \u001b[38;5;241m=\u001b[39m non_padding_mask(struct_embed, padding_value)  \u001b[38;5;66;03m# [B, Ls]\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# enforce residue-wise alignment\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(seq_mask.sum(dim=1).cpu().tolist())\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(str_mask.sum(dim=1).cpu().tolist())\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'non_padding_mask' is not defined"
     ]
    }
   ],
   "source": [
    "### Loading original embeddings and RANDOM projection head\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "original_embeds_random_head = []\n",
    "seq_proj = nn.Linear(1280, 512).to(\"cuda\")\n",
    "padding_value = -5000.0\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    seq_embed, seqs_list, struct_embed = batch\n",
    "    seq_embed, struct_embed = seq_embed.to(device), struct_embed.to(device)\n",
    "\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        # proj = model.seq_down(real_seq)      # [Li, 512]\n",
    "        proj = seq_proj(real_seq)\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    original_embeds_random_head.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac15e2cd-2621-4248-98b0-7beb08476767",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(original_embeds_random_head, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similarities original ESM-2 embeddings/random proj_head vs ESM-IF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c415d-b9f6-4563-9a13-787ea1de5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading original embeddings and PRE-TRAINED projection head\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "original_embeds_pretrained_head_ep1 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    seq_embed, seqs_list, struct_embed = batch\n",
    "    seq_embed, struct_embed = seq_embed.to(device), struct_embed.to(device)\n",
    "\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        # proj = seq_proj(real_seq)\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    original_embeds_pretrained_head_ep1.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8439dfe-3a2c-464a-b87d-710dd1278bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(original_embeds_pretrained_head_ep1, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similarities original ESM-2 embeddings/pre-trained proj_head vs ESM-IF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e3647-8445-483e-af10-7c43815e33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep1 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep1.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16756c20-95b2-4565-90ee-6378ed095457",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep1, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 1)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c027063-6b79-44d1-ac3b-bdae006bb2a4",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d98b2c-b10e-4607-a3fd-be6453bd14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 5 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_5.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_5.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1280, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc13145-22b7-4b18-8ad1-4f6be4cfcf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep5 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep5.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff680f-896c-4178-9f14-d0cc0a850fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep5, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 5)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cba68a-9235-4af0-86c8-48eaeedc4bea",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c24e93-bf66-4c0a-a8ce-a503268e82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 25 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_25.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_25.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1280, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a2db4-0a97-4186-a5b9-b870fac86a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep25 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep25.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03f5154-74ac-4016-9a4b-9306e6b49cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep25, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 25)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d435f0c-890c-4355-8013-5837d35b347b",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d6682-82a4-483f-a891-98e8c126a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 50 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_50.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "# seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_5.pt\"\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_50.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1280, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0b655-da3e-49b1-8096-dade7ed5f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep50 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep50.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7151f-33fa-469a-8300-3c83c286ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep50, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head(seq_down_5) vs ESM-IF (after epoch 50)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f1443-63e7-42a4-a71a-5acfbf7bf0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep50, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head(seq_down_50) vs ESM-IF (after epoch 50)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf7efb-333f-4ab6-9876-80ae00d0b3fc",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15679cbc-101c-4486-a2e0-9f7fb2801604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Training seq_down for 60 epoch \n",
    "# seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_60.pt\"\n",
    "# seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "# seq_encoder = ESM2EncoderLoRA()\n",
    "# seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "# seq_encoder.to(device)\n",
    "# seq_encoder.eval()\n",
    "\n",
    "# seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_25.pt\"\n",
    "# seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "# seq_down = nn.Linear(1280, 512)\n",
    "# seq_down.load_state_dict(seq_down_state_dict)\n",
    "# seq_down.to(device)\n",
    "# # seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c371f-26a9-4549-8917-9984af60741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "# _loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "# pretrained_encoder_head_ep60 = []\n",
    "\n",
    "# for batch in tqdm(_loader):\n",
    "#     ___, seqs_list, struct_embed = batch\n",
    "#     struct_embed = struct_embed.to(device)\n",
    "\n",
    "#     seq_embed = seq_encoder(seqs_list)\n",
    "#     B, Lq, _ = seq_embed.shape\n",
    "#     _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "#     seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "#     str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "#     # enforce residue-wise alignment\n",
    "#     # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "#     # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "#     assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "#     # ---- project seq tokens + pad to structure length ----\n",
    "#     seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "#     for i in range(B):\n",
    "#         real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "#         proj = seq_down(real_seq)      # [Li, 512]\n",
    "#         seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "#     # ---- token-level cosine similarity (aligned positions) ----\n",
    "#     cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "#     cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "#     per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "#     pretrained_encoder_head_ep60.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56854a-1799-4676-af6f-ff868a66d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 4))\n",
    "# plt.hist(pretrained_encoder_head_ep60, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# # plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "# plt.xlabel(\"cos-sim\")\n",
    "# plt.ylabel(\"Density\")\n",
    "# plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 60)\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fb904-b1f4-497c-8deb-8eeabc241973",
   "metadata": {},
   "source": [
    "#### Cosine-similarity 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a663e-ccbb-4a8c-8664-585b0f48836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 60 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/39c990f3-0db5-430a-8095-075f38a5e808/seq_encoder_cos-sim0.2.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/39c990f3-0db5-430a-8095-075f38a5e808/seq_down_cos-sim0.2.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1280, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c3590-d12b-452a-83dd-44401ff2913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep02 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep02.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a6b26-06f3-49eb-a559-4b295474808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep02, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (cos-sim 0.2)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de98b6f-4c41-4953-8b90-846f34c59d93",
   "metadata": {},
   "source": [
    "#### Cosine-similarity 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266f1d5-1b36-434d-a786-b2fdcfd5854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 60 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/39c990f3-0db5-430a-8095-075f38a5e808/seq_encoder_cos-sim0.3.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/39c990f3-0db5-430a-8095-075f38a5e808/seq_down_cos-sim0.3.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1280, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9068b5c-fc86-4c39-b47c-8b6d760f7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep03 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1280]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep03.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923520f4-a751-45e4-b8c9-f23170f497c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep03, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (cos-sim 0.3)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fe8f8-f830-4929-9ebb-f6c1afcd1b76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688cca7-6bd8-46a6-82e4-62e12d5f5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.hist(original_embeds_random_head, bins=50, alpha=0.5,\n",
    "         label=\"Original ESM-2 embeds/ random proj_head\", density=True)\n",
    "\n",
    "# plt.hist(original_embeds_pretrained_head_ep1, bins=50, alpha=0.5,\n",
    "#          label=\"Original embeds (pretrained head)\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep1, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 1 \", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep5, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 5 \", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep25, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 25\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep50, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head(seq_down_5) epoch 50\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep02, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head cos-sim 0.2\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep03, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head cos-sim 0.3\", density=True)\n",
    "\n",
    "plt.xlabel(\"Cosine similarity\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cos-sim SM-2 vs ESM-IF (proj head frozen after epoch 4)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d545a9b-7242-425f-88d1-27ef72964ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.hist(original_embeds_random_head, bins=50, alpha=0.5,\n",
    "         label=\"Original ESM-2 embeds/ random proj_head\", density=True)\n",
    "\n",
    "# plt.hist(original_embeds_pretrained_head_ep1, bins=50, alpha=0.5,\n",
    "#          label=\"Original embeds (pretrained head)\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep1, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 1 \", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep5, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 5 \", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep25, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 25\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep50, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 50\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep02, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head cos-sim 0.2\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep03, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head cos-sim 0.3\", density=True)\n",
    "\n",
    "plt.xlabel(\"Cosine similarity\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cos-sim SM-2 vs ESM-IF (proj head frozen after epoch 4)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae242efa-a799-4608-ad97-8e0eaa676654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESM CUDA Env",
   "language": "python",
   "name": "esm_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
