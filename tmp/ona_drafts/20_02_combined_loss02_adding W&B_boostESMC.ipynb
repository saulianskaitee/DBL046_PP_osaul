{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f838074-e829-40d5-9b15-949a9bfe9708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import uuid, sys, os\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "\n",
    "from transformers import EsmModel, AutoTokenizer # huggingface\n",
    "import esm\n",
    "\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.cuda.set_device(0)  # 0 == \"first visible\" -> actually GPU 2 on the node\n",
    "torch.manual_seed(0)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import AdamW\n",
    "from accelerate import Accelerator\n",
    "import training_utils.partitioning_utils as pat_utils\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "# LoRA\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d0770f-c901-45f7-b5e7-801a2f8f261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1+cu128\n",
      "Using device: cuda\n",
      "Current location: /zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch:\", torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print(\"Current location:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da12c27-b0c9-4166-bf60-a7e182e83805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /zhome/c9/0/203261/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms232958\u001b[0m (\u001b[33ms232958-danmarks-tekniske-universitet-dtu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://api.wandb.ai/status\").status_code\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"f8a6d759fe657b095d56bddbdb4d586dfaebd468\", relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a771b897-1647-4594-b648-41d2639d5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting a seed to have the same initiation of weights\n",
    "\n",
    "def set_seed(seed: int = 0):\n",
    "    # Python & NumPy\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "\n",
    "    # CuDNN settings (for convolution etc.)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # (Optional) for some Python hashing randomness\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "SEED = 0\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcfc6c69-e492-4bf1-a23e-e8ee41a27d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "memory_verbose = False\n",
    "use_wandb = True # Used to track loss in real-time without printing\n",
    "\n",
    "seq_embed_dimension = 1152 #| 960 | 1152\n",
    "# struct_embed_dimension = 256\n",
    "number_of_recycles = 2\n",
    "padding_value = -5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b152a01f-a72c-4d75-9e1c-6b6f937515eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory:  34.072559616\n",
      "Reserved memory:  0.0\n",
      "Allocated memory:  0.0\n",
      "Free memory:  0.0\n"
     ]
    }
   ],
   "source": [
    "# ## Training variables\n",
    "runID = uuid.uuid4()\n",
    "\n",
    "def print_mem_consumption():\n",
    "    # 1. Total memory available on the GPU (device 0)\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    # 2. How much memory PyTorch has *reserved* from CUDA\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    # 3. How much of that reserved memory is actually *used* by tensors\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    # 4. Reserved but not currently allocated (so “free inside PyTorch’s pool”)\n",
    "    f = r - a\n",
    "\n",
    "    print(\"Total memory: \", t/1e9)      # total VRAM in GB\n",
    "    print(\"Reserved memory: \", r/1e9)   # PyTorch’s reserved pool in GB\n",
    "    print(\"Allocated memory: \", a//1e9) # actually in use (integer division)\n",
    "    print(\"Free memory: \", f/1e9)       # slack in the reserved pool in GB\n",
    "print_mem_consumption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b001f70e-d769-4c9e-ad66-6e6c919a0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_key_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings < (padding_value + offset)).all(dim=-1)\n",
    "\n",
    "def create_mean_of_non_masked(embeddings, padding_mask):\n",
    "    # Use masked select and mean to compute the mean of non-masked elements\n",
    "    # embeddings should be of shape (batch_size, seq_len, features)\n",
    "    seq_embeddings = []\n",
    "    for i in range(embeddings.shape[0]): # looping over all batch elements\n",
    "        non_masked_embeddings = embeddings[i][~padding_mask[i]] # shape [num_real_tokens, features]\n",
    "        if len(non_masked_embeddings) == 0:\n",
    "            print(\"You are masking all positions when creating sequence representation\")\n",
    "            sys.exit(1)\n",
    "        mean_embedding = non_masked_embeddings.mean(dim=0) # sequence is represented by the single vecotr [1152] [features]\n",
    "        seq_embeddings.append(mean_embedding)\n",
    "    return torch.stack(seq_embeddings)\n",
    "\n",
    "def non_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings > (padding_value + offset)).all(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349b030-2126-46c1-bb65-8d25e7fb6c0e",
   "metadata": {},
   "source": [
    "### Loading Data for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1277c85e-2ea7-44f6-8523-8b1362106edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interface_id</th>\n",
       "      <th>PDB</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>seq_target</th>\n",
       "      <th>seq_target_len</th>\n",
       "      <th>seq_pdb_target</th>\n",
       "      <th>pdb_target_len</th>\n",
       "      <th>target_chain</th>\n",
       "      <th>seq_binder</th>\n",
       "      <th>seq_binder_len</th>\n",
       "      <th>seq_pdb_binder</th>\n",
       "      <th>pdb_binder_len</th>\n",
       "      <th>binder_chain</th>\n",
       "      <th>pdb_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6IDB_0</td>\n",
       "      <td>6IDB</td>\n",
       "      <td>6IDB_0_A</td>\n",
       "      <td>6IDB_0_B</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "      <td>6IDB_A</td>\n",
       "      <td>GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...</td>\n",
       "      <td>172</td>\n",
       "      <td>GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...</td>\n",
       "      <td>172</td>\n",
       "      <td>6IDB_B</td>\n",
       "      <td>6idb.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2WZP_3</td>\n",
       "      <td>2WZP</td>\n",
       "      <td>2WZP_3_D</td>\n",
       "      <td>2WZP_3_G</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "      <td>2WZP_D</td>\n",
       "      <td>TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...</td>\n",
       "      <td>266</td>\n",
       "      <td>TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...</td>\n",
       "      <td>266</td>\n",
       "      <td>2WZP_G</td>\n",
       "      <td>2wzp.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ZKP_0</td>\n",
       "      <td>1ZKP</td>\n",
       "      <td>1ZKP_0_A</td>\n",
       "      <td>1ZKP_0_C</td>\n",
       "      <td>LYFQSNAKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLA...</td>\n",
       "      <td>246</td>\n",
       "      <td>LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...</td>\n",
       "      <td>251</td>\n",
       "      <td>1ZKP_A</td>\n",
       "      <td>AKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQKYI...</td>\n",
       "      <td>240</td>\n",
       "      <td>AMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQK...</td>\n",
       "      <td>245</td>\n",
       "      <td>1ZKP_C</td>\n",
       "      <td>1zkp.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6GRH_3</td>\n",
       "      <td>6GRH</td>\n",
       "      <td>6GRH_3_C</td>\n",
       "      <td>6GRH_3_D</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "      <td>6GRH_C</td>\n",
       "      <td>MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...</td>\n",
       "      <td>396</td>\n",
       "      <td>MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...</td>\n",
       "      <td>396</td>\n",
       "      <td>6GRH_D</td>\n",
       "      <td>6grh.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8R57_1</td>\n",
       "      <td>8R57</td>\n",
       "      <td>8R57_1_M</td>\n",
       "      <td>8R57_1_f</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "      <td>8R57_M</td>\n",
       "      <td>PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...</td>\n",
       "      <td>64</td>\n",
       "      <td>PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...</td>\n",
       "      <td>64</td>\n",
       "      <td>8R57_f</td>\n",
       "      <td>8r57.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>4YO8_0</td>\n",
       "      <td>4YO8</td>\n",
       "      <td>4YO8_0_A</td>\n",
       "      <td>4YO8_0_B</td>\n",
       "      <td>HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...</td>\n",
       "      <td>238</td>\n",
       "      <td>HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...</td>\n",
       "      <td>238</td>\n",
       "      <td>4YO8_A</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "      <td>4YO8_B</td>\n",
       "      <td>4yo8.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>3CKI_0</td>\n",
       "      <td>3CKI</td>\n",
       "      <td>3CKI_0_A</td>\n",
       "      <td>3CKI_0_B</td>\n",
       "      <td>DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...</td>\n",
       "      <td>256</td>\n",
       "      <td>DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...</td>\n",
       "      <td>256</td>\n",
       "      <td>3CKI_A</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "      <td>3CKI_B</td>\n",
       "      <td>3cki.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>7MHY_1</td>\n",
       "      <td>7MHY</td>\n",
       "      <td>7MHY_1_M</td>\n",
       "      <td>7MHY_1_N</td>\n",
       "      <td>QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...</td>\n",
       "      <td>118</td>\n",
       "      <td>QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...</td>\n",
       "      <td>118</td>\n",
       "      <td>7MHY_M</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "      <td>7MHY_N</td>\n",
       "      <td>7mhy.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>7MHY_2</td>\n",
       "      <td>7MHY</td>\n",
       "      <td>7MHY_2_O</td>\n",
       "      <td>7MHY_2_P</td>\n",
       "      <td>IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...</td>\n",
       "      <td>100</td>\n",
       "      <td>IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...</td>\n",
       "      <td>100</td>\n",
       "      <td>7MHY_O</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "      <td>7MHY_P</td>\n",
       "      <td>7mhy.pdb.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>6O42_0</td>\n",
       "      <td>6O42</td>\n",
       "      <td>6O42_0_L</td>\n",
       "      <td>6O42_0_H</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>214</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>214</td>\n",
       "      <td>6O42_L</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "      <td>6O42_H</td>\n",
       "      <td>6o42.pdb.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1977 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     interface_id   PDB       ID1       ID2  \\\n",
       "0          6IDB_0  6IDB  6IDB_0_A  6IDB_0_B   \n",
       "1          2WZP_3  2WZP  2WZP_3_D  2WZP_3_G   \n",
       "2          1ZKP_0  1ZKP  1ZKP_0_A  1ZKP_0_C   \n",
       "3          6GRH_3  6GRH  6GRH_3_C  6GRH_3_D   \n",
       "4          8R57_1  8R57  8R57_1_M  8R57_1_f   \n",
       "...           ...   ...       ...       ...   \n",
       "1972       4YO8_0  4YO8  4YO8_0_A  4YO8_0_B   \n",
       "1973       3CKI_0  3CKI  3CKI_0_A  3CKI_0_B   \n",
       "1974       7MHY_1  7MHY  7MHY_1_M  7MHY_1_N   \n",
       "1975       7MHY_2  7MHY  7MHY_2_O  7MHY_2_P   \n",
       "1976       6O42_0  6O42  6O42_0_L  6O42_0_H   \n",
       "\n",
       "                                             seq_target  seq_target_len  \\\n",
       "0     DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...             317   \n",
       "1     VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...             122   \n",
       "2     LYFQSNAKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLA...             246   \n",
       "3     SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...             266   \n",
       "4     DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...             118   \n",
       "...                                                 ...             ...   \n",
       "1972  HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...             238   \n",
       "1973  DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...             256   \n",
       "1974  QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...             118   \n",
       "1975  IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...             100   \n",
       "1976  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...             214   \n",
       "\n",
       "                                         seq_pdb_target  pdb_target_len  \\\n",
       "0     DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...             317   \n",
       "1     VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...             122   \n",
       "2     LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...             251   \n",
       "3     SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...             266   \n",
       "4     DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...             118   \n",
       "...                                                 ...             ...   \n",
       "1972  HENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNVFHKG...             238   \n",
       "1973  DPMKNTCKLLVVADHRFYRYMGRGEESTTTNYLIELIDRVDDIYRN...             256   \n",
       "1974  QVQLRQSGAELAKPGASVKMSCKASGYTFTNYWLHWIKQRPGQGLE...             118   \n",
       "1975  IQLVQSGPELVKISCKASGYTFTNYGMNWVRQAPGKGLKWMGWINT...             100   \n",
       "1976  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...             214   \n",
       "\n",
       "     target_chain                                         seq_binder  \\\n",
       "0          6IDB_A  GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...   \n",
       "1          2WZP_D  TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...   \n",
       "2          1ZKP_A  AKTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQKYI...   \n",
       "3          6GRH_C  MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...   \n",
       "4          8R57_M  PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...   \n",
       "...           ...                                                ...   \n",
       "1972       4YO8_A  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...   \n",
       "1973       3CKI_A  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...   \n",
       "1974       7MHY_M  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...   \n",
       "1975       7MHY_O  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...   \n",
       "1976       6O42_L  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...   \n",
       "\n",
       "      seq_binder_len                                     seq_pdb_binder  \\\n",
       "0                172  GLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAID...   \n",
       "1                266  TIKNFTFFSPNSTEFPVGSNNDGKLYMMLTGMDYRTIRRKDWSSPL...   \n",
       "2                240  AMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGVLAQLQK...   \n",
       "3                396  MINVYSNLMSAWPATMAMSPKLNRNMPTFSQIWDYERITPASAAGE...   \n",
       "4                 64  PKKQKHKHKKVKLAVLQFYKVDDATGKVTRLRKECPNADCGAGTFM...   \n",
       "...              ...                                                ...   \n",
       "1972             242  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...   \n",
       "1973             121  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...   \n",
       "1974             109  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...   \n",
       "1975              94  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...   \n",
       "1976             220  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...   \n",
       "\n",
       "      pdb_binder_len binder_chain     pdb_path  \n",
       "0                172       6IDB_B  6idb.pdb.gz  \n",
       "1                266       2WZP_G  2wzp.pdb.gz  \n",
       "2                245       1ZKP_C  1zkp.pdb.gz  \n",
       "3                396       6GRH_D  6grh.pdb.gz  \n",
       "4                 64       8R57_f  8r57.pdb.gz  \n",
       "...              ...          ...          ...  \n",
       "1972             242       4YO8_B  4yo8.pdb.gz  \n",
       "1973             121       3CKI_B  3cki.pdb.gz  \n",
       "1974             109       7MHY_N  7mhy.pdb.gz  \n",
       "1975              94       7MHY_P  7mhy.pdb.gz  \n",
       "1976             220       6O42_H  6o42.pdb.gz  \n",
       "\n",
       "[1977 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_train = pd.read_csv(\"/work3/s232958/data/PPint_DB/PPint_train_w_pbd_lens.csv\",index_col=0).reset_index(drop=True)\n",
    "Df_test = pd.read_csv(\"/work3/s232958/data/PPint_DB/PPint_test_w_pbd_lens.csv\",index_col=0).reset_index(drop=True)\n",
    "\n",
    "Df_train[\"target_chain\"] = [str(row.ID1[:5]+row.ID1[-1]) for __, row in Df_train.iterrows()]\n",
    "Df_train[\"binder_chain\"] = [str(row.ID2[:5]+row.ID2[-1]) for __, row in Df_train.iterrows()]\n",
    "\n",
    "Df_test[\"target_chain\"] = [str(row.ID1[:5]+row.ID1[-1]) for __, row in Df_test.iterrows()]\n",
    "Df_test[\"binder_chain\"] = [str(row.ID2[:5]+row.ID2[-1]) for __, row in Df_test.iterrows()]\n",
    "\n",
    "Df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dc3459-94e9-4184-88a3-b13120177122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SKVVKFSYMWTINNFSFCREEMGEVIKSSTFSSKLKWCLRVNPKGLDSKDYLSLYLLLVSCPKEVRAKFKFSILNAKGEETKAMESQRAYRFVQGKDWGFKKFIRRGFLLDEANGLLPDDKLTLFCEVSVVQDSQTMNMVKVPECRLADELGGLWENSRFTDCCLCVAGQEFQAHKAILAARSPVFSAMFEHKNRVEINDVEPEVFKEMMCFIYTGKAPNLDKMADDLLAAADKYALERLKVMCEDALCSNLSVENAAEILILADLHSADQLKTQAVDFINYHA'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_train[Df_train.ID1.str.startswith(\"3HU6\")].seq_target.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab57963-a7cc-4b28-b250-bf5f5529f82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6IDB_A</td>\n",
       "      <td>DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2WZP_D</td>\n",
       "      <td>VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ZKP_A</td>\n",
       "      <td>LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6GRH_C</td>\n",
       "      <td>SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8R57_M</td>\n",
       "      <td>DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>4YO8_B</td>\n",
       "      <td>HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>3CKI_B</td>\n",
       "      <td>CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>7MHY_N</td>\n",
       "      <td>DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>7MHY_P</td>\n",
       "      <td>VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>6O42_H</td>\n",
       "      <td>QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3949 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                           sequence  seq_len\n",
       "0     6IDB_A  DKICLGHHAVSNGTKVNTLTERGVEVVNATETVERTNIPRICSKGK...      317\n",
       "1     2WZP_D  VQLQESGGGLVQAGGSLRLSCTASRRTGSNWCMGWFRQLAGKEPEL...      122\n",
       "2     1ZKP_A  LYFQSNAMKMTVVGFWGGFPEAGEATSGYLFEHDGFRLLVDCGSGV...      251\n",
       "3     6GRH_C  SKHELSLVEVTHYTDPEVLAIVKDFHVRGNFASLPEFAERTFVSAV...      266\n",
       "4     8R57_M  DLMTALQLVMKKSSAHDGLVKGLREAAKAIEKHAAQICVLAEDCDQ...      118\n",
       "...      ...                                                ...      ...\n",
       "3949  4YO8_B  HHHHHENLYFQGVQKIGILGAMREEITPILELFGVDFEEIPLGGNV...      242\n",
       "3950  3CKI_B  CTCSPSHPQDAFCNSDIVIRAKVVGKKLVKEGPFGTLVYTIKQMKM...      121\n",
       "3951  7MHY_N  DVLMTQTPLSLPVSLGDQVSISCRSSQSIVHNTYLEWYLQKPGQSP...      109\n",
       "3952  7MHY_P  VLMTQTPLSLPVSISCRSSQSIVHSNGNTYLEWYLQKPGQSPKLLI...       94\n",
       "3953  6O42_H  QVQLVQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLE...      220\n",
       "\n",
       "[3949 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Df1 = Df_train[[\"target_chain\", \"seq_pdb_target\", \"pdb_target_len\"]].rename(columns = {\n",
    "    \"seq_pdb_target\" : \"sequence\",\n",
    "    \"target_chain\" : \"ID\",\n",
    "    \"pdb_target_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "train_Df2 = Df_train[[\"binder_chain\", \"seq_pdb_binder\", \"pdb_binder_len\"]].rename(columns = {\n",
    "    \"seq_pdb_binder\" : \"sequence\",\n",
    "    \"binder_chain\" : \"ID\",\n",
    "    \"pdb_binder_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "Df_train_LONG = pd.concat([train_Df1, train_Df2], axis=0, ignore_index=True).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "Df_train_LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9355a32-db3d-4962-b5b3-6c7515eb52c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1NNW_A</td>\n",
       "      <td>VYVAVLANIAGNLPALTAALSRIEEMREEGYEIEKYYILGNIVGLF...</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3UCN_A</td>\n",
       "      <td>TADLSPLLEANRKWADECAAKDSTYFSKVAGSQAPEYLYIGCADSR...</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1POV_1</td>\n",
       "      <td>QHRSRSESSIESFFARGACVTIMTVDNPASTTNKDKLFAVWKITYK...</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3R6Y_C</td>\n",
       "      <td>VRIEKDFLGEKEIPKDAYYGVQTIRATENFPITGYRIHPELIKSLG...</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5YHI_A</td>\n",
       "      <td>PMRYPVDVYTGKIQVDGELMLTELGLEGDGPDRALCHYPREHYLYW...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>3GXE_F</td>\n",
       "      <td>GLPGMKGHRGF</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>6LY5_l</td>\n",
       "      <td>ANFIKPYNDDPFVGHLATPITSSAVTRSLLKNLPAYRFGLTPLLRG...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>5MLK_B</td>\n",
       "      <td>ARISKVLVANRGEIAVRVIRAARDAGLPSVAVYAEPDAESPHVRLA...</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>8BS4_B</td>\n",
       "      <td>GHPVLEKLKAAHSYNPKEFEWNLKSGRVFIIKSYSEDDIHRSIKYS...</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>6WDS_H</td>\n",
       "      <td>VQLVESGGGLVKPGGLRLSCAASGFTFSTYIMTWVRQAPGRGLEWV...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                           sequence  seq_len\n",
       "0    1NNW_A  VYVAVLANIAGNLPALTAALSRIEEMREEGYEIEKYYILGNIVGLF...      251\n",
       "1    3UCN_A  TADLSPLLEANRKWADECAAKDSTYFSKVAGSQAPEYLYIGCADSR...      222\n",
       "2    1POV_1  QHRSRSESSIESFFARGACVTIMTVDNPASTTNKDKLFAVWKITYK...      235\n",
       "3    3R6Y_C  VRIEKDFLGEKEIPKDAYYGVQTIRATENFPITGYRIHPELIKSLG...      383\n",
       "4    5YHI_A  PMRYPVDVYTGKIQVDGELMLTELGLEGDGPDRALCHYPREHYLYW...      202\n",
       "..      ...                                                ...      ...\n",
       "983  3GXE_F                                        GLPGMKGHRGF       11\n",
       "984  6LY5_l  ANFIKPYNDDPFVGHLATPITSSAVTRSLLKNLPAYRFGLTPLLRG...      144\n",
       "985  5MLK_B  ARISKVLVANRGEIAVRVIRAARDAGLPSVAVYAEPDAESPHVRLA...      384\n",
       "986  8BS4_B  GHPVLEKLKAAHSYNPKEFEWNLKSGRVFIIKSYSEDDIHRSIKYS...      193\n",
       "987  6WDS_H  VQLVESGGGLVKPGGLRLSCAASGFTFSTYIMTWVRQAPGRGLEWV...      115\n",
       "\n",
       "[985 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Df1 = Df_test[[\"target_chain\", \"seq_pdb_target\", \"pdb_target_len\"]].rename(columns = {\n",
    "    \"seq_pdb_target\" : \"sequence\",\n",
    "    \"target_chain\" : \"ID\",\n",
    "    \"pdb_target_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "test_Df2 = Df_test[[\"binder_chain\", \"seq_pdb_binder\", \"pdb_binder_len\"]].rename(columns = {\n",
    "    \"seq_pdb_binder\" : \"sequence\",\n",
    "    \"binder_chain\" : \"ID\",\n",
    "    \"pdb_binder_len\": \"seq_len\",\n",
    "})\n",
    "\n",
    "Df_test_LONG = pd.concat([test_Df1, test_Df2], axis=0, ignore_index=True).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "Df_test_LONG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ed436-2f6a-42d8-912c-a0e9ff15b06a",
   "metadata": {},
   "source": [
    "#### Loading seqeunce, structural_embeddings & using pooled embeddings for CLIP (PPint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d15e1e2-6358-47d8-9fc5-e9e3f977566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Loading ESM2 embeddings and contacts: 100%|███████████████████████████████████████████████████████████| 3949/3949 [00:10<00:00, 386.91it/s]\n",
      "#Loading ESM2 embeddings and contacts: 100%|█████████████████████████████████████████████████████████████| 985/985 [00:02<00:00, 415.20it/s]\n"
     ]
    }
   ],
   "source": [
    "class CLIP_PPint_w_esmIF(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        paths,\n",
    "        embedding_dim_struct=512,\n",
    "        embedding_dim_seq=1152,\n",
    "        embedding_pad_value=-5000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim_seq = embedding_dim_seq\n",
    "        self.embedding_dim_struct = embedding_dim_struct\n",
    "        self.emb_pad = embedding_pad_value\n",
    "\n",
    "        # lengths\n",
    "        self.max_len = self.dframe[\"seq_len\"].max()+2\n",
    "\n",
    "        # paths\n",
    "        self.seq_encodings_path, self.struct_encodings_path = paths\n",
    "\n",
    "        # index & storage\n",
    "        self.dframe.set_index(\"ID\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings and contacts\"):\n",
    "\n",
    "            # laod embeddings\n",
    "            emb_struct = np.load(os.path.join(self.struct_encodings_path, f\"{accession}.npy\"))[1:-1, :] # remove EOS BOS, to use only real aa token for cos-sim\n",
    "            sequence = self.dframe.loc[accession].sequence\n",
    "\n",
    "            if len(sequence) != emb_struct.shape[0]:\n",
    "                print(sequence, emb_struct.shape[0])\n",
    "\n",
    "            if emb_struct.shape[1] != self.embedding_dim_struct:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "\n",
    "            if emb_struct.shape[0] < self.max_len:\n",
    "                emb_struct = np.concatenate([emb_struct, np.full((self.max_len - emb_struct.shape[0], emb_struct.shape[1]), self.emb_pad, dtype=emb_struct.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_struct = emb_struct[: self.max_len] # no padding was used\n",
    "\n",
    "            self.samples.append((sequence, emb_struct))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, emb_struct = self.samples[idx]\n",
    "        emb_struct = torch.from_numpy(emb_struct).float()\n",
    "        label = torch.tensor(1, dtype=torch.float32)  # single scalar labe        \n",
    "        return sequence, emb_struct, label\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        # emb_seq_list, emb_struct_list, label_list = zip(*out)\n",
    "        sequence_list, emb_struct_list, lbl_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings    \n",
    "        emb_struct_stacked  = torch.stack([torch.as_tensor(x) for x in emb_struct_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        lbl_stacked = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return list(sequence_list), emb_struct_stacked, lbl_stacked\n",
    "\n",
    "emb_seq_path = \"/work3/s232958/data/PPint_DB/embeddings_esmC\"\n",
    "emb_struct_path = \"/work3/s232958/data/PPint_DB/esmif_embeddings_noncanonical\"\n",
    "\n",
    "train_Dataset = CLIP_PPint_w_esmIF(\n",
    "    Df_train_LONG,\n",
    "    paths=[emb_seq_path, emb_struct_path],\n",
    "    embedding_dim_seq=1152,\n",
    "    embedding_dim_struct=512\n",
    ")\n",
    "\n",
    "test_Dataset = CLIP_PPint_w_esmIF(\n",
    "    Df_test_LONG,\n",
    "    paths=[emb_seq_path, emb_struct_path],\n",
    "    embedding_dim_seq=1152,\n",
    "    embedding_dim_struct=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f9021-6e1b-4dd5-a207-1f3d976d9c37",
   "metadata": {},
   "source": [
    "#### Loading seqeunce, structural_embeddings & using pooled embeddings for CLIP (meta-anlaysis dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c2f4cb1-1c4f-4a30-8d41-dca5e0704a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGFR2_124</td>\n",
       "      <td>DIVEEAHKLLSRAMSEAMENDDPDKLRRANELYFKLEEALKNNDPK...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EGFR_2_149</td>\n",
       "      <td>SEELVEKVVEEILNSDLSNDQKILETHDRLMELHDQGKISKEEYYK...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FGFR2_339</td>\n",
       "      <td>TINRVFHLHIQGDTEEARKAHEELVEEVRRWAEELAKRLNLTVRVT...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FGFR2_1234</td>\n",
       "      <td>DDLRKVERIASELAFFAAEQNDTKVAFTALELIHQLIRAIFHNDEE...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IL2Ra_48</td>\n",
       "      <td>DEEVEELEELLEKAEDPRERAKLLRELAKLIRRDPRLRELATEVVA...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>t_SARS_CoV2_RBD</td>\n",
       "      <td>TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>t_VirB8</td>\n",
       "      <td>ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>t_sntx_2</td>\n",
       "      <td>MICHNQQSSQPPTTKTCSEGQCYKKTWRDHRGTIIERGCGCPTVKP...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>t_sntx</td>\n",
       "      <td>MICYNQQSSQPPTTKTCSETSCYKKTWRDHRGTIIERGCGCPKVKP...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>t_EGFR_3</td>\n",
       "      <td>VCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYVQRNYD...</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3548 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                           sequence  \\\n",
       "0           FGFR2_124  DIVEEAHKLLSRAMSEAMENDDPDKLRRANELYFKLEEALKNNDPK...   \n",
       "1          EGFR_2_149  SEELVEKVVEEILNSDLSNDQKILETHDRLMELHDQGKISKEEYYK...   \n",
       "2           FGFR2_339  TINRVFHLHIQGDTEEARKAHEELVEEVRRWAEELAKRLNLTVRVT...   \n",
       "3          FGFR2_1234  DDLRKVERIASELAFFAAEQNDTKVAFTALELIHQLIRAIFHNDEE...   \n",
       "4            IL2Ra_48  DEEVEELEELLEKAEDPRERAKLLRELAKLIRRDPRLRELATEVVA...   \n",
       "...               ...                                                ...   \n",
       "3543  t_SARS_CoV2_RBD  TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFK...   \n",
       "3544          t_VirB8  ANPYISVANIMLQNYVKQREKYNYDTLKEQFTFIKNASTSIVYMQF...   \n",
       "3545         t_sntx_2  MICHNQQSSQPPTTKTCSEGQCYKKTWRDHRGTIIERGCGCPTVKP...   \n",
       "3546           t_sntx  MICYNQQSSQPPTTKTCSETSCYKKTWRDHRGTIIERGCGCPKVKP...   \n",
       "3547         t_EGFR_3  VCQGTSNKLTQLGTFEDHFLSLQRMFNNCEVVLGNLEITYVQRNYD...   \n",
       "\n",
       "      seq_len  \n",
       "0          62  \n",
       "1          58  \n",
       "2          65  \n",
       "3          64  \n",
       "4          65  \n",
       "...       ...  \n",
       "3543      195  \n",
       "3544      138  \n",
       "3545       60  \n",
       "3546       60  \n",
       "3547      157  \n",
       "\n",
       "[3548 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.read_csv(\"/work3/s232958/data/meta_analysis/interaction_df_metaanal_w_pbd_lens.csv\").drop(columns = [\"binder_id\", \"target_id\"]).rename(columns = {\n",
    "    \"target_id_mod\" : \"target_id\",\n",
    "    \"target_binder_ID\" : \"binder_id\",\n",
    "})\n",
    "\n",
    "meta_df[\"target_id_mod\"] = [str(\"t_\"+row.target_id) for __, row in meta_df.iterrows()]\n",
    "\n",
    "# Interaction Dict\n",
    "meta_df_shuffled = meta_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "meta_df_shuffled_LONG_binder = meta_df_shuffled[[\"binder_id\", \"binder_seq\", \"seq_len_binder\"]].rename(columns = {\n",
    "    \"binder_id\" : \"ID\",\n",
    "    \"binder_seq\" : \"sequence\",\n",
    "    \"seq_len_binder\": \"seq_len\",\n",
    "})\n",
    "\n",
    "meta_df_shuffled_LONG_taget = meta_df_shuffled[[\"target_id_mod\", \"target_seq\", \"seq_len_target\"]].rename(columns = {\n",
    "    \"target_id_mod\" : \"ID\",\n",
    "    \"target_seq\" : \"sequence\",\n",
    "    \"seq_len_target\": \"seq_len\",\n",
    "}).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "\n",
    "meta_df_shuffled_LONG = pd.concat([meta_df_shuffled_LONG_binder, meta_df_shuffled_LONG_taget], axis=0, ignore_index=True)\n",
    "meta_sample_Df = meta_df_shuffled_LONG.sample(n=len(Df_test_LONG), random_state=0).reset_index(drop=True)\n",
    "meta_df_shuffled_LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf42816b-7572-41d0-9752-6c36b26bdfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Loading ESM2 embeddings and contacts: 100%|█████████████████████████████████████████████████████████████| 985/985 [00:01<00:00, 631.82it/s]\n"
     ]
    }
   ],
   "source": [
    "class CLIP_Meta_w_esmIF(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        embedding_dim_struct=512,\n",
    "        embedding_dim_seq=1152,\n",
    "        embedding_pad_value=-5000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim_seq = embedding_dim_seq\n",
    "        self.embedding_dim_struct = embedding_dim_struct\n",
    "        self.emb_pad = embedding_pad_value\n",
    "\n",
    "        # lengths\n",
    "        self.max_len = self.dframe[\"seq_len\"].max()\n",
    "\n",
    "        # index & storage\n",
    "        \n",
    "        self.dframe.set_index(\"ID\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings and contacts\"):\n",
    "            \n",
    "            if accession.startswith(\"t_\"):\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_targets\"\n",
    "                \n",
    "                # emb_struct = np.load(os.path.join(esmIF_path, f\"{accession[2:]}.npy\"))\n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession[2:]}.npy\"))[1:-1, :] # remove EOS BOS, to use only real aa token for cos-sim\n",
    "                sequence = str(self.dframe.loc[accession].sequence)\n",
    "\n",
    "            else:\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "\n",
    "                # emb_struct = np.load(os.path.join(esmIF_path, f\"{accession}.npy\"))     # [Lb, D]\n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession}.npy\"))[1:-1, :] # remove EOS BOS, to use only real aa token for cos-sim\n",
    "                sequence = str(self.dframe.loc[accession].sequence)            \n",
    "\n",
    "            if len(sequence) != emb_struct.shape[0]:\n",
    "                print(str(sequence), len(sequence), emb_struct.shape[0])\n",
    "\n",
    "            if emb_struct.shape[1] != self.embedding_dim_struct:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "\n",
    "            if emb_struct.shape[0] < self.max_len:\n",
    "                emb_struct = np.concatenate([emb_struct, np.full((self.max_len - emb_struct.shape[0], emb_struct.shape[1]), self.emb_pad, dtype=emb_struct.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_struct = emb_struct[: self.max_len] # no padding was used\n",
    "\n",
    "            self.samples.append((sequence, emb_struct))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, emb_struct = self.samples[idx]\n",
    "        emb_struct = torch.from_numpy(emb_struct).float()\n",
    "        label = torch.tensor(1, dtype=torch.float32)  # single scalar labe        \n",
    "        return sequence, emb_struct, label\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        # emb_seq_list, emb_struct_list, label_list = zip(*out)\n",
    "        sequence_list, emb_struct_list, lbl_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings    \n",
    "        emb_struct_stacked  = torch.stack([torch.as_tensor(x) for x in emb_struct_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        lbl_stacked = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return list(sequence_list), emb_struct_stacked, lbl_stacked\n",
    "\n",
    "esm2_path_binders = \"/work3/s232958/data/meta_analysis/embeddings_esmC_binders\"\n",
    "esm2_path_targets = \"/work3/s232958/data/meta_analysis/embeddings_esmC_targets\"\n",
    "\n",
    "## Contact maps paths\n",
    "esmIF_path_binders = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "esmIF_path_targets = \"/work3/s232958/data/meta_analysis/esmif_embeddings_targets\"\n",
    "\n",
    "# meta_Dataset_train = CLIP_Meta_w_esmIF(\n",
    "#     meta_df_shuffled_LONG_train,\n",
    "#     embedding_dim_seq=1152,\n",
    "#     embedding_dim_struct=512\n",
    "# )\n",
    "\n",
    "meta_Dataset = CLIP_Meta_w_esmIF(\n",
    "    meta_sample_Df,\n",
    "    embedding_dim_seq=1152,\n",
    "    embedding_dim_struct=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d71f96-2474-4724-8a83-129fbe9ddf5d",
   "metadata": {},
   "source": [
    "### Contrastive Sequence-Structure Pre-training (CSSP)\n",
    "- combined loss = CLIP loss + token_level loss\n",
    "- stop training of `seq_down` after `4 epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cfd101c-a7ed-4708-afb0-ed6703649e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMCEncoderLoRA(nn.Module):\n",
    "    def __init__(self, padding_value=-5000.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "        self.model = EsmModel.from_pretrained(\n",
    "            \"EvolutionaryScale/esmc-300m-2024-12\",\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"EvolutionaryScale/esmc-300m-2024-12\")\n",
    "\n",
    "        # Freeze original weights\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # LoRA on top layers\n",
    "        lora_cfg = LoraConfig(\n",
    "            task_type=\"FEATURE_EXTRACTION\",\n",
    "            inference_mode=False,\n",
    "            r=4,\n",
    "            lora_alpha=1,\n",
    "            lora_dropout=0.1,\n",
    "            bias=\"none\",\n",
    "            # target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            layers_to_transform=list(range(25, 33)),\n",
    "        )\n",
    "\n",
    "        self.model = get_peft_model(self.model, lora_cfg)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attentions(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs, output_attentions=True)\n",
    "        return out.attentions   # list[num_layers] → [B, num_heads, L, L]\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs)\n",
    "        reps = out.hidden_states[-1]                  # [B, Ltok, 1152]\n",
    "        reps = reps[:, 1:-1, :]                       # remove CLS/EOS\n",
    "\n",
    "        seq_lengths = [len(s) for s in sequences]\n",
    "        Lmax = max(seq_lengths)\n",
    "\n",
    "        B, D = reps.size(0), reps.size(-1)\n",
    "        padded = torch.full((B, Lmax, D), self.padding_value, device=reps.device)\n",
    "\n",
    "        for i, (r, real_len) in enumerate(zip(reps, seq_lengths)):\n",
    "            padded[i, :real_len] = r[:real_len]\n",
    "\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e3a74c-27ff-474d-a87b-9119229ca907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_padding_mask(embeddings, padding_value=-5000, offset=10):\n",
    "    return (embeddings > (padding_value + offset)).all(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cee6ce23-8969-4fee-aae7-231abe416d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSSPBoostingESM(nn.Module):\n",
    "    def __init__(self, seq_embed_dim=1152, struct_embed_dim=512, padding_value=-5000):\n",
    "        super().__init__()\n",
    "        self.padding_value = padding_value\n",
    "        self.struct_embed_dim = 512\n",
    "        self.seq_encoder = ESM2EncoderLoRA()\n",
    "        self.seq_down = nn.Linear(seq_embed_dim, struct_embed_dim)  \n",
    "        self.logit_scale = nn.Parameter(torch.tensor(math.log(1/0.07)))\n",
    "\n",
    "    def forward(self, sequences, struct_embed):\n",
    "    \n",
    "        # ---- encode sequence ----\n",
    "        seq_embed = self.seq_encoder(sequences)          # [B, Lseq, 1152]\n",
    "        B, Lseq, _ = seq_embed.shape\n",
    "        _, Lstr, D = struct_embed.shape                  # D = 512\n",
    "    \n",
    "        # ---- masks ----\n",
    "        seq_mask = non_padding_mask(seq_embed, self.padding_value)      # True = real\n",
    "        struct_mask = non_padding_mask(struct_embed, self.padding_value)  # True = real\n",
    "    \n",
    "        # enforce residue alignment\n",
    "        assert (\n",
    "            seq_mask.sum(dim=1).cpu().tolist()\n",
    "            == struct_mask.sum(dim=1).cpu().tolist()\n",
    "        ), \"Sequence and structure residue counts do not match\"\n",
    "    \n",
    "        # ---- project seq + pad to structure length ----\n",
    "        seq_embed_proj = torch.full(\n",
    "            (B, Lstr, D),\n",
    "            self.padding_value,\n",
    "            device=seq_embed.device,\n",
    "            dtype=seq_embed.dtype,\n",
    "        )\n",
    "    \n",
    "        for i in range(B):\n",
    "            real_seq = seq_embed[i][seq_mask[i]]     # [Li, 1152]\n",
    "            proj = self.seq_down(real_seq)            # [Li, 512]\n",
    "            seq_embed_proj[i, :proj.size(0)] = proj   # align positions\n",
    "    \n",
    "        seq_pooled = create_mean_of_non_masked(seq_embed_proj, create_key_padding_mask(seq_embed_proj))\n",
    "        struct_pooled = create_mean_of_non_masked(struct_embed, create_key_padding_mask(struct_embed))\n",
    "    \n",
    "        seq_full = F.normalize(seq_pooled, dim=-1)\n",
    "        struct_full = F.normalize(struct_pooled, dim=-1)\n",
    "    \n",
    "        scale = torch.exp(self.logit_scale).clamp(max=100)\n",
    "        logits_seq = scale * (seq_full @ struct_full.T)\n",
    "        logits_struct = scale * (struct_full @ seq_full.T)\n",
    "    \n",
    "        return logits_seq, logits_struct, seq_embed_proj, struct_embed, struct_mask\n",
    "\n",
    "    def training_step(self, batch, device):\n",
    "    \n",
    "        sequences, struct_embed, _ = batch\n",
    "        struct_embed = struct_embed.to(device)\n",
    "    \n",
    "        logits_seq, logits_struct, seq_embed_proj, struct_embed, struct_mask = self.forward(sequences, struct_embed)\n",
    "    \n",
    "        # ---- CLIP loss ----\n",
    "        B = logits_seq.size(0)\n",
    "        labels = torch.arange(B, device=device)\n",
    "    \n",
    "        loss_seq = F.cross_entropy(logits_seq, labels)\n",
    "        loss_struct = F.cross_entropy(logits_struct, labels)\n",
    "        clip_loss = 0.5 * (loss_seq + loss_struct)\n",
    "    \n",
    "        # ---- token-level cosine loss (aligned positions) ----\n",
    "        cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Lstr]\n",
    "        cos = cos * struct_mask.float()                                   # mask padding\n",
    "    \n",
    "        per_token_loss = 1.0 - (cos.sum(dim=1) / struct_mask.sum(dim=1)).mean()\n",
    "    \n",
    "        return clip_loss + per_token_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "222872f2-2d38-481f-9427-98816146bd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model = CSSPBoostingESM(\n",
    "#     seq_embed_dim=1152,\n",
    "#     struct_embed_dim=512,\n",
    "#     padding_value=-5000,\n",
    "# ).to(device)\n",
    "\n",
    "# # model\n",
    "\n",
    "# runID = uuid.uuid4()\n",
    "# learning_rate = 2e-5\n",
    "# EPOCHS = 50\n",
    "# batch_size = 10\n",
    "# model = CSSPBoostingESM(seq_embed_dim=1152, struct_embed_dim=512).to(\"cuda\")\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "# # seq_down_params = set(model.seq_down.parameters())\n",
    "# # other_params = [p for p in model.parameters() if p not in seq_down_params]\n",
    "# # optimizer = torch.optim.AdamW([\n",
    "# #     {\"params\": other_params, \"lr\": learning_rate},\n",
    "# #     {\"params\": model.seq_down.parameters(),\"lr\": 2e-5},\n",
    "# # ])\n",
    "\n",
    "# accelerator = Accelerator()\n",
    "# device = accelerator.device\n",
    "\n",
    "# train_dataloader = DataLoader(train_Dataset, batch_size=10, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_Dataset, batch_size=10, shuffle=False)\n",
    "# val_dataloader = DataLoader(meta_Dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9072c55-5d54-4a1e-9e63-d11d04e0c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s232958/envs/esm_cuda/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logit_scale', 'seq_encoder.model.base_model.model.embeddings.word_embeddings.weight', 'seq_encoder.model.base_model.model.embeddings.position_embeddings.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.rotary_embeddings.inv_freq']\n",
      "['logit_scale', 'seq_encoder.model.base_model.model.embeddings.word_embeddings.weight', 'seq_encoder.model.base_model.model.embeddings.position_embeddings.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.query.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.key.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.weight', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.value.bias', 'seq_encoder.model.base_model.model.encoder.layer.0.attention.self.rotary_embeddings.inv_freq']\n"
     ]
    }
   ],
   "source": [
    "runID = uuid.uuid4()\n",
    "learning_rate = 2e-5\n",
    "EPOCHS = 200\n",
    "batch_size = 10\n",
    "# model = CSSPBoostingESM(seq_embed_dim=1152, struct_embed_dim=512).to(\"cuda\")\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "### Loading model pre-tarined for 50 epochs\n",
    "model_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_combinedLoss02/fd002c98-cf05-4f5a-8684-af9cc03cf6dc/model_cos-sim0.2.pt\"\n",
    "model_checkpoint_dict = torch.load(model_checkpoint_path, map_location=\"cuda\")\n",
    "\n",
    "model = CSSPBoostingESM(\n",
    "    seq_embed_dim=1152,\n",
    "    struct_embed_dim=512,\n",
    "    padding_value=-5000,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(model_checkpoint_dict)\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "accelerator = Accelerator()\n",
    "\n",
    "print(list(model_checkpoint_dict.keys())[:10])\n",
    "print(list(model.state_dict().keys())[:10])\n",
    "\n",
    "train_dataloader = DataLoader(train_Dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_Dataset, batch_size=10, shuffle=False)\n",
    "val_dataloader = DataLoader(meta_Dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22daa948-10c0-484a-8b8b-c2cf14a9d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- token-lvl cos-siminilarity\n",
    "- train seq_down for 5 epochs and then freeze all parameters\n",
    "- train in total for 50 epochs, save model every 5 epochs and plot progress in W&B\n",
    "\"\"\"\n",
    "\n",
    "class TrainWrapper():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=model,\n",
    "        train_loader=train_dataloader,\n",
    "        test_loader=test_dataloader,\n",
    "        val_loader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        epochs=EPOCHS,\n",
    "        device=device,\n",
    "        wandb_tracker=False,\n",
    "        save_at = []\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.training_loader = train_loader\n",
    "        self.testing_loader = test_loader\n",
    "        self.validation_loader = val_loader\n",
    "        self.EPOCHS = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.wandb_tracker = wandb_tracker\n",
    "        self.save_at = set(save_at)\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "\n",
    "        self.model.train()\n",
    "        self.model.seq_encoder.train()\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        for batch in tqdm(self.training_loader, total=len(self.training_loader), desc=\"Running through epoch\"):\n",
    "\n",
    "            sequences, struct_embed, labels = batch\n",
    "            struct_embed = struct_embed.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.model.training_step((sequences, struct_embed, labels), self.device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        return running_loss / len(self.training_loader)\n",
    "    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_embeddings_cos_similariy(self, loader=None, loader_name=\"test\"):\n",
    "    \n",
    "        if loader is None:\n",
    "            loader = self.testing_loader\n",
    "    \n",
    "        self.model.eval()\n",
    "        self.model.seq_encoder.eval()\n",
    "    \n",
    "        all_embeds = []\n",
    "        cosine_similarities = []\n",
    "    \n",
    "        for batch in tqdm(loader, desc=f\"Computing cosine similarity & embeddings ({loader_name})\"):\n",
    "    \n",
    "            seqs, struct_embed, _ = batch\n",
    "            struct_embed = struct_embed.to(self.device)      # [B, Ls, 512]\n",
    "    \n",
    "            # ---- sequence embeddings ----\n",
    "            seq_embed = self.model.seq_encoder(seqs)         # [B, Lq, 1152]\n",
    "            B, Lq, _ = seq_embed.shape\n",
    "            _, Ls, Ds = struct_embed.shape\n",
    "    \n",
    "            seq_mask = non_padding_mask(seq_embed, self.model.padding_value)   # [B, Lq]\n",
    "            str_mask = non_padding_mask(struct_embed, self.model.padding_value)  # [B, Ls]\n",
    "    \n",
    "            # enforce residue-wise alignment\n",
    "            assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "    \n",
    "            # ---- project seq tokens + pad to structure length ----\n",
    "            seq_embed_proj = torch.full((B, Ls, Ds), self.model.padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "            for i in range(B):\n",
    "                real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1152]\n",
    "                proj = self.model.seq_down(real_seq)      # [Li, 512]\n",
    "                seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "    \n",
    "            # ---- token-level cosine similarity (aligned positions) ----\n",
    "            cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "            cos = cos * str_mask.float()   # mask padding\n",
    "    \n",
    "            per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "            cosine_similarities.extend(per_seq_cos.cpu().tolist())\n",
    "    \n",
    "            # ---- pooled sequence embeddings (projected space) ----\n",
    "            seq_pooled = create_mean_of_non_masked(seq_embed_proj, create_key_padding_mask(seq_embed_proj))\n",
    "            seq_full = F.normalize(seq_pooled, dim=-1)\n",
    "            all_embeds.append(seq_full.cpu())\n",
    "    \n",
    "        all_embeds = torch.cat(all_embeds, dim=0)\n",
    "    \n",
    "        avg_cos = float(np.mean(cosine_similarities))\n",
    "        std_cos = float(np.std(cosine_similarities))\n",
    "    \n",
    "        return all_embeds, cosine_similarities, avg_cos, std_cos\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval_train_loss(self):\n",
    "        self.model.eval()\n",
    "        running = 0.0\n",
    "        for sequences, struct_embed, labels in tqdm(self.training_loader, total=len(self.training_loader), desc=f\"Computing Training Loss before training\"):\n",
    "            struct_embed = struct_embed.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            loss = self.model.training_step((sequences, struct_embed, labels), self.device)\n",
    "            running += loss.item()\n",
    "        return running / len(self.training_loader)\n",
    "\n",
    "    def plot_embeddings_drift_cos_similarity_change(self, start_embeddings, end_embeddings, cosine_similarities):\n",
    "\n",
    "        drift = (end_embeddings - start_embeddings).norm(dim=1).cpu().numpy()\n",
    "        cosine_similarities = np.array(cosine_similarities)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "        ax[0].hist(drift, bins=30, color=\"steelblue\", alpha=0.8)\n",
    "        ax[0].set_title(\"Embedding Drift per Sequence\", fontsize=8)\n",
    "        ax[0].set_xlabel(\"L2 Norm Drift\", fontsize=8)\n",
    "        ax[0].set_ylabel(\"Density\", fontsize=8)\n",
    "\n",
    "        ax[1].hist(cosine_similarities, bins=40, color=\"darkorange\", alpha=0.7, density=True)\n",
    "        ax[1].set_title(\"Cosine Similarities (ESM-2 vs ESM-IF)\", fontsize=8)\n",
    "        ax[1].set_xlabel(\"Cosine Similarity\", fontsize=8)\n",
    "        ax[1].set_ylabel(\"Density\", fontsize=8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def train_model(self, save_every: int = 5):\n",
    "    \n",
    "        # run_dir = f\"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/{runID}/\"\n",
    "        run_dir = f\"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/fd002c98-cf05-4f5a-8684-af9cc03cf6dc/\"\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "    \n",
    "        print(\"\\nTrainable parameters inside seq_encoder (LoRA layers):\")\n",
    "        for name, p in self.model.seq_encoder.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                print(\"  \", name)\n",
    "    \n",
    "        # ---- Save checkpoint BEFORE training (epoch 0) ----\n",
    "        # save_path_encoder = os.path.join(run_dir, \"seq_encoder_before_training.pt\")\n",
    "        # save_path_projhead = os.path.join(run_dir, \"seq_down_before_training.pt\")\n",
    "        # torch.save(self.model.seq_encoder.state_dict(), save_path_encoder)\n",
    "        # torch.save(self.model.seq_down.state_dict(), save_path_projhead)\n",
    "        # print(f\"Saved seq_encoder checkpoint before training -> {save_path_encoder}\")\n",
    "        # print(f\"Saved proj head checkpoint before training -> {save_path_projhead}\")\n",
    "    \n",
    "        # ---- START embeddings/cos-sim for both loaders ----\n",
    "        # print(\"Computing Loss before training:\")\n",
    "        # train_loss = self.eval_train_loss()\n",
    "        # print(f\"[TRAIN] Loss {train_loss}\")\n",
    "        \n",
    "        print(\"\\nExtracting START embeddings & cosine similarities (val + test)...\")\n",
    "        start_val_emb, start_val_cos, start_val_avg, start_val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "        print(f\"[VAL]  avg cos: {start_val_avg:.4f}, std: {start_val_std:.4f}\")\n",
    "        self.plot_embeddings_drift_cos_similarity_change(start_val_emb, start_val_emb, start_val_cos)\n",
    "    \n",
    "        start_test_emb, start_test_cos, start_test_avg, start_test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "        print(f\"[TEST] avg cos: {start_test_avg:.4f}, std: {start_test_std:.4f}\")\n",
    "        # self.plot_embeddings_drift_cos_similarity_change(start_test_emb, start_test_emb, start_test_cos)\n",
    "\n",
    "        if self.wandb_tracker:\n",
    "            self.wandb_tracker.log({\n",
    "                \"train/loss\": train_loss,\n",
    "                \"val/cos_avg\": start_val_avg,\n",
    "                \"val/cos_std\": start_val_std,\n",
    "                \"test/cos_avg\": start_test_avg,\n",
    "                \"test/cos_std\": start_test_std,\n",
    "            }, step=0)\n",
    "    \n",
    "        for epoch in range(1, self.EPOCHS + 1):\n",
    "        \n",
    "            # if epoch == 5:\n",
    "            if epoch == 1: # training for longer\n",
    "                print(f\"\\nFreezing projection head (seq_down) after {epoch-1} epoch(s), continuing training of the rest...\")\n",
    "                for p in self.model.seq_down.parameters():\n",
    "                    p.requires_grad = False\n",
    "                self.optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "            train_loss = self.train_one_epoch()\n",
    "            print(f\"Epoch {epoch}: loss={train_loss:.4f}\")\n",
    "    \n",
    "            # Optional: monitor cos-sim each epoch (val + test)\n",
    "            val_emb, val_cos, val_avg, val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "            print(f\"[VAL]  avg cos: {val_avg:.4f}, std: {val_std:.4f}\")\n",
    "    \n",
    "            test_emb, test_cos, test_avg, test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "            print(f\"[TEST] avg cos: {test_avg:.4f}, std: {test_std:.4f}\")\n",
    "    \n",
    "            # ---- Save every `save_every` epochs ----\n",
    "            value = round(val_avg, 2)\n",
    "            if value in self.save_at:\n",
    "                save_path_encoder = os.path.join(run_dir, f\"seq_encoder_cos-sim{value}.pt\")\n",
    "                save_path_projhead = os.path.join(run_dir, f\"seq_down_cos-sim{value}.pt\")\n",
    "                save_path_model = os.path.join(run_dir, f\"model_cos-sim{value}.pt\")\n",
    "                torch.save(self.model.state_dict(), save_path_model)\n",
    "                torch.save(self.model.seq_encoder.state_dict(), save_path_encoder)\n",
    "                torch.save(self.model.seq_down.state_dict(), save_path_projhead)\n",
    "                print(f\"Saved whole model checkpoint -> {save_path_model}\")\n",
    "                print(f\"Saved seq_encoder checkpoint -> {save_path_encoder}\")\n",
    "                print(f\"Saved proj head checkpoint -> {save_path_projhead}\")\n",
    "                self.save_at.remove(value)\n",
    "                self.plot_embeddings_drift_cos_similarity_change(start_val_emb, val_emb, val_cos)\n",
    "\n",
    "            # elif epoch < 5:\n",
    "            #     save_path_encoder = os.path.join(run_dir, f\"seq_encoder_{epoch}.pt\")\n",
    "            #     save_path_projhead = os.path.join(run_dir, f\"seq_down_{epoch}.pt\")\n",
    "            #     torch.save(self.model.seq_encoder.state_dict(), save_path_encoder)\n",
    "            #     torch.save(self.model.seq_down.state_dict(), save_path_projhead)\n",
    "            #     print(f\"Saved seq_encoder checkpoint -> {save_path_encoder}\")\n",
    "            #     print(f\"Saved proj head checkpoint -> {save_path_projhead}\")\n",
    "            #     self.plot_embeddings_drift_cos_similarity_change(start_val_emb, val_emb, val_cos)\n",
    "\n",
    "            if self.wandb_tracker:\n",
    "                self.wandb_tracker.log({\n",
    "                    \"train/loss\": train_loss,\n",
    "                    \"val/cos_avg\": val_avg,\n",
    "                    \"val/cos_std\": val_std,\n",
    "                    \"test/cos_avg\": test_avg,\n",
    "                    \"test/cos_std\": test_std,\n",
    "                }, step=epoch)\n",
    "    \n",
    "        # ---- END embeddings/cos-sim for both loaders ----\n",
    "        print(\"\\nExtracting END embeddings & cosine similarities (val + test)...\")\n",
    "        end_val_emb, end_val_cos, val_avg, val_std = self.compute_embeddings_cos_similariy(loader=self.validation_loader, loader_name=\"val\")\n",
    "        print(f\"[VAL]  avg cos: {val_avg:.4f}, std: {val_std:.4f}\")\n",
    "        self.plot_embeddings_drift_cos_similarity_change(start_val_emb, end_val_emb, end_val_cos)\n",
    "\n",
    "        end_test_emb, end_test_cos, test_avg, test_std = self.compute_embeddings_cos_similariy(loader=self.testing_loader, loader_name=\"test\")\n",
    "        print(f\"[TEST] avg cos: {test_avg:.4f}, std: {test_std:.4f}\")\n",
    "    \n",
    "        # Return test triplet like your original expectation:\n",
    "        return (start_val_emb, end_val_emb, end_test_cos), (start_test_emb, end_test_emb, end_test_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34b248-273c-40b5-9bf8-6dff944745b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">freeze_projhead_after_epoch4_ed0cc239-ce89-424a-b700-9f1984f595d6</strong> at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_C_w_ESM_IF_02/runs/qn0yhop4' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_C_w_ESM_IF_02/runs/qn0yhop4</a><br> View project at: <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_C_w_ESM_IF_02' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_C_w_ESM_IF_02</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_181335-qn0yhop4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/zhome/c9/0/203261/DBL046_PP_osaul/DBL046_PP_osaul/tmp/ona_drafts/wandb/run-20260120_181547-duzlx7vo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_C_w_ESM_IF_02/runs/duzlx7vo' target=\"_blank\">freeze_projhead_after_epoch4_ed0cc239-ce89-424a-b700-9f1984f595d6</a></strong> to <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_C_w_ESM_IF_02' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_C_w_ESM_IF_02' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_C_w_ESM_IF_02</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_C_w_ESM_IF_02/runs/duzlx7vo' target=\"_blank\">https://wandb.ai/s232958-danmarks-tekniske-universitet-dtu/Boosting_ESM_C_w_ESM_IF_02/runs/duzlx7vo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters inside seq_encoder (LoRA layers):\n",
      "   model.base_model.model.encoder.layer.25.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.25.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.25.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.26.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.26.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.27.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.27.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.28.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.28.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.29.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.29.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.30.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.30.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.31.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.31.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.query.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.query.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.key.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.key.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.value.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.self.value.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.attention.output.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.intermediate.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.intermediate.dense.lora_B.default.weight\n",
      "   model.base_model.model.encoder.layer.32.output.dense.lora_A.default.weight\n",
      "   model.base_model.model.encoder.layer.32.output.dense.lora_B.default.weight\n",
      "\n",
      "Extracting START embeddings & cosine similarities (val + test)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.1954, std: 0.0247\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1605, std: 0.0361\n",
      "\n",
      "Freezing projection head (seq_down) after 0 epoch(s), continuing training of the rest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:40<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=1.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.1968, std: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1618, std: 0.0363\n",
      "Saved whole model checkpoint -> /work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/fd002c98-cf05-4f5a-8684-af9cc03cf6dc/model_cos-sim0.2.pt\n",
      "Saved seq_encoder checkpoint -> /work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/fd002c98-cf05-4f5a-8684-af9cc03cf6dc/seq_encoder_cos-sim0.2.pt\n",
      "Saved proj head checkpoint -> /work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/fd002c98-cf05-4f5a-8684-af9cc03cf6dc/seq_down_cos-sim0.2.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=1.2311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.1980, std: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1630, std: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss=1.2206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.1995, std: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1643, std: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:48<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: loss=1.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:18<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2007, std: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:55<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1656, std: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:44<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: loss=1.1932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2017, std: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1668, std: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: loss=1.1922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2031, std: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1682, std: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: loss=1.1765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2045, std: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1696, std: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: loss=1.1743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2055, std: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1707, std: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: loss=1.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2065, std: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1720, std: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:44<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: loss=1.1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:18<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2077, std: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:55<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1732, std: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:46<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: loss=1.1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2092, std: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1744, std: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: loss=1.1392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2103, std: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1757, std: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: loss=1.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2116, std: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1769, std: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:47<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: loss=1.1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:16<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2127, std: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1781, std: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: loss=1.1188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2140, std: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:54<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1794, std: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:46<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: loss=1.1167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2152, std: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:54<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1805, std: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:47<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: loss=1.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2163, std: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:55<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1816, std: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:44<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: loss=1.0957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2174, std: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1829, std: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:48<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: loss=1.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2185, std: 0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:55<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1841, std: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:44<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: loss=1.0827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2205, std: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:54<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1854, std: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:43<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: loss=1.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2212, std: 0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:59<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1866, std: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [05:05<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: loss=1.0697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2228, std: 0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1878, std: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:49<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: loss=1.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2241, std: 0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1891, std: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:51<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: loss=1.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2252, std: 0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:08<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1904, std: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [05:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: loss=1.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2268, std: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1915, std: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:51<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: loss=1.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:20<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2287, std: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:05<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1929, std: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:35<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: loss=1.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:16<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2300, std: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1941, std: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:33<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: loss=1.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:16<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2311, std: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1953, std: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:39<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: loss=1.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2325, std: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1963, std: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: loss=1.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2339, std: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1976, std: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:41<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: loss=1.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:29<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2350, std: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [01:29<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1987, std: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [06:53<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: loss=1.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2364, std: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.1998, std: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: loss=1.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2375, std: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2011, std: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:35<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: loss=1.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2392, std: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2024, std: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: loss=0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2404, std: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2037, std: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:35<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: loss=1.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2418, std: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2049, std: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:38<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: loss=0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2435, std: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2062, std: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: loss=0.9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2443, std: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2071, std: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: loss=0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2457, std: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2084, std: 0.0372\n",
      "Saved whole model checkpoint -> /work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/fd002c98-cf05-4f5a-8684-af9cc03cf6dc/model_cos-sim0.25.pt\n",
      "Saved seq_encoder checkpoint -> /work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/fd002c98-cf05-4f5a-8684-af9cc03cf6dc/seq_encoder_cos-sim0.25.pt\n",
      "Saved proj head checkpoint -> /work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint/fd002c98-cf05-4f5a-8684-af9cc03cf6dc/seq_down_cos-sim0.25.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: loss=0.9715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2473, std: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2096, std: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:35<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: loss=0.9693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2488, std: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2108, std: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: loss=0.9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2498, std: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2120, std: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: loss=0.9666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2514, std: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2132, std: 0.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:35<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: loss=0.9479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2525, std: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2143, std: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: loss=0.9439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2539, std: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2156, std: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: loss=0.9418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2557, std: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:53<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2171, std: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: loss=0.9386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2574, std: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2183, std: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: loss=0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2588, std: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2196, std: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: loss=0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:16<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2598, std: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2209, std: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:35<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: loss=0.9278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:17<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2614, std: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2222, std: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: loss=0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:16<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2624, std: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2232, std: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: loss=0.9176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:16<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2644, std: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2246, std: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:34<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: loss=0.9170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:16<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2657, std: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2260, std: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:43<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: loss=0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:16<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2670, std: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2269, std: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch: 100%|██████████████████████████████████████████████████████████| 395/395 [04:36<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: loss=0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (val): 100%|███████████████████████████████████| 99/99 [00:16<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  avg cos: 0.2689, std: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing cosine similarity & embeddings (test): 100%|██████████████████████████████████| 99/99 [00:52<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] avg cos: 0.2284, std: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through epoch:  16%|█████████▌                                                 | 64/395 [00:44<03:56,  1.40it/s]"
     ]
    }
   ],
   "source": [
    "### wandb\n",
    "if use_wandb:\n",
    "    run = wandb.init(\n",
    "        project=\"Boosting_ESM_C_w_ESM_IF_02\",\n",
    "        name=f\"freeze_projhead_after_epoch4_{runID}\",\n",
    "        config={\"learning_rate\": learning_rate, \n",
    "                \"batch_size\": batch_size, \n",
    "                \"epochs\": EPOCHS,\n",
    "                \"architecture\": \"MiniCLIP_w_transformer_crossattn\", \n",
    "                \"dataset\": \n",
    "                \"PPint\"},\n",
    "    )\n",
    "    wandb.watch(accelerator.unwrap_model(model), log=\"all\", log_freq=100)\n",
    "else:\n",
    "    run = None\n",
    "\n",
    "# accelerator\n",
    "model, optimizer, train_dataloader, test_dataloader, val_dataloader = accelerator.prepare(model, optimizer, train_dataloader, test_dataloader, val_dataloader)\n",
    "\n",
    "training_wrapper = TrainWrapper(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    test_loader=test_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=EPOCHS,\n",
    "    device=device,\n",
    "    # wandb_tracker=wandb,\n",
    "    wandb_tracker=False,\n",
    "    save_at = [0.05, 0.10, 0.15, 0.20, 0.25, 0.35, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.00]\n",
    ")\n",
    "\n",
    "val_params, test_params = training_wrapper.train_model(save_every=[5, 10, 25, 50, 60, 70, 80, 90, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5a908-af2d-4029-8319-9fb40f8d5f0d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc18de4-01c3-4749-b67d-b5dff72cc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(\"/work3/s232958/data/meta_analysis/interaction_df_metaanal_w_pbd_lens.csv\").drop(columns = [\"binder_id\", \"target_id\"]).rename(columns = {\n",
    "    \"target_id_mod\" : \"target_id\",\n",
    "    \"target_binder_ID\" : \"binder_id\",\n",
    "})\n",
    "\n",
    "meta_df[\"target_id_mod\"] = [str(\"t_\"+row.target_id) for __, row in meta_df.iterrows()]\n",
    "\n",
    "# Interaction Dict\n",
    "meta_df_shuffled = meta_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "meta_df_shuffled_LONG_binder = meta_df_shuffled[[\"binder_id\", \"binder_seq\", \"seq_len_binder\"]].rename(columns = {\n",
    "    \"binder_id\" : \"ID\",\n",
    "    \"binder_seq\" : \"sequence\",\n",
    "    \"seq_len_binder\": \"seq_len\",\n",
    "})\n",
    "\n",
    "meta_df_shuffled_LONG_taget = meta_df_shuffled[[\"target_id_mod\", \"target_seq\", \"seq_len_target\"]].rename(columns = {\n",
    "    \"target_id_mod\" : \"ID\",\n",
    "    \"target_seq\" : \"sequence\",\n",
    "    \"seq_len_target\": \"seq_len\",\n",
    "}).drop_duplicates(subset=\"ID\", keep=\"first\")\n",
    "\n",
    "meta_df_shuffled_LONG = pd.concat([meta_df_shuffled_LONG_binder, meta_df_shuffled_LONG_taget], axis=0, ignore_index=True)\n",
    "meta_df_shuffled_LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f71035-c096-4bcb-ba16-b8eb70424ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESM2EncoderLoRA(nn.Module):\n",
    "    def __init__(self, padding_value=-5000.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "        self.model = EsmModel.from_pretrained(\n",
    "            \"facebook/esm2_t33_650M_UR50D\",\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n",
    "        # Freeze original weights\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # LoRA on top layers\n",
    "        lora_cfg = LoraConfig(\n",
    "            task_type=\"FEATURE_EXTRACTION\",\n",
    "            inference_mode=False,\n",
    "            r=4,\n",
    "            lora_alpha=1,\n",
    "            lora_dropout=0.1,\n",
    "            bias=\"none\",\n",
    "            # target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "            layers_to_transform=list(range(25, 33)),\n",
    "        )\n",
    "\n",
    "        self.model = get_peft_model(self.model, lora_cfg)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attentions(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs, output_attentions=True)\n",
    "        return out.attentions   # list[num_layers] → [B, num_heads, L, L]\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        inputs = self.tokenizer(\n",
    "            sequences, return_tensors=\"pt\", padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        out = self.model(**inputs)\n",
    "        reps = out.hidden_states[-1]                  # [B, Ltok, 1152]\n",
    "        reps = reps[:, 1:-1, :]                       # remove CLS/EOS\n",
    "\n",
    "        seq_lengths = [len(s) for s in sequences]\n",
    "        Lmax = max(seq_lengths)\n",
    "\n",
    "        B, D = reps.size(0), reps.size(-1)\n",
    "        padded = torch.full((B, Lmax, D), self.padding_value, device=reps.device)\n",
    "\n",
    "        for i, (r, real_len) in enumerate(zip(reps, seq_lengths)):\n",
    "            padded[i, :real_len] = r[:real_len]\n",
    "\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500eb040-da96-416e-9dba-6bf91914e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIP_PPint_w_esmIF(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dframe,\n",
    "        paths,\n",
    "        embedding_dim_struct=512,\n",
    "        embedding_dim_seq=1152,\n",
    "        embedding_pad_value=-5000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dframe = dframe.copy()\n",
    "        self.embedding_dim_seq = embedding_dim_seq\n",
    "        self.embedding_dim_struct = embedding_dim_struct\n",
    "        self.emb_pad = embedding_pad_value\n",
    "\n",
    "        # lengths\n",
    "        self.seq_len = self.dframe[\"seq_len\"].max()\n",
    "\n",
    "        # index & storage\n",
    "        self.dframe.set_index(\"ID\", inplace=True)\n",
    "        self.accessions = self.dframe.index.astype(str).tolist()\n",
    "        self.name_to_row = {name: i for i, name in enumerate(self.accessions)}\n",
    "        self.samples = []\n",
    "\n",
    "        for accession in tqdm(self.accessions, total=len(self.accessions), desc=\"#Loading ESM2 embeddings and contacts\"):\n",
    "\n",
    "            # laod embeddings\n",
    "            if accession.startswith(\"t_\"):\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_targets\"\n",
    "                esm2_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_targets\"\n",
    "               \n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession[2:]}.npy\"))[1:-1, :]\n",
    "                emb_seq = np.load(os.path.join(esm2_path, f\"{accession[2:]}.npy\"))[1:-1, :]\n",
    "                sequence = str(self.dframe.loc[accession].sequence)\n",
    "\n",
    "                assert (emb_struct.shape[0]== emb_seq.shape[0] == len(sequence))\n",
    "\n",
    "            else:\n",
    "                esmIF_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "                esm2_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_binders\"\n",
    "\n",
    "                emb_struct = np.load(os.path.join(esmIF_path, f\"{accession}.npy\"))[1:-1, :]\n",
    "                emb_seq = np.load(os.path.join(esm2_path, f\"{accession}.npy\"))[1:-1, :] \n",
    "                sequence = str(self.dframe.loc[accession].sequence)\n",
    "\n",
    "                # print(emb_struct.shape, emb_seq.shape)\n",
    "                assert (emb_struct.shape[0]== emb_seq.shape[0] == len(sequence))\n",
    "\n",
    "            # quich check whether embedding dimmension is as it suppose to be\n",
    "            if emb_seq.shape[1] != self.embedding_dim_seq:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim_seq'.\")\n",
    "            if emb_struct.shape[1] != self.embedding_dim_struct:\n",
    "                raise ValueError(\"Embedding dim mismatch with 'embedding_dim'.\")\n",
    "                \n",
    "            # add -5000 to all the padded target rows\n",
    "            if emb_seq.shape[0] < self.seq_len:\n",
    "                emb_seq = np.concatenate([emb_seq, np.full((self.seq_len - emb_seq.shape[0], emb_seq.shape[1]), self.emb_pad, dtype=emb_seq.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_seq = emb_seq[: self.seq_len] # no padding was usedd\n",
    "\n",
    "            if emb_struct.shape[0] < self.seq_len:\n",
    "                emb_struct = np.concatenate([emb_struct, np.full((self.seq_len - emb_struct.shape[0], emb_struct.shape[1]), self.emb_pad, dtype=emb_struct.dtype)], axis=0)\n",
    "            else:\n",
    "                emb_struct = emb_struct[: self.seq_len] # no padding was used\n",
    "\n",
    "            self.samples.append((emb_seq, sequence, emb_struct))\n",
    "\n",
    "    # ---- Dataset API ----\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb_seq, seq, emb_struct = self.samples[idx]\n",
    "        emb_seq, emb_struct = torch.from_numpy(emb_seq).float(), torch.from_numpy(emb_struct).float()\n",
    "        # label = torch.tensor(1, dtype=torch.float32)  # single scalar labe\n",
    "        return emb_seq, seq, emb_struct\n",
    "\n",
    "    def _get_by_name(self, name):\n",
    "        # Single item -> return exactly what __getitem__ returns\n",
    "        if isinstance(name, str):\n",
    "            return self.__getitem__(self.name_to_row[name])\n",
    "        \n",
    "        # Multiple items -> fetch all\n",
    "        out = [self.__getitem__(self.name_to_row[n]) for n in list(name)]\n",
    "        # emb_seq_list, emb_struct_list, label_list = zip(*out)\n",
    "        emb_seq_list, seqs_list, emb_struct_list = zip(*out)\n",
    "    \n",
    "        # Stack embeddings\n",
    "        emb_seq_stacked  = torch.stack([torch.as_tensor(x) for x in emb_seq_list],  dim=0)  # [B, ...]        \n",
    "        emb_struct_stacked  = torch.stack([torch.as_tensor(x) for x in emb_struct_list],  dim=0)  # [B, ...]\n",
    "    \n",
    "        # Stack labels\n",
    "        # labels = torch.stack(lbl_list)  # [B]\n",
    "    \n",
    "        return emb_seq_stacked, seqs_list, emb_struct_stacked\n",
    "\n",
    "emb_seq_path = \"/work3/s232958/data/meta_analysis/embeddings_esm2_binders\"\n",
    "emb_struct_path = \"/work3/s232958/data/meta_analysis/esmif_embeddings_binders\"\n",
    "\n",
    "meta_Dataset = CLIP_PPint_w_esmIF(\n",
    "    meta_df_shuffled_LONG,\n",
    "    paths=[emb_seq_path, emb_struct_path],\n",
    "    embedding_dim_seq=1152,\n",
    "    embedding_dim_struct=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21333b2d-5dd8-4455-bf85-7329f1310f3e",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44f545-4476-4782-b9e9-747a8ba862da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "### Training seq_down for 1 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_1.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_1.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1152, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca76ebd-44d4-4e39-bd14-a703cd47e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading original embeddings and RANDOM projection head\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "original_embeds_random_head = []\n",
    "seq_proj = nn.Linear(1152, 512).to(\"cuda\")\n",
    "padding_value = -5000.0\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    seq_embed, seqs_list, struct_embed = batch\n",
    "    seq_embed, struct_embed = seq_embed.to(device), struct_embed.to(device)\n",
    "\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1152]\n",
    "        # proj = model.seq_down(real_seq)      # [Li, 512]\n",
    "        proj = seq_proj(real_seq)\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    original_embeds_random_head.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac15e2cd-2621-4248-98b0-7beb08476767",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(original_embeds_random_head, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similarities original ESM-2 embeddings/random proj_head vs ESM-IF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c415d-b9f6-4563-9a13-787ea1de5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading original embeddings and PRE-TRAINED projection head\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "original_embeds_pretrained_head_ep1 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    seq_embed, seqs_list, struct_embed = batch\n",
    "    seq_embed, struct_embed = seq_embed.to(device), struct_embed.to(device)\n",
    "\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1152]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        # proj = seq_proj(real_seq)\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    original_embeds_pretrained_head_ep1.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8439dfe-3a2c-464a-b87d-710dd1278bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(original_embeds_pretrained_head_ep1, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similarities original ESM-2 embeddings/pre-trained proj_head vs ESM-IF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e3647-8445-483e-af10-7c43815e33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep1 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1152]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep1.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16756c20-95b2-4565-90ee-6378ed095457",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep1, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 1)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c027063-6b79-44d1-ac3b-bdae006bb2a4",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d98b2c-b10e-4607-a3fd-be6453bd14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 5 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_5.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_5.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1152, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc13145-22b7-4b18-8ad1-4f6be4cfcf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep5 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1152]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep5.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff680f-896c-4178-9f14-d0cc0a850fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep5, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 5)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cba68a-9235-4af0-86c8-48eaeedc4bea",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c24e93-bf66-4c0a-a8ce-a503268e82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 25 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_25.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_25.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1152, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a2db4-0a97-4186-a5b9-b870fac86a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep25 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1152]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep25.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03f5154-74ac-4016-9a4b-9306e6b49cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep25, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 25)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d435f0c-890c-4355-8013-5837d35b347b",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d6682-82a4-483f-a891-98e8c126a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 50 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_50.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "# seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_5.pt\"\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_50.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1152, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0b655-da3e-49b1-8096-dade7ed5f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep50 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1152]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep50.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7151f-33fa-469a-8300-3c83c286ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep50, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head(seq_down_5) vs ESM-IF (after epoch 50)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f1443-63e7-42a4-a71a-5acfbf7bf0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep50, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head(seq_down_50) vs ESM-IF (after epoch 50)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf7efb-333f-4ab6-9876-80ae00d0b3fc",
   "metadata": {},
   "source": [
    "#### Checkpoint after epoch 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15679cbc-101c-4486-a2e0-9f7fb2801604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Training seq_down for 60 epoch \n",
    "# seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_encoder_60.pt\"\n",
    "# seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "# seq_encoder = ESM2EncoderLoRA()\n",
    "# seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "# seq_encoder.to(device)\n",
    "# seq_encoder.eval()\n",
    "\n",
    "# seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/4334cb1c-12f0-4fa2-982c-da9f78779bee/seq_down_25.pt\"\n",
    "# seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "# seq_down = nn.Linear(1152, 512)\n",
    "# seq_down.load_state_dict(seq_down_state_dict)\n",
    "# seq_down.to(device)\n",
    "# # seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c371f-26a9-4549-8917-9984af60741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "# _loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "# pretrained_encoder_head_ep60 = []\n",
    "\n",
    "# for batch in tqdm(_loader):\n",
    "#     ___, seqs_list, struct_embed = batch\n",
    "#     struct_embed = struct_embed.to(device)\n",
    "\n",
    "#     seq_embed = seq_encoder(seqs_list)\n",
    "#     B, Lq, _ = seq_embed.shape\n",
    "#     _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "#     seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "#     str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "#     # enforce residue-wise alignment\n",
    "#     # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "#     # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "#     assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "#     # ---- project seq tokens + pad to structure length ----\n",
    "#     seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "#     for i in range(B):\n",
    "#         real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1152]\n",
    "#         proj = seq_down(real_seq)      # [Li, 512]\n",
    "#         seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "#     # ---- token-level cosine similarity (aligned positions) ----\n",
    "#     cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "#     cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "#     per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "#     pretrained_encoder_head_ep60.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56854a-1799-4676-af6f-ff868a66d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 4))\n",
    "# plt.hist(pretrained_encoder_head_ep60, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# # plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "# plt.xlabel(\"cos-sim\")\n",
    "# plt.ylabel(\"Density\")\n",
    "# plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (after epoch 60)\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fb904-b1f4-497c-8deb-8eeabc241973",
   "metadata": {},
   "source": [
    "#### Cosine-similarity 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a663e-ccbb-4a8c-8664-585b0f48836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 60 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/39c990f3-0db5-430a-8095-075f38a5e808/seq_encoder_cos-sim0.2.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/39c990f3-0db5-430a-8095-075f38a5e808/seq_down_cos-sim0.2.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1152, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c3590-d12b-452a-83dd-44401ff2913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep02 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1152]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep02.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a6b26-06f3-49eb-a559-4b295474808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep02, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (cos-sim 0.2)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de98b6f-4c41-4953-8b90-846f34c59d93",
   "metadata": {},
   "source": [
    "#### Cosine-similarity 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266f1d5-1b36-434d-a786-b2fdcfd5854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training seq_down for 60 epoch \n",
    "seq_encoder_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/39c990f3-0db5-430a-8095-075f38a5e808/seq_encoder_cos-sim0.3.pt\"\n",
    "seq_encoder_state_dict = torch.load(seq_encoder_checkpoint_path, map_location=device)\n",
    "seq_encoder = ESM2EncoderLoRA()\n",
    "seq_encoder.load_state_dict(seq_encoder_state_dict)\n",
    "seq_encoder.to(device)\n",
    "seq_encoder.eval()\n",
    "\n",
    "seq_down_checkpoint_path = \"/work3/s232958/data/trained/boostingESM2wESMIF/train_on_PPint_OldLoss/39c990f3-0db5-430a-8095-075f38a5e808/seq_down_cos-sim0.3.pt\"\n",
    "seq_down_state_dict = torch.load(seq_down_checkpoint_path, map_location=device)\n",
    "seq_down = nn.Linear(1152, 512)\n",
    "seq_down.load_state_dict(seq_down_state_dict)\n",
    "seq_down.to(device)\n",
    "# seq_down.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9068b5c-fc86-4c39-b47c-8b6d760f7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED seq_encoder and seq_down\n",
    "\n",
    "_loader = DataLoader(meta_Dataset, batch_size=10)\n",
    "pretrained_encoder_head_ep03 = []\n",
    "\n",
    "for batch in tqdm(_loader):\n",
    "    ___, seqs_list, struct_embed = batch\n",
    "    struct_embed = struct_embed.to(device)\n",
    "\n",
    "    seq_embed = seq_encoder(seqs_list)\n",
    "    B, Lq, _ = seq_embed.shape\n",
    "    _, Ls, Ds = struct_embed.shape\n",
    "\n",
    "    seq_mask = non_padding_mask(seq_embed, padding_value)   # [B, Lq]\n",
    "    str_mask = non_padding_mask(struct_embed, padding_value)  # [B, Ls]\n",
    "\n",
    "    # enforce residue-wise alignment\n",
    "    # print(seq_mask.sum(dim=1).cpu().tolist())\n",
    "    # print(str_mask.sum(dim=1).cpu().tolist())\n",
    "    assert (seq_mask.sum(dim=1).cpu().tolist()== str_mask.sum(dim=1).cpu().tolist())\n",
    "\n",
    "    # ---- project seq tokens + pad to structure length ----\n",
    "    seq_embed_proj = torch.full((B, Ls, Ds), padding_value, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "    \n",
    "    for i in range(B):\n",
    "        real_seq = seq_embed[i][seq_mask[i]]      # [Li, 1152]\n",
    "        proj = seq_down(real_seq)      # [Li, 512]\n",
    "        seq_embed_proj[i, :proj.size(0)] = proj   # pad up to Ls\n",
    "\n",
    "\n",
    "    # ---- token-level cosine similarity (aligned positions) ----\n",
    "    cos = F.cosine_similarity(seq_embed_proj, struct_embed, dim=-1)  # [B, Ls]\n",
    "    cos = cos * str_mask.float()   # mask padding\n",
    "\n",
    "    per_seq_cos = cos.sum(dim=1) / str_mask.sum(dim=1)\n",
    "    pretrained_encoder_head_ep03.extend(per_seq_cos.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923520f4-a751-45e4-b8c9-f23170f497c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pretrained_encoder_head_ep03, bins=50, alpha=0.6, label=\"Cosine similarities before\", density=True)\n",
    "# plt.hist(neg_logits, bins=50, alpha=0.6, label=\"Negative pairs\", density=True)\n",
    "\n",
    "plt.xlabel(\"cos-sim\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cosine similaritiespre-trained seq_encoder&proj_head vs ESM-IF (cos-sim 0.3)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fe8f8-f830-4929-9ebb-f6c1afcd1b76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688cca7-6bd8-46a6-82e4-62e12d5f5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.hist(original_embeds_random_head, bins=50, alpha=0.5,\n",
    "         label=\"Original ESM-2 embeds/ random proj_head\", density=True)\n",
    "\n",
    "# plt.hist(original_embeds_pretrained_head_ep1, bins=50, alpha=0.5,\n",
    "#          label=\"Original embeds (pretrained head)\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep1, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 1 \", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep5, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 5 \", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep25, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 25\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep50, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head(seq_down_5) epoch 50\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep02, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head cos-sim 0.2\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep03, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head cos-sim 0.3\", density=True)\n",
    "\n",
    "plt.xlabel(\"Cosine similarity\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cos-sim SM-2 vs ESM-IF (proj head frozen after epoch 4)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d545a9b-7242-425f-88d1-27ef72964ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.hist(original_embeds_random_head, bins=50, alpha=0.5,\n",
    "         label=\"Original ESM-2 embeds/ random proj_head\", density=True)\n",
    "\n",
    "# plt.hist(original_embeds_pretrained_head_ep1, bins=50, alpha=0.5,\n",
    "#          label=\"Original embeds (pretrained head)\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep1, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 1 \", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep5, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 5 \", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep25, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 25\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep50, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head epoch 50\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep02, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head cos-sim 0.2\", density=True)\n",
    "\n",
    "plt.hist(pretrained_encoder_head_ep03, bins=50, alpha=0.5,\n",
    "         label=\"Pretrained seq_encoder/proj_head cos-sim 0.3\", density=True)\n",
    "\n",
    "plt.xlabel(\"Cosine similarity\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Cos-sim SM-2 vs ESM-IF (proj head frozen after epoch 4)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae242efa-a799-4608-ad97-8e0eaa676654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESM CUDA Env",
   "language": "python",
   "name": "esm_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
